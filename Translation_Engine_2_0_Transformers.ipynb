{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANDN-s1fjvDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3aac6ab-a9fc-4c26-a47d-e6447cf5fa7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive, auth\n",
        "import pandas as pd\n",
        "import io\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "auth.authenticate_user()\n",
        "FILE_ID = \"1Ia0lMueQGicyHzacvLCmtVxiiALbaydQ\"\n",
        "\n",
        "def download_file_from_drive(file_id):\n",
        "    \"\"\"Downloads corpus from Google Drive using the file ID.\"\"\"\n",
        "    service = build('drive', 'v3')\n",
        "    request = service.files().get_media(fileId=file_id)\n",
        "    file_handle = io.BytesIO()\n",
        "\n",
        "    downloader = MediaIoBaseDownload(file_handle, request)\n",
        "    done = False\n",
        "    while not done:\n",
        "        status, done = downloader.next_chunk()\n",
        "    file_handle.seek(0)\n",
        "    return file_handle\n",
        "\n",
        "\n",
        "file_handle = download_file_from_drive(FILE_ID)\n",
        "df = pd.read_csv(file_handle)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preproccessing"
      ],
      "metadata": {
        "id": "argkcgDrkdu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n",
        "print(len(df[\"English\"]))\n",
        "print(len(df[\"Greek\"]))"
      ],
      "metadata": {
        "id": "dwY9E12QnOdn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0070e354-02f8-432a-f120-84bea1080181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             English  \\\n",
            "0                          Resumption of the session   \n",
            "1  I declare resumed the session of the European ...   \n",
            "2  Although, as you will have seen, the dreaded '...   \n",
            "3  You have requested a debate on this subject in...   \n",
            "4  In the meantime, I should like to observe a mi...   \n",
            "\n",
            "                                               Greek  \n",
            "0                              Επαvάληψη της συvσδoυ  \n",
            "1  Κηρύσσω την επανάληψη της συνόδου του Ευρωπαϊκ...  \n",
            "2  Όπως μπορέσατε να διαπιστώσετε, ο περίφημος \"ι...  \n",
            "3  Επιθυμείτε μία συζήτηση επί του θέματος τις επ...  \n",
            "4  Επί του παρόντος θα ήθελα, όπως μου ζήτησαν ορ...  \n",
            "1235977\n",
            "1235977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing_english = df['English'].isnull().sum()\n",
        "print(f\"Missing values in English column: {missing_english}\")\n",
        "\n",
        "missing_greek = df['Greek'].isnull().sum()\n",
        "print(f\"Missing values in Greek column: {missing_greek}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0yUrShd3qBG",
        "outputId": "07d0532d-1d65-40c0-93dd-44159831adef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in English column: 2354\n",
            "Missing values in Greek column: 5767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text\n",
        "import sentencepiece as spm\n",
        "\n",
        "# Preprocessing Hyperparameters\n",
        "MAX_VOCAB_SIZE = 32000 #Same as the paper\n",
        "BATCH_SIZE = 128\n",
        "MIN_TOKENS = 3\n",
        "MAX_TOKENS = 20\n",
        "MAX_SEQ_LENGTH = MAX_TOKENS + 2  # +2 for start and end tokens\n",
        "\n",
        "df = df.dropna(subset=[\"English\", \"Greek\"])\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower().strip()\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text\n",
        "\n",
        "df[\"English\"] = df[\"English\"].apply(clean_text)\n",
        "df[\"Greek\"] = df[\"Greek\"].apply(clean_text)\n",
        "\n",
        "# Filter by token length (without start/end tokens)\n",
        "df = df[df[\"English\"].str.split().str.len().between(MIN_TOKENS, MAX_TOKENS)]\n",
        "df = df[df[\"Greek\"].str.split().str.len().between(MIN_TOKENS, MAX_TOKENS)]\n",
        "\n",
        "# Shuffle data\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Split into train/val/test (80/10/10)\n",
        "total = len(df)\n",
        "train_df = df.iloc[:int(0.8*total)]\n",
        "val_df = df.iloc[int(0.8*total):int(0.9*total)]\n",
        "test_df = df.iloc[int(0.9*total):]\n",
        "\n",
        "# Print dataset sizes\n",
        "print(\"Training set size:\", len(train_df))\n",
        "print(\"Validation set size:\", len(val_df))\n",
        "print(\"Test set size:\", len(test_df))\n",
        "\n",
        "# Combine training data for both languages to train a shared vocabulary\n",
        "combined_train_text = pd.concat([train_df[\"English\"], train_df[\"Greek\"]], axis=0)\n",
        "combined_train_text_path = \"combined_train_text.txt\"\n",
        "combined_train_text.to_csv(combined_train_text_path, index=False, header=False)\n",
        "\n",
        "spm.SentencePieceTrainer.Train(\n",
        "    input=combined_train_text_path,\n",
        "    model_prefix=\"spm_model\",\n",
        "    vocab_size=MAX_VOCAB_SIZE,\n",
        "    character_coverage=1.0,\n",
        "    model_type='bpe',\n",
        "    max_sentence_length=10000\n",
        ")\n",
        "\n",
        "# Load the trained SentencePiece model\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(\"spm_model.model\")\n",
        "\n",
        "# Ensure start_token_id and end_token_id are outside the normal token range\n",
        "vocab_size = sp.get_piece_size()\n",
        "start_token_id = vocab_size + 1\n",
        "end_token_id = vocab_size + 2\n",
        "\n",
        "print(\"Trained SentencePiece vocab size:\", sp.get_piece_size())\n",
        "\n",
        "# Create tf_text SentencepieceTokenizer\n",
        "tokenizer = tf_text.SentencepieceTokenizer(\n",
        "    model=tf.io.gfile.GFile(\"spm_model.model\", 'rb').read(),\n",
        "    out_type=tf.int32,\n",
        "    nbest_size=0,\n",
        "    add_bos=False, add_eos=False\n",
        ")\n",
        "\n",
        "def vectorize_pairs(en, gr):\n",
        "    # Tokenize English\n",
        "    en_tokens = tokenizer.tokenize(en)\n",
        "    en_tokens = en_tokens.to_tensor(shape=[tf.shape(en)[0], MAX_SEQ_LENGTH], default_value=0)\n",
        "\n",
        "    # Tokenize Greek\n",
        "    gr_tokens = tokenizer.tokenize(gr)\n",
        "    # prepend start_token_id and append end_token_id to each sequence\n",
        "    gr_tokens = tf.ragged.map_flat_values(\n",
        "        lambda row: tf.concat([[start_token_id], row, [end_token_id]], axis=0),\n",
        "        gr_tokens\n",
        "    )\n",
        "\n",
        "    # Convert to dense with padding/truncation\n",
        "    gr_tokens = gr_tokens.to_tensor(shape=[tf.shape(gr)[0], MAX_SEQ_LENGTH], default_value=0)\n",
        "\n",
        "    return (en_tokens, gr_tokens)\n",
        "\n",
        "train_eng = tf.data.Dataset.from_tensor_slices(train_df[\"English\"].values)\n",
        "train_gr = tf.data.Dataset.from_tensor_slices(train_df[\"Greek\"].values)\n",
        "val_eng = tf.data.Dataset.from_tensor_slices(val_df[\"English\"].values)\n",
        "val_gr = tf.data.Dataset.from_tensor_slices(val_df[\"Greek\"].values)\n",
        "\n",
        "train_ds = tf.data.Dataset.zip((train_eng, train_gr)).batch(BATCH_SIZE).map(vectorize_pairs).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = tf.data.Dataset.zip((val_eng, val_gr)).batch(BATCH_SIZE).map(vectorize_pairs).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"Vocabulary size:\", sp.get_piece_size())\n",
        "print(\"A few random tokens from the vocab:\")\n",
        "for i in [0, 10, 100, 500, 9999]:\n",
        "    print(i, sp.id_to_piece(i))\n",
        "\n",
        "for inp, tar in train_ds.take(1):\n",
        "    print(\"Sample batch from train_ds:\")\n",
        "    print(\"Input shape:\", inp.shape)\n",
        "    print(\"Target shape:\", tar.shape)\n",
        "    print(\"First input sequence (token IDs):\", inp[0, :20])\n",
        "    print(\"First target sequence (token IDs):\", tar[0, :20])\n",
        "\n",
        "    # Convert a few tokens back to text for sanity check\n",
        "    first_inp_tokens = inp[0].numpy()\n",
        "    first_tar_tokens = tar[0].numpy()\n",
        "    # Filter out padding (0)\n",
        "    first_inp_tokens = [t for t in first_inp_tokens if t != 0]\n",
        "    first_tar_tokens = [t for t in first_tar_tokens if t != 0]\n",
        "\n",
        "    print(\"Reconstructed input text:\", \" \".join([sp.id_to_piece(int(t)) for t in first_inp_tokens if t < vocab_size]))\n",
        "    print(\"Reconstructed target text:\", \" \".join([sp.id_to_piece(int(t)) for t in first_tar_tokens if t < vocab_size]))\n",
        "\n",
        "for inp, tar in val_ds.take(1):\n",
        "    print(\"Validation batch sample:\")\n",
        "    print(\"Input shape:\", inp.shape)\n",
        "    print(\"Target shape:\", tar.shape)\n",
        "    print(\"Input tokens (first sequence):\", inp[0, :20])\n",
        "    print(\"Target tokens (first sequence):\", tar[0, :20])\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo3H8_cc3AeI",
        "outputId": "f992347d-d546-47db-ae3f-e4db4987346a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 366815\n",
            "Validation set size: 45852\n",
            "Test set size: 45852\n",
            "Trained SentencePiece vocab size: 32000\n",
            "Vocabulary size: 32000\n",
            "A few random tokens from the vocab:\n",
            "0 <unk>\n",
            "10 ▁α\n",
            "100 ▁and\n",
            "500 ▁fa\n",
            "9999 ▁νομικό\n",
            "Sample batch from train_ds:\n",
            "Input shape: (128, 22)\n",
            "Target shape: (128, 22)\n",
            "First input sequence (token IDs): tf.Tensor(\n",
            "[  137    71  2254  5660 31819     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0], shape=(20,), dtype=int32)\n",
            "First target sequence (token IDs): tf.Tensor(\n",
            "[32001   119  2148 29408     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0], shape=(20,), dtype=int32)\n",
            "Reconstructed input text: ▁it ▁is ▁really ▁considerable .\n",
            "Reconstructed target text: ▁είναι ▁πραγματικά ▁αξιοσημείωτο\n",
            "Validation batch sample:\n",
            "Input shape: (128, 22)\n",
            "Target shape: (128, 22)\n",
            "Input tokens (first sequence): tf.Tensor(\n",
            "[  120    71   375   623 21718 22248 22227    43   200    48 26530 31819\n",
            "     0     0     0     0     0     0     0     0], shape=(20,), dtype=int32)\n",
            "Target tokens (first sequence): tf.Tensor(\n",
            "[32001   774  4372    95 14495  1919   445  3141  2543 31818   239 17273\n",
            " 31819     0     0     0     0     0     0     0], shape=(20,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "vd7E7-59Bl6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_angles(pos, i, d_model):\n",
        "      # Ensures float32 operations\n",
        "      pos = tf.cast(pos, tf.float32)\n",
        "      i = tf.cast(i, tf.float32)\n",
        "      return pos / tf.pow(10000., (2 * (i//2)) / tf.cast(d_model, tf.float32))\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(\n",
        "        tf.range(position)[:, tf.newaxis],\n",
        "        tf.range(d_model)[tf.newaxis, :],\n",
        "        d_model\n",
        "    )\n",
        "    sines = tf.sin(angle_rads[:, 0::2])\n",
        "    cosines = tf.cos(angle_rads[:, 1::2])\n",
        "    angle_rads = tf.TensorArray(tf.float32, size=d_model)\n",
        "    # Combine sines and cosines back:\n",
        "    even_out = tf.reshape(sines, (-1, tf.shape(sines)[1])) # sines shape: position x d_model/2\n",
        "    odd_out = tf.reshape(cosines, (-1, tf.shape(cosines)[1])) # same\n",
        "\n",
        "    angle_rads = tf.reshape(tf.stack([even_out, odd_out], axis=2), (1, position, d_model))\n",
        "    return tf.cast(angle_rads, tf.float32)\n",
        "\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, vocab_size, d_model, max_length):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
        "        self.pos_encoding = positional_encoding(max_length, d_model)\n",
        "\n",
        "    def call(self, x):\n",
        "        length = tf.shape(x)[1]\n",
        "        x = self.embedding(x) * tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x = x + self.pos_encoding[:, :length, :]\n",
        "        return x\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    # Compute attention weights and output\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled_logits += (mask * -1e9)\n",
        "\n",
        "    weights = tf.nn.softmax(scaled_logits, axis=-1)\n",
        "    output = tf.matmul(weights, v)\n",
        "    return output, weights\n",
        "\n",
        "class MultiHeadAttention(layers.Layer):\n",
        "    # Multi-head attention mechanism\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0\n",
        "        self.num_heads = num_heads\n",
        "        self.depth = d_model // num_heads\n",
        "        self.wq = layers.Dense(d_model)\n",
        "        self.wk = layers.Dense(d_model)\n",
        "        self.wv = layers.Dense(d_model)\n",
        "        self.dense = layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        # Split the last dimension into (num_heads, depth)\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "        scaled_attention, _ = scaled_dot_product_attention(q, k, v, mask)\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.num_heads*self.depth))\n",
        "        return self.dense(concat_attention)\n",
        "\n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "        # Fully connected feed-forward network\n",
        "        return tf.keras.Sequential([\n",
        "            layers.Dense(dff, activation='relu'),\n",
        "            layers.Dense(d_model)\n",
        "        ])\n",
        "\n",
        "class EncoderLayer(layers.Layer):\n",
        "    # A single layer of the Transformer encoder\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, mask, training):\n",
        "        attn_output = self.mha(x, x, x, mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, look_ahead_mask=None, padding_mask=None, training=False):\n",
        "        attn1 = self.mha1(q=x, k=x, v=x, mask=look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(x + attn1)\n",
        "\n",
        "        attn2 = self.mha2(q=out1, k=enc_output, v=enc_output, mask=padding_mask)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(out1 + attn2)\n",
        "\n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(out2 + ffn_output)\n",
        "\n",
        "        return out3\n",
        "\n",
        "class Encoder(layers.Layer):\n",
        "    # The full Transformer encoder: multiple encoder layers\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size,\n",
        "                 maximum_position_encoding, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = PositionalEmbedding(vocab_size, d_model, maximum_position_encoding)\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
        "                           for _ in range(num_layers)]\n",
        "        self.dropout = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, mask, training):\n",
        "        x = self.embedding(x)\n",
        "        x = self.dropout(x, training=training)\n",
        "        for enc_layer in self.enc_layers:\n",
        "            x = enc_layer(x=x, mask=mask, training=training)\n",
        "        return x\n",
        "\n",
        "class Decoder(layers.Layer):\n",
        "    # The full Transformer decoder: multiple decoder layers\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size,\n",
        "                 maximum_position_encoding, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = PositionalEmbedding(vocab_size, d_model, maximum_position_encoding)\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)\n",
        "                           for _ in range(num_layers)]\n",
        "        self.dropout = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, look_ahead_mask, padding_mask, training):\n",
        "        x = self.embedding(x)\n",
        "        x = self.dropout(x, training=training)\n",
        "        for dec_layer in self.dec_layers:\n",
        "            x = dec_layer(x=x, enc_output=enc_output,\n",
        "                          look_ahead_mask=look_ahead_mask,\n",
        "                          padding_mask=padding_mask,\n",
        "                          training=training)\n",
        "        return x\n",
        "\n",
        "class Transformer(tf.keras.Model):\n",
        "    # The full Transformer model: encoder + decoder + final linear layer\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "                 target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                               input_vocab_size, pe_input, rate)\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                               target_vocab_size, pe_target, rate)\n",
        "        self.final_layer = layers.Dense(target_vocab_size)\n",
        "\n",
        "    def call(self, enc_inputs, dec_inputs, enc_padding_mask,\n",
        "             look_ahead_mask, dec_padding_mask, training):\n",
        "        enc_output = self.encoder(x=enc_inputs, mask=enc_padding_mask, training=training)\n",
        "        dec_output = self.decoder(x=dec_inputs, enc_output=enc_output, look_ahead_mask=look_ahead_mask, padding_mask=dec_padding_mask, training=training)\n",
        "        final_output = self.final_layer(dec_output)\n",
        "        return final_output"
      ],
      "metadata": {
        "id": "Wt8NJIJjBmyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training\n"
      ],
      "metadata": {
        "id": "C-qOzgOtDAJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import GPUtil\n",
        "import math\n",
        "# Hyperparameters (Following \"Attention is All You Need\")\n",
        "EPOCHS = 20\n",
        "LEARNING_RATE = 1e-3\n",
        "NUM_LAYERS = 6\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "DFF = 1024\n",
        "DROPOUT_RATE = 0.1\n",
        "warmup_steps = 4000\n",
        "\n",
        "input_vocab_size = sp.get_piece_size()\n",
        "target_vocab_size = input_vocab_size\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
        "\n",
        "\n",
        "#Follows learning rate scheduling from \"Attention is All You Need\"\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "        self.d_model = tf.cast(d_model, tf.float32)\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = tf.cast(step, tf.float32)\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "transformer = Transformer(\n",
        "    num_layers=NUM_LAYERS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dff=DFF,\n",
        "    input_vocab_size=input_vocab_size,\n",
        "    target_vocab_size=target_vocab_size,\n",
        "    pe_input=MAX_SEQ_LENGTH,\n",
        "    pe_target=MAX_SEQ_LENGTH,\n",
        "    rate=DROPOUT_RATE\n",
        ")\n",
        "\n",
        "# Loss and metrics\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "learning_rate_schedule = CustomSchedule(D_MODEL)\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=learning_rate_schedule,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.98,\n",
        "    epsilon=1e-9\n",
        ")\n",
        "\n",
        "def create_padding_mask(seq):\n",
        "    # Mask out padding tokens\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    # Prevent decoder from attending to future tokens\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask\n",
        "\n",
        "def create_masks(inp, tar):\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)\n",
        "\n",
        "@tf.function\n",
        "def train_step(inp, tar):\n",
        "    # tar_inp is everything except last token, tar_real is everything except first token\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    # Check how many tokens are non-padding in tar_real\n",
        "    non_pad_tokens = tf.reduce_sum(\n",
        "        tf.cast(tf.math.logical_not(tf.math.equal(tar_real, 0)), tf.float32)\n",
        "    )\n",
        "    tf.print(\"Number of non-padding tokens in tar_real:\", non_pad_tokens)\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = transformer(\n",
        "            enc_inputs=inp,\n",
        "            dec_inputs=tar_inp,\n",
        "            enc_padding_mask=enc_padding_mask,\n",
        "            look_ahead_mask=combined_mask,\n",
        "            dec_padding_mask=dec_padding_mask,\n",
        "            training=True\n",
        "        )\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    # Print out the loss to confirm it's non-zero\n",
        "    tf.print(\"Loss:\", loss)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    avg_grad = tf.reduce_mean([tf.reduce_mean(tf.abs(g)) for g in gradients if g is not None])\n",
        "    tf.print(\"Average gradient:\", avg_grad)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "    train_loss(loss)\n",
        "\n",
        "@tf.function\n",
        "def val_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "    predictions = transformer(\n",
        "        enc_inputs=inp,\n",
        "        dec_inputs=tar_inp,\n",
        "        enc_padding_mask=enc_padding_mask,\n",
        "        look_ahead_mask=combined_mask,\n",
        "        dec_padding_mask=dec_padding_mask,\n",
        "        training=True\n",
        "    )\n",
        "\n",
        "    v_loss = loss_function(tar_real, predictions)\n",
        "    val_loss(v_loss)\n",
        "\n",
        "sample_input = tf.ones((1, MAX_SEQ_LENGTH), dtype=tf.int32)\n",
        "sample_target = tf.ones((1, MAX_SEQ_LENGTH), dtype=tf.int32)\n",
        "_ = transformer(\n",
        "    enc_inputs=sample_input,\n",
        "    dec_inputs=sample_target[:, :-1],\n",
        "    enc_padding_mask=create_padding_mask(sample_input),\n",
        "    look_ahead_mask=create_look_ahead_mask(MAX_SEQ_LENGTH-1),\n",
        "    dec_padding_mask=create_padding_mask(sample_input),\n",
        "    training=False\n",
        ")\n",
        "\n",
        "def get_resource_usage():\n",
        "    # CPU usage\n",
        "    cpu = psutil.cpu_percent()\n",
        "\n",
        "    # RAM usage\n",
        "    ram = psutil.virtual_memory().percent\n",
        "\n",
        "    # GPU info\n",
        "    try:\n",
        "        gpus = GPUtil.getGPUs()\n",
        "        if gpus:\n",
        "            gpu = gpus[0]  # Get first GPU\n",
        "            gpu_name = gpu.name\n",
        "            gpu_util = gpu.load * 100\n",
        "            gpu_mem = gpu.memoryUtil * 100\n",
        "            gpu_info = f\"GPU ({gpu_name}): {gpu_util:.1f}% (MEM: {gpu_mem:.1f}%)\"\n",
        "        else:\n",
        "            gpu_info = \"No GPU found\"\n",
        "    except:\n",
        "        gpu_info = \"GPU info unavailable\"\n",
        "\n",
        "    return f\"CPU: {cpu:.1f}% | RAM: {ram:.1f}% | {gpu_info}\"\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss.reset_state()\n",
        "    val_loss.reset_state()\n",
        "\n",
        "    # Training\n",
        "    for (batch, (inp, tar)) in enumerate(train_ds):\n",
        "        train_step(inp, tar)\n",
        "        print(f\"Resources: {get_resource_usage()}\")\n",
        "        print(f\"Training Epoch {epoch+1}, Batch {batch+1}...\")\n",
        "\n",
        "    # Validation\n",
        "    for (batch, (inp, tar)) in enumerate(val_ds):\n",
        "        val_step(inp, tar)\n",
        "\n",
        "    # Print epoch results\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}, \"\n",
        "          f\"Train Loss: {train_loss.result():.4f}, \"\n",
        "          f\"Val Loss: {val_loss.result():.4f}\")\n",
        "\n",
        "    # Save the model weights after each epoch\n",
        "    transformer.save_weights(f\"transformer_weights_epoch_{epoch+1}.weights.h5\")\n",
        "    print(\"Model weights saved.\")\n",
        "\n",
        "# Save final weights\n",
        "transformer.save_weights(\"/content/drive/MyDrive/transformer_weights_final.weights.h5\")\n",
        "print(\"Model training completed and weights saved.\")"
      ],
      "metadata": {
        "id": "zBqUhvNsDBf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d371aac-fae7-4fdd-e962-51116267ffb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1867...\n",
            "Number of non-padding tokens in tar_real: 1758\n",
            "Loss: 2.23072147\n",
            "Average gradient: 0.000861086301\n",
            "Resources: CPU: 15.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1868...\n",
            "Number of non-padding tokens in tar_real: 1744\n",
            "Loss: 2.31198359\n",
            "Average gradient: 0.000789158454\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1869...\n",
            "Number of non-padding tokens in tar_real: 1803\n",
            "Loss: 2.17277026\n",
            "Average gradient: 0.000709340151\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1870...\n",
            "Number of non-padding tokens in tar_real: 1731\n",
            "Loss: 2.34794021\n",
            "Average gradient: 0.000825890806\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1871...\n",
            "Number of non-padding tokens in tar_real: 1822\n",
            "Loss: 2.14740205\n",
            "Average gradient: 0.000722212542\n",
            "Resources: CPU: 11.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1872...\n",
            "Number of non-padding tokens in tar_real: 1827\n",
            "Loss: 2.11237454\n",
            "Average gradient: 0.000756237772\n",
            "Resources: CPU: 14.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1873...\n",
            "Number of non-padding tokens in tar_real: 1802\n",
            "Loss: 2.12082362\n",
            "Average gradient: 0.000798941939\n",
            "Resources: CPU: 14.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1874...\n",
            "Number of non-padding tokens in tar_real: 1732\n",
            "Loss: 2.15182018\n",
            "Average gradient: 0.000756196154\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1875...\n",
            "Number of non-padding tokens in tar_real: 1771\n",
            "Loss: 2.14931345\n",
            "Average gradient: 0.000770470942\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1876...\n",
            "Number of non-padding tokens in tar_real: 1734\n",
            "Loss: 2.07193422\n",
            "Average gradient: 0.000899007602\n",
            "Resources: CPU: 13.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1877...\n",
            "Number of non-padding tokens in tar_real: 1797\n",
            "Loss: 2.2698524\n",
            "Average gradient: 0.000794126652\n",
            "Resources: CPU: 15.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1878...\n",
            "Number of non-padding tokens in tar_real: 1867\n",
            "Loss: 2.10707188\n",
            "Average gradient: 0.000769607374\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1879...\n",
            "Number of non-padding tokens in tar_real: 1741\n",
            "Loss: 2.20136857\n",
            "Average gradient: 0.000895521371\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1880...\n",
            "Number of non-padding tokens in tar_real: 1828\n",
            "Loss: 2.20824075\n",
            "Average gradient: 0.00079614541\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1881...\n",
            "Number of non-padding tokens in tar_real: 1809\n",
            "Loss: 2.25075078\n",
            "Average gradient: 0.000778963498\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1882...\n",
            "Number of non-padding tokens in tar_real: 1736\n",
            "Loss: 2.20994043\n",
            "Average gradient: 0.000791642757\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1883...\n",
            "Number of non-padding tokens in tar_real: 1912\n",
            "Loss: 2.29618859\n",
            "Average gradient: 0.000735399546\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1884...\n",
            "Number of non-padding tokens in tar_real: 1763\n",
            "Loss: 2.20885754\n",
            "Average gradient: 0.000888529874\n",
            "Resources: CPU: 12.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1885...\n",
            "Number of non-padding tokens in tar_real: 1789\n",
            "Loss: 2.07803893\n",
            "Average gradient: 0.000798603112\n",
            "Resources: CPU: 13.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1886...\n",
            "Number of non-padding tokens in tar_real: 1785\n",
            "Loss: 2.21204567\n",
            "Average gradient: 0.000820142275\n",
            "Resources: CPU: 15.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1887...\n",
            "Number of non-padding tokens in tar_real: 1816\n",
            "Loss: 2.25861573\n",
            "Average gradient: 0.000854933751\n",
            "Resources: CPU: 12.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1888...\n",
            "Number of non-padding tokens in tar_real: 1850\n",
            "Loss: 2.23992634\n",
            "Average gradient: 0.00080419908\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1889...\n",
            "Number of non-padding tokens in tar_real: 1881\n",
            "Loss: 2.24931216\n",
            "Average gradient: 0.000788236852\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1890...\n",
            "Number of non-padding tokens in tar_real: 1831\n",
            "Loss: 2.16529965\n",
            "Average gradient: 0.000796914916\n",
            "Resources: CPU: 21.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1891...\n",
            "Number of non-padding tokens in tar_real: 1736\n",
            "Loss: 2.13537073\n",
            "Average gradient: 0.000801669899\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1892...\n",
            "Number of non-padding tokens in tar_real: 1784\n",
            "Loss: 2.28998113\n",
            "Average gradient: 0.000840510475\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1893...\n",
            "Number of non-padding tokens in tar_real: 1879\n",
            "Loss: 2.24975157\n",
            "Average gradient: 0.000797528832\n",
            "Resources: CPU: 14.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1894...\n",
            "Number of non-padding tokens in tar_real: 1836\n",
            "Loss: 2.40631294\n",
            "Average gradient: 0.000836525694\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1895...\n",
            "Number of non-padding tokens in tar_real: 1836\n",
            "Loss: 2.32557321\n",
            "Average gradient: 0.000784485601\n",
            "Resources: CPU: 14.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1896...\n",
            "Number of non-padding tokens in tar_real: 1836\n",
            "Loss: 2.39982462\n",
            "Average gradient: 0.000819738\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1897...\n",
            "Number of non-padding tokens in tar_real: 1924\n",
            "Loss: 2.30681109\n",
            "Average gradient: 0.000894704834\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1898...\n",
            "Number of non-padding tokens in tar_real: 1788\n",
            "Loss: 2.37861896\n",
            "Average gradient: 0.000804433541\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1899...\n",
            "Number of non-padding tokens in tar_real: 1804\n",
            "Loss: 2.17091227\n",
            "Average gradient: 0.000813659164\n",
            "Resources: CPU: 14.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1900...\n",
            "Number of non-padding tokens in tar_real: 1880\n",
            "Loss: 2.28577352\n",
            "Average gradient: 0.000847111805\n",
            "Resources: CPU: 14.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1901...\n",
            "Number of non-padding tokens in tar_real: 1768\n",
            "Loss: 2.19047642\n",
            "Average gradient: 0.000759527902\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1902...\n",
            "Number of non-padding tokens in tar_real: 1766\n",
            "Loss: 2.04060388\n",
            "Average gradient: 0.000731572334\n",
            "Resources: CPU: 14.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1903...\n",
            "Number of non-padding tokens in tar_real: 1873\n",
            "Loss: 2.19090104\n",
            "Average gradient: 0.000812530925\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1904...\n",
            "Number of non-padding tokens in tar_real: 1821\n",
            "Loss: 2.20314503\n",
            "Average gradient: 0.000810649828\n",
            "Resources: CPU: 14.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1905...\n",
            "Number of non-padding tokens in tar_real: 1810\n",
            "Loss: 2.29562378\n",
            "Average gradient: 0.000777572801\n",
            "Resources: CPU: 12.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1906...\n",
            "Number of non-padding tokens in tar_real: 1798\n",
            "Loss: 2.33713412\n",
            "Average gradient: 0.000846280309\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1907...\n",
            "Number of non-padding tokens in tar_real: 1815\n",
            "Loss: 2.22102952\n",
            "Average gradient: 0.000822002068\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1908...\n",
            "Number of non-padding tokens in tar_real: 1806\n",
            "Loss: 2.3588376\n",
            "Average gradient: 0.000754078734\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1909...\n",
            "Number of non-padding tokens in tar_real: 1878\n",
            "Loss: 2.21333981\n",
            "Average gradient: 0.000816948828\n",
            "Resources: CPU: 13.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1910...\n",
            "Number of non-padding tokens in tar_real: 1822\n",
            "Loss: 2.30839205\n",
            "Average gradient: 0.000827242213\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1911...\n",
            "Number of non-padding tokens in tar_real: 1776\n",
            "Loss: 2.31569147\n",
            "Average gradient: 0.000777436886\n",
            "Resources: CPU: 12.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1912...\n",
            "Number of non-padding tokens in tar_real: 1777\n",
            "Loss: 2.31651568\n",
            "Average gradient: 0.000849217875\n",
            "Resources: CPU: 14.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1913...\n",
            "Number of non-padding tokens in tar_real: 1886\n",
            "Loss: 2.29634786\n",
            "Average gradient: 0.000782609684\n",
            "Resources: CPU: 15.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1914...\n",
            "Number of non-padding tokens in tar_real: 1854\n",
            "Loss: 2.20274925\n",
            "Average gradient: 0.000757903443\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1915...\n",
            "Number of non-padding tokens in tar_real: 1856\n",
            "Loss: 2.34324026\n",
            "Average gradient: 0.000794738706\n",
            "Resources: CPU: 12.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1916...\n",
            "Number of non-padding tokens in tar_real: 1764\n",
            "Loss: 2.04133844\n",
            "Average gradient: 0.000803311\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1917...\n",
            "Number of non-padding tokens in tar_real: 1840\n",
            "Loss: 2.32025647\n",
            "Average gradient: 0.000903779699\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1918...\n",
            "Number of non-padding tokens in tar_real: 1668\n",
            "Loss: 2.17806029\n",
            "Average gradient: 0.000799233734\n",
            "Resources: CPU: 13.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1919...\n",
            "Number of non-padding tokens in tar_real: 1820\n",
            "Loss: 2.14999294\n",
            "Average gradient: 0.000756625552\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1920...\n",
            "Number of non-padding tokens in tar_real: 1794\n",
            "Loss: 2.29459047\n",
            "Average gradient: 0.000802603376\n",
            "Resources: CPU: 13.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1921...\n",
            "Number of non-padding tokens in tar_real: 1907\n",
            "Loss: 2.41859365\n",
            "Average gradient: 0.000826061587\n",
            "Resources: CPU: 12.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1922...\n",
            "Number of non-padding tokens in tar_real: 1775\n",
            "Loss: 2.38645697\n",
            "Average gradient: 0.000802122231\n",
            "Resources: CPU: 15.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1923...\n",
            "Number of non-padding tokens in tar_real: 1738\n",
            "Loss: 2.30852318\n",
            "Average gradient: 0.000775492808\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1924...\n",
            "Number of non-padding tokens in tar_real: 1770\n",
            "Loss: 2.28239799\n",
            "Average gradient: 0.000829581812\n",
            "Resources: CPU: 19.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1925...\n",
            "Number of non-padding tokens in tar_real: 1800\n",
            "Loss: 2.08525658\n",
            "Average gradient: 0.000768516969\n",
            "Resources: CPU: 21.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1926...\n",
            "Number of non-padding tokens in tar_real: 1924\n",
            "Loss: 2.21198511\n",
            "Average gradient: 0.000783898111\n",
            "Resources: CPU: 21.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1927...\n",
            "Number of non-padding tokens in tar_real: 1874\n",
            "Loss: 2.15427494\n",
            "Average gradient: 0.00081970304\n",
            "Resources: CPU: 22.5% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1928...\n",
            "Number of non-padding tokens in tar_real: 1832\n",
            "Loss: 2.2808249\n",
            "Average gradient: 0.000759942573\n",
            "Resources: CPU: 20.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1929...\n",
            "Number of non-padding tokens in tar_real: 1804\n",
            "Loss: 2.2140348\n",
            "Average gradient: 0.000798826455\n",
            "Resources: CPU: 23.0% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1930...\n",
            "Number of non-padding tokens in tar_real: 1773\n",
            "Loss: 2.18648219\n",
            "Average gradient: 0.000805548159\n",
            "Resources: CPU: 22.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1931...\n",
            "Number of non-padding tokens in tar_real: 1869\n",
            "Loss: 2.16727328\n",
            "Average gradient: 0.000797828427\n",
            "Resources: CPU: 26.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1932...\n",
            "Number of non-padding tokens in tar_real: 1763\n",
            "Loss: 2.15624833\n",
            "Average gradient: 0.000729811494\n",
            "Resources: CPU: 22.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1933...\n",
            "Number of non-padding tokens in tar_real: 1856\n",
            "Loss: 2.1580689\n",
            "Average gradient: 0.000752946\n",
            "Resources: CPU: 21.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1934...\n",
            "Number of non-padding tokens in tar_real: 1854\n",
            "Loss: 2.27416706\n",
            "Average gradient: 0.000817293301\n",
            "Resources: CPU: 23.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1935...\n",
            "Number of non-padding tokens in tar_real: 1706\n",
            "Loss: 2.18087149\n",
            "Average gradient: 0.000733593362\n",
            "Resources: CPU: 21.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1936...\n",
            "Number of non-padding tokens in tar_real: 1815\n",
            "Loss: 2.07155561\n",
            "Average gradient: 0.000758875161\n",
            "Resources: CPU: 21.5% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1937...\n",
            "Number of non-padding tokens in tar_real: 1683\n",
            "Loss: 2.34012389\n",
            "Average gradient: 0.000887323404\n",
            "Resources: CPU: 23.0% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1938...\n",
            "Number of non-padding tokens in tar_real: 1943\n",
            "Loss: 2.33264875\n",
            "Average gradient: 0.000860640837\n",
            "Resources: CPU: 21.2% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1939...\n",
            "Number of non-padding tokens in tar_real: 1889\n",
            "Loss: 2.32549644\n",
            "Average gradient: 0.000910632894\n",
            "Resources: CPU: 24.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1940...\n",
            "Number of non-padding tokens in tar_real: 1811\n",
            "Loss: 2.26874137\n",
            "Average gradient: 0.000925539818\n",
            "Resources: CPU: 25.5% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1941...\n",
            "Number of non-padding tokens in tar_real: 1862\n",
            "Loss: 2.11536717\n",
            "Average gradient: 0.000765014556\n",
            "Resources: CPU: 22.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1942...\n",
            "Number of non-padding tokens in tar_real: 1818\n",
            "Loss: 2.18066049\n",
            "Average gradient: 0.000833865197\n",
            "Resources: CPU: 22.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1943...\n",
            "Number of non-padding tokens in tar_real: 1806\n",
            "Loss: 2.17724133\n",
            "Average gradient: 0.00081987842\n",
            "Resources: CPU: 22.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1944...\n",
            "Number of non-padding tokens in tar_real: 1792\n",
            "Loss: 2.18919921\n",
            "Average gradient: 0.000739830371\n",
            "Resources: CPU: 23.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1945...\n",
            "Number of non-padding tokens in tar_real: 1721\n",
            "Loss: 2.12631249\n",
            "Average gradient: 0.000781709619\n",
            "Resources: CPU: 20.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1946...\n",
            "Number of non-padding tokens in tar_real: 1829\n",
            "Loss: 2.18666649\n",
            "Average gradient: 0.000868052\n",
            "Resources: CPU: 23.2% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1947...\n",
            "Number of non-padding tokens in tar_real: 1793\n",
            "Loss: 2.21409369\n",
            "Average gradient: 0.000855106278\n",
            "Resources: CPU: 21.9% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1948...\n",
            "Number of non-padding tokens in tar_real: 1853\n",
            "Loss: 2.12739944\n",
            "Average gradient: 0.000856557104\n",
            "Resources: CPU: 23.9% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1949...\n",
            "Number of non-padding tokens in tar_real: 1739\n",
            "Loss: 2.25344038\n",
            "Average gradient: 0.000770512735\n",
            "Resources: CPU: 16.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 54.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1950...\n",
            "Number of non-padding tokens in tar_real: 1731\n",
            "Loss: 2.14055228\n",
            "Average gradient: 0.000801980728\n",
            "Resources: CPU: 13.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 54.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1951...\n",
            "Number of non-padding tokens in tar_real: 1774\n",
            "Loss: 2.29659271\n",
            "Average gradient: 0.000882757246\n",
            "Resources: CPU: 12.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 53.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1952...\n",
            "Number of non-padding tokens in tar_real: 1803\n",
            "Loss: 2.28458357\n",
            "Average gradient: 0.000729639432\n",
            "Resources: CPU: 13.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 53.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1953...\n",
            "Number of non-padding tokens in tar_real: 1734\n",
            "Loss: 2.2385776\n",
            "Average gradient: 0.000834329636\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1954...\n",
            "Number of non-padding tokens in tar_real: 1869\n",
            "Loss: 2.19902515\n",
            "Average gradient: 0.000779884926\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1955...\n",
            "Number of non-padding tokens in tar_real: 1816\n",
            "Loss: 2.28640175\n",
            "Average gradient: 0.00082013692\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1956...\n",
            "Number of non-padding tokens in tar_real: 1797\n",
            "Loss: 2.15747523\n",
            "Average gradient: 0.000752943452\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1957...\n",
            "Number of non-padding tokens in tar_real: 1717\n",
            "Loss: 2.11473918\n",
            "Average gradient: 0.000805862073\n",
            "Resources: CPU: 14.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1958...\n",
            "Number of non-padding tokens in tar_real: 1829\n",
            "Loss: 2.28235459\n",
            "Average gradient: 0.000905295368\n",
            "Resources: CPU: 14.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1959...\n",
            "Number of non-padding tokens in tar_real: 1822\n",
            "Loss: 2.37797236\n",
            "Average gradient: 0.000841854897\n",
            "Resources: CPU: 12.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1960...\n",
            "Number of non-padding tokens in tar_real: 1862\n",
            "Loss: 2.19004583\n",
            "Average gradient: 0.000838854583\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1961...\n",
            "Number of non-padding tokens in tar_real: 1785\n",
            "Loss: 2.29373431\n",
            "Average gradient: 0.000754826237\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1962...\n",
            "Number of non-padding tokens in tar_real: 1738\n",
            "Loss: 2.13233757\n",
            "Average gradient: 0.000825091964\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1963...\n",
            "Number of non-padding tokens in tar_real: 1900\n",
            "Loss: 2.27506495\n",
            "Average gradient: 0.000889606134\n",
            "Resources: CPU: 12.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1964...\n",
            "Number of non-padding tokens in tar_real: 1795\n",
            "Loss: 2.26907969\n",
            "Average gradient: 0.000845158356\n",
            "Resources: CPU: 17.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1965...\n",
            "Number of non-padding tokens in tar_real: 1734\n",
            "Loss: 2.11848569\n",
            "Average gradient: 0.000880177831\n",
            "Resources: CPU: 12.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1966...\n",
            "Number of non-padding tokens in tar_real: 1767\n",
            "Loss: 2.21015072\n",
            "Average gradient: 0.000815231295\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1967...\n",
            "Number of non-padding tokens in tar_real: 1849\n",
            "Loss: 2.18767476\n",
            "Average gradient: 0.000882253167\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1968...\n",
            "Number of non-padding tokens in tar_real: 1854\n",
            "Loss: 2.21482635\n",
            "Average gradient: 0.000826406351\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1969...\n",
            "Number of non-padding tokens in tar_real: 1786\n",
            "Loss: 2.29444623\n",
            "Average gradient: 0.000847980671\n",
            "Resources: CPU: 15.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1970...\n",
            "Number of non-padding tokens in tar_real: 1788\n",
            "Loss: 2.16038823\n",
            "Average gradient: 0.000765482662\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1971...\n",
            "Number of non-padding tokens in tar_real: 1884\n",
            "Loss: 2.18479371\n",
            "Average gradient: 0.000819620909\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1972...\n",
            "Number of non-padding tokens in tar_real: 1813\n",
            "Loss: 2.34113884\n",
            "Average gradient: 0.000908696849\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1973...\n",
            "Number of non-padding tokens in tar_real: 1900\n",
            "Loss: 2.28527284\n",
            "Average gradient: 0.000735768874\n",
            "Resources: CPU: 15.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1974...\n",
            "Number of non-padding tokens in tar_real: 1827\n",
            "Loss: 2.29729342\n",
            "Average gradient: 0.000771345221\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1975...\n",
            "Number of non-padding tokens in tar_real: 1791\n",
            "Loss: 2.3048017\n",
            "Average gradient: 0.000812361\n",
            "Resources: CPU: 12.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1976...\n",
            "Number of non-padding tokens in tar_real: 1681\n",
            "Loss: 2.12124181\n",
            "Average gradient: 0.000896616606\n",
            "Resources: CPU: 15.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1977...\n",
            "Number of non-padding tokens in tar_real: 1725\n",
            "Loss: 2.21155834\n",
            "Average gradient: 0.000750275678\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1978...\n",
            "Number of non-padding tokens in tar_real: 1848\n",
            "Loss: 2.40464449\n",
            "Average gradient: 0.000847313553\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1979...\n",
            "Number of non-padding tokens in tar_real: 1828\n",
            "Loss: 2.17425132\n",
            "Average gradient: 0.000696201925\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1980...\n",
            "Number of non-padding tokens in tar_real: 1839\n",
            "Loss: 2.16093946\n",
            "Average gradient: 0.000731513253\n",
            "Resources: CPU: 13.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1981...\n",
            "Number of non-padding tokens in tar_real: 1852\n",
            "Loss: 2.33617926\n",
            "Average gradient: 0.000873353449\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1982...\n",
            "Number of non-padding tokens in tar_real: 1703\n",
            "Loss: 2.25338697\n",
            "Average gradient: 0.00084007316\n",
            "Resources: CPU: 14.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1983...\n",
            "Number of non-padding tokens in tar_real: 1827\n",
            "Loss: 2.19594193\n",
            "Average gradient: 0.00075753883\n",
            "Resources: CPU: 13.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1984...\n",
            "Number of non-padding tokens in tar_real: 1899\n",
            "Loss: 2.35391164\n",
            "Average gradient: 0.00078824244\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1985...\n",
            "Number of non-padding tokens in tar_real: 1817\n",
            "Loss: 2.34170222\n",
            "Average gradient: 0.000939157559\n",
            "Resources: CPU: 18.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1986...\n",
            "Number of non-padding tokens in tar_real: 1845\n",
            "Loss: 2.24694872\n",
            "Average gradient: 0.000910753501\n",
            "Resources: CPU: 11.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1987...\n",
            "Number of non-padding tokens in tar_real: 1802\n",
            "Loss: 2.21532869\n",
            "Average gradient: 0.000855668739\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1988...\n",
            "Number of non-padding tokens in tar_real: 1803\n",
            "Loss: 2.21716905\n",
            "Average gradient: 0.000829002704\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1989...\n",
            "Number of non-padding tokens in tar_real: 1833\n",
            "Loss: 2.42848301\n",
            "Average gradient: 0.000782918651\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1990...\n",
            "Number of non-padding tokens in tar_real: 1910\n",
            "Loss: 2.31904244\n",
            "Average gradient: 0.000794197549\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1991...\n",
            "Number of non-padding tokens in tar_real: 1758\n",
            "Loss: 2.16590691\n",
            "Average gradient: 0.00082595757\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1992...\n",
            "Number of non-padding tokens in tar_real: 1761\n",
            "Loss: 2.31467891\n",
            "Average gradient: 0.000827871962\n",
            "Resources: CPU: 15.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1993...\n",
            "Number of non-padding tokens in tar_real: 1855\n",
            "Loss: 2.22211146\n",
            "Average gradient: 0.00086605252\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1994...\n",
            "Number of non-padding tokens in tar_real: 1864\n",
            "Loss: 2.1975503\n",
            "Average gradient: 0.000882586464\n",
            "Resources: CPU: 15.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1995...\n",
            "Number of non-padding tokens in tar_real: 1687\n",
            "Loss: 2.23522329\n",
            "Average gradient: 0.000861939101\n",
            "Resources: CPU: 12.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1996...\n",
            "Number of non-padding tokens in tar_real: 1867\n",
            "Loss: 2.1893456\n",
            "Average gradient: 0.000819666369\n",
            "Resources: CPU: 12.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1997...\n",
            "Number of non-padding tokens in tar_real: 1840\n",
            "Loss: 2.19535613\n",
            "Average gradient: 0.000778279384\n",
            "Resources: CPU: 12.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1998...\n",
            "Number of non-padding tokens in tar_real: 1784\n",
            "Loss: 2.15605092\n",
            "Average gradient: 0.000830622448\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 1999...\n",
            "Number of non-padding tokens in tar_real: 1781\n",
            "Loss: 2.38354445\n",
            "Average gradient: 0.00085796346\n",
            "Resources: CPU: 12.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2000...\n",
            "Number of non-padding tokens in tar_real: 1851\n",
            "Loss: 2.22946739\n",
            "Average gradient: 0.000835321436\n",
            "Resources: CPU: 13.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2001...\n",
            "Number of non-padding tokens in tar_real: 1925\n",
            "Loss: 2.23074126\n",
            "Average gradient: 0.00101259188\n",
            "Resources: CPU: 15.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2002...\n",
            "Number of non-padding tokens in tar_real: 1840\n",
            "Loss: 2.29902792\n",
            "Average gradient: 0.000852983561\n",
            "Resources: CPU: 13.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2003...\n",
            "Number of non-padding tokens in tar_real: 1781\n",
            "Loss: 2.2892971\n",
            "Average gradient: 0.000825875031\n",
            "Resources: CPU: 16.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2004...\n",
            "Number of non-padding tokens in tar_real: 1794\n",
            "Loss: 2.10667467\n",
            "Average gradient: 0.000757362053\n",
            "Resources: CPU: 12.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2005...\n",
            "Number of non-padding tokens in tar_real: 1729\n",
            "Loss: 2.27453661\n",
            "Average gradient: 0.000893498422\n",
            "Resources: CPU: 13.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2006...\n",
            "Number of non-padding tokens in tar_real: 1825\n",
            "Loss: 2.53094506\n",
            "Average gradient: 0.000924572523\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2007...\n",
            "Number of non-padding tokens in tar_real: 1799\n",
            "Loss: 2.2165072\n",
            "Average gradient: 0.000837172\n",
            "Resources: CPU: 12.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2008...\n",
            "Number of non-padding tokens in tar_real: 1781\n",
            "Loss: 2.17239714\n",
            "Average gradient: 0.000870155694\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2009...\n",
            "Number of non-padding tokens in tar_real: 1763\n",
            "Loss: 2.21008086\n",
            "Average gradient: 0.000786075\n",
            "Resources: CPU: 13.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2010...\n",
            "Number of non-padding tokens in tar_real: 1869\n",
            "Loss: 2.32235575\n",
            "Average gradient: 0.000820434128\n",
            "Resources: CPU: 15.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2011...\n",
            "Number of non-padding tokens in tar_real: 1790\n",
            "Loss: 2.25649714\n",
            "Average gradient: 0.000812872429\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2012...\n",
            "Number of non-padding tokens in tar_real: 1867\n",
            "Loss: 2.27920842\n",
            "Average gradient: 0.000720746815\n",
            "Resources: CPU: 15.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2013...\n",
            "Number of non-padding tokens in tar_real: 1858\n",
            "Loss: 2.32577801\n",
            "Average gradient: 0.000936936121\n",
            "Resources: CPU: 12.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2014...\n",
            "Number of non-padding tokens in tar_real: 1679\n",
            "Loss: 2.07804227\n",
            "Average gradient: 0.000734961\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2015...\n",
            "Number of non-padding tokens in tar_real: 1798\n",
            "Loss: 2.2843821\n",
            "Average gradient: 0.000811246107\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2016...\n",
            "Number of non-padding tokens in tar_real: 1805\n",
            "Loss: 2.21774793\n",
            "Average gradient: 0.000846539333\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2017...\n",
            "Number of non-padding tokens in tar_real: 1913\n",
            "Loss: 2.32298136\n",
            "Average gradient: 0.000867968542\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2018...\n",
            "Number of non-padding tokens in tar_real: 1764\n",
            "Loss: 2.2519269\n",
            "Average gradient: 0.000860402535\n",
            "Resources: CPU: 11.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2019...\n",
            "Number of non-padding tokens in tar_real: 1711\n",
            "Loss: 2.10385561\n",
            "Average gradient: 0.000775772554\n",
            "Resources: CPU: 15.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2020...\n",
            "Number of non-padding tokens in tar_real: 1892\n",
            "Loss: 2.29345274\n",
            "Average gradient: 0.000858667481\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2021...\n",
            "Number of non-padding tokens in tar_real: 1803\n",
            "Loss: 2.23890519\n",
            "Average gradient: 0.000803160539\n",
            "Resources: CPU: 14.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2022...\n",
            "Number of non-padding tokens in tar_real: 1753\n",
            "Loss: 2.24582481\n",
            "Average gradient: 0.00080681243\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2023...\n",
            "Number of non-padding tokens in tar_real: 1756\n",
            "Loss: 2.23423624\n",
            "Average gradient: 0.000821681926\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2024...\n",
            "Number of non-padding tokens in tar_real: 1815\n",
            "Loss: 2.30318618\n",
            "Average gradient: 0.000757575035\n",
            "Resources: CPU: 13.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2025...\n",
            "Number of non-padding tokens in tar_real: 1873\n",
            "Loss: 2.30540466\n",
            "Average gradient: 0.00075148046\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2026...\n",
            "Number of non-padding tokens in tar_real: 1812\n",
            "Loss: 2.19016552\n",
            "Average gradient: 0.000783936528\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2027...\n",
            "Number of non-padding tokens in tar_real: 1805\n",
            "Loss: 2.21016216\n",
            "Average gradient: 0.000798232737\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2028...\n",
            "Number of non-padding tokens in tar_real: 1804\n",
            "Loss: 2.25723934\n",
            "Average gradient: 0.000801139046\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2029...\n",
            "Number of non-padding tokens in tar_real: 1911\n",
            "Loss: 2.3800571\n",
            "Average gradient: 0.000836451247\n",
            "Resources: CPU: 14.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2030...\n",
            "Number of non-padding tokens in tar_real: 1829\n",
            "Loss: 2.13687348\n",
            "Average gradient: 0.000778445334\n",
            "Resources: CPU: 14.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2031...\n",
            "Number of non-padding tokens in tar_real: 1745\n",
            "Loss: 2.26533484\n",
            "Average gradient: 0.000787092315\n",
            "Resources: CPU: 14.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2032...\n",
            "Number of non-padding tokens in tar_real: 1845\n",
            "Loss: 2.29994822\n",
            "Average gradient: 0.00075834943\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2033...\n",
            "Number of non-padding tokens in tar_real: 1854\n",
            "Loss: 2.35273123\n",
            "Average gradient: 0.000818967412\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2034...\n",
            "Number of non-padding tokens in tar_real: 1765\n",
            "Loss: 2.04431081\n",
            "Average gradient: 0.000718494353\n",
            "Resources: CPU: 12.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2035...\n",
            "Number of non-padding tokens in tar_real: 1777\n",
            "Loss: 2.24113846\n",
            "Average gradient: 0.000802658789\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2036...\n",
            "Number of non-padding tokens in tar_real: 1817\n",
            "Loss: 2.34024239\n",
            "Average gradient: 0.000837048574\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2037...\n",
            "Number of non-padding tokens in tar_real: 1815\n",
            "Loss: 2.36494279\n",
            "Average gradient: 0.000792080944\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2038...\n",
            "Number of non-padding tokens in tar_real: 1753\n",
            "Loss: 2.2786963\n",
            "Average gradient: 0.000858447456\n",
            "Resources: CPU: 14.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2039...\n",
            "Number of non-padding tokens in tar_real: 1870\n",
            "Loss: 2.10186481\n",
            "Average gradient: 0.000787337311\n",
            "Resources: CPU: 14.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2040...\n",
            "Number of non-padding tokens in tar_real: 1761\n",
            "Loss: 2.34643674\n",
            "Average gradient: 0.00078181061\n",
            "Resources: CPU: 24.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2041...\n",
            "Number of non-padding tokens in tar_real: 1766\n",
            "Loss: 2.24557686\n",
            "Average gradient: 0.000747405516\n",
            "Resources: CPU: 20.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2042...\n",
            "Number of non-padding tokens in tar_real: 1835\n",
            "Loss: 2.230232\n",
            "Average gradient: 0.000761487056\n",
            "Resources: CPU: 20.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2043...\n",
            "Number of non-padding tokens in tar_real: 1890\n",
            "Loss: 2.26878881\n",
            "Average gradient: 0.000836632913\n",
            "Resources: CPU: 21.4% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2044...\n",
            "Number of non-padding tokens in tar_real: 1706\n",
            "Loss: 2.09621286\n",
            "Average gradient: 0.000783681055\n",
            "Resources: CPU: 22.0% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2045...\n",
            "Number of non-padding tokens in tar_real: 1826\n",
            "Loss: 2.18596911\n",
            "Average gradient: 0.000920707709\n",
            "Resources: CPU: 20.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2046...\n",
            "Number of non-padding tokens in tar_real: 1773\n",
            "Loss: 2.25955677\n",
            "Average gradient: 0.000774286\n",
            "Resources: CPU: 23.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2047...\n",
            "Number of non-padding tokens in tar_real: 1914\n",
            "Loss: 2.26032257\n",
            "Average gradient: 0.000802391151\n",
            "Resources: CPU: 26.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2048...\n",
            "Number of non-padding tokens in tar_real: 1799\n",
            "Loss: 2.19757366\n",
            "Average gradient: 0.000801781425\n",
            "Resources: CPU: 22.9% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2049...\n",
            "Number of non-padding tokens in tar_real: 1701\n",
            "Loss: 2.19263768\n",
            "Average gradient: 0.000800643757\n",
            "Resources: CPU: 21.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2050...\n",
            "Number of non-padding tokens in tar_real: 1803\n",
            "Loss: 2.16961122\n",
            "Average gradient: 0.000767558755\n",
            "Resources: CPU: 22.0% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2051...\n",
            "Number of non-padding tokens in tar_real: 1707\n",
            "Loss: 2.24259663\n",
            "Average gradient: 0.000883383094\n",
            "Resources: CPU: 21.5% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2052...\n",
            "Number of non-padding tokens in tar_real: 1830\n",
            "Loss: 2.26212597\n",
            "Average gradient: 0.000752155844\n",
            "Resources: CPU: 22.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2053...\n",
            "Number of non-padding tokens in tar_real: 1778\n",
            "Loss: 2.16866565\n",
            "Average gradient: 0.000887736504\n",
            "Resources: CPU: 22.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2054...\n",
            "Number of non-padding tokens in tar_real: 1755\n",
            "Loss: 2.06655312\n",
            "Average gradient: 0.000771912863\n",
            "Resources: CPU: 22.0% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2055...\n",
            "Number of non-padding tokens in tar_real: 1796\n",
            "Loss: 2.19724\n",
            "Average gradient: 0.0007546579\n",
            "Resources: CPU: 23.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2056...\n",
            "Number of non-padding tokens in tar_real: 1875\n",
            "Loss: 2.27636433\n",
            "Average gradient: 0.000770033745\n",
            "Resources: CPU: 24.2% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2057...\n",
            "Number of non-padding tokens in tar_real: 1827\n",
            "Loss: 2.25350666\n",
            "Average gradient: 0.000828398624\n",
            "Resources: CPU: 28.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2058...\n",
            "Number of non-padding tokens in tar_real: 1825\n",
            "Loss: 2.14800978\n",
            "Average gradient: 0.000743495533\n",
            "Resources: CPU: 24.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2059...\n",
            "Number of non-padding tokens in tar_real: 1880\n",
            "Loss: 2.23556828\n",
            "Average gradient: 0.000803856063\n",
            "Resources: CPU: 24.2% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2060...\n",
            "Number of non-padding tokens in tar_real: 1876\n",
            "Loss: 2.27380323\n",
            "Average gradient: 0.000799544039\n",
            "Resources: CPU: 24.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2061...\n",
            "Number of non-padding tokens in tar_real: 1747\n",
            "Loss: 2.39202166\n",
            "Average gradient: 0.000797424407\n",
            "Resources: CPU: 20.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2062...\n",
            "Number of non-padding tokens in tar_real: 1779\n",
            "Loss: 2.28131366\n",
            "Average gradient: 0.000732655404\n",
            "Resources: CPU: 22.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2063...\n",
            "Number of non-padding tokens in tar_real: 1826\n",
            "Loss: 2.29224348\n",
            "Average gradient: 0.000856532\n",
            "Resources: CPU: 19.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2064...\n",
            "Number of non-padding tokens in tar_real: 1866\n",
            "Loss: 2.32612419\n",
            "Average gradient: 0.000782614\n",
            "Resources: CPU: 26.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2065...\n",
            "Number of non-padding tokens in tar_real: 1759\n",
            "Loss: 2.0926373\n",
            "Average gradient: 0.00076326204\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2066...\n",
            "Number of non-padding tokens in tar_real: 1870\n",
            "Loss: 2.1684041\n",
            "Average gradient: 0.000826695061\n",
            "Resources: CPU: 15.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2067...\n",
            "Number of non-padding tokens in tar_real: 1870\n",
            "Loss: 2.24588299\n",
            "Average gradient: 0.000804383424\n",
            "Resources: CPU: 14.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2068...\n",
            "Number of non-padding tokens in tar_real: 1808\n",
            "Loss: 2.14275575\n",
            "Average gradient: 0.000780110364\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2069...\n",
            "Number of non-padding tokens in tar_real: 1865\n",
            "Loss: 2.21272635\n",
            "Average gradient: 0.000767368765\n",
            "Resources: CPU: 13.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2070...\n",
            "Number of non-padding tokens in tar_real: 1826\n",
            "Loss: 2.27317119\n",
            "Average gradient: 0.000876182632\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2071...\n",
            "Number of non-padding tokens in tar_real: 1910\n",
            "Loss: 2.33756924\n",
            "Average gradient: 0.000791530591\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2072...\n",
            "Number of non-padding tokens in tar_real: 1887\n",
            "Loss: 2.38369155\n",
            "Average gradient: 0.000797088956\n",
            "Resources: CPU: 12.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2073...\n",
            "Number of non-padding tokens in tar_real: 1804\n",
            "Loss: 2.40283489\n",
            "Average gradient: 0.000819011\n",
            "Resources: CPU: 14.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2074...\n",
            "Number of non-padding tokens in tar_real: 1814\n",
            "Loss: 2.15758181\n",
            "Average gradient: 0.000753000437\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2075...\n",
            "Number of non-padding tokens in tar_real: 1840\n",
            "Loss: 2.22848105\n",
            "Average gradient: 0.000811146863\n",
            "Resources: CPU: 14.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2076...\n",
            "Number of non-padding tokens in tar_real: 1812\n",
            "Loss: 2.15226579\n",
            "Average gradient: 0.000889888266\n",
            "Resources: CPU: 14.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2077...\n",
            "Number of non-padding tokens in tar_real: 1812\n",
            "Loss: 2.21985531\n",
            "Average gradient: 0.000863787252\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2078...\n",
            "Number of non-padding tokens in tar_real: 1806\n",
            "Loss: 2.2269423\n",
            "Average gradient: 0.00073169457\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2079...\n",
            "Number of non-padding tokens in tar_real: 1740\n",
            "Loss: 2.28078103\n",
            "Average gradient: 0.000785587705\n",
            "Resources: CPU: 11.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2080...\n",
            "Number of non-padding tokens in tar_real: 1839\n",
            "Loss: 2.25080705\n",
            "Average gradient: 0.000763319142\n",
            "Resources: CPU: 13.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2081...\n",
            "Number of non-padding tokens in tar_real: 1794\n",
            "Loss: 2.19002581\n",
            "Average gradient: 0.000782873423\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2082...\n",
            "Number of non-padding tokens in tar_real: 1866\n",
            "Loss: 2.29967761\n",
            "Average gradient: 0.000793855579\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2083...\n",
            "Number of non-padding tokens in tar_real: 1745\n",
            "Loss: 2.2175169\n",
            "Average gradient: 0.000750916544\n",
            "Resources: CPU: 13.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2084...\n",
            "Number of non-padding tokens in tar_real: 1772\n",
            "Loss: 2.23026371\n",
            "Average gradient: 0.000742389122\n",
            "Resources: CPU: 15.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2085...\n",
            "Number of non-padding tokens in tar_real: 1838\n",
            "Loss: 2.28666902\n",
            "Average gradient: 0.000873028708\n",
            "Resources: CPU: 15.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2086...\n",
            "Number of non-padding tokens in tar_real: 1721\n",
            "Loss: 2.21056747\n",
            "Average gradient: 0.000865488197\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2087...\n",
            "Number of non-padding tokens in tar_real: 1766\n",
            "Loss: 2.22761846\n",
            "Average gradient: 0.000818514964\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2088...\n",
            "Number of non-padding tokens in tar_real: 1796\n",
            "Loss: 2.25842023\n",
            "Average gradient: 0.000734421192\n",
            "Resources: CPU: 13.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2089...\n",
            "Number of non-padding tokens in tar_real: 1772\n",
            "Loss: 2.2135191\n",
            "Average gradient: 0.000781720155\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2090...\n",
            "Number of non-padding tokens in tar_real: 1782\n",
            "Loss: 2.30054808\n",
            "Average gradient: 0.000849585049\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2091...\n",
            "Number of non-padding tokens in tar_real: 1830\n",
            "Loss: 2.21189976\n",
            "Average gradient: 0.000796183827\n",
            "Resources: CPU: 14.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2092...\n",
            "Number of non-padding tokens in tar_real: 1860\n",
            "Loss: 2.25668883\n",
            "Average gradient: 0.000887147151\n",
            "Resources: CPU: 12.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2093...\n",
            "Number of non-padding tokens in tar_real: 1765\n",
            "Loss: 2.2063849\n",
            "Average gradient: 0.000801118324\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2094...\n",
            "Number of non-padding tokens in tar_real: 1834\n",
            "Loss: 2.18204021\n",
            "Average gradient: 0.000809477817\n",
            "Resources: CPU: 16.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2095...\n",
            "Number of non-padding tokens in tar_real: 1911\n",
            "Loss: 2.22491908\n",
            "Average gradient: 0.00076934573\n",
            "Resources: CPU: 13.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2096...\n",
            "Number of non-padding tokens in tar_real: 1847\n",
            "Loss: 2.24612856\n",
            "Average gradient: 0.000771907333\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2097...\n",
            "Number of non-padding tokens in tar_real: 1945\n",
            "Loss: 2.2548027\n",
            "Average gradient: 0.000814264407\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2098...\n",
            "Number of non-padding tokens in tar_real: 1769\n",
            "Loss: 2.32991409\n",
            "Average gradient: 0.000822885369\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2099...\n",
            "Number of non-padding tokens in tar_real: 1797\n",
            "Loss: 2.15200567\n",
            "Average gradient: 0.000890413707\n",
            "Resources: CPU: 10.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2100...\n",
            "Number of non-padding tokens in tar_real: 1788\n",
            "Loss: 2.40435934\n",
            "Average gradient: 0.000856125611\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2101...\n",
            "Number of non-padding tokens in tar_real: 1822\n",
            "Loss: 2.19360042\n",
            "Average gradient: 0.00089746929\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2102...\n",
            "Number of non-padding tokens in tar_real: 1829\n",
            "Loss: 2.23782158\n",
            "Average gradient: 0.000859636406\n",
            "Resources: CPU: 14.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2103...\n",
            "Number of non-padding tokens in tar_real: 1866\n",
            "Loss: 2.17491198\n",
            "Average gradient: 0.000825829164\n",
            "Resources: CPU: 16.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2104...\n",
            "Number of non-padding tokens in tar_real: 1780\n",
            "Loss: 2.16587043\n",
            "Average gradient: 0.000825125608\n",
            "Resources: CPU: 12.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2105...\n",
            "Number of non-padding tokens in tar_real: 1864\n",
            "Loss: 2.38572216\n",
            "Average gradient: 0.000895434176\n",
            "Resources: CPU: 14.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2106...\n",
            "Number of non-padding tokens in tar_real: 1820\n",
            "Loss: 2.25113583\n",
            "Average gradient: 0.000706891646\n",
            "Resources: CPU: 12.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2107...\n",
            "Number of non-padding tokens in tar_real: 1878\n",
            "Loss: 2.19262028\n",
            "Average gradient: 0.000796302571\n",
            "Resources: CPU: 12.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2108...\n",
            "Number of non-padding tokens in tar_real: 1798\n",
            "Loss: 2.22475839\n",
            "Average gradient: 0.000810815\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2109...\n",
            "Number of non-padding tokens in tar_real: 1776\n",
            "Loss: 2.26640868\n",
            "Average gradient: 0.000769342238\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2110...\n",
            "Number of non-padding tokens in tar_real: 1834\n",
            "Loss: 2.14324021\n",
            "Average gradient: 0.000766771\n",
            "Resources: CPU: 14.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2111...\n",
            "Number of non-padding tokens in tar_real: 1743\n",
            "Loss: 2.23427415\n",
            "Average gradient: 0.000852540135\n",
            "Resources: CPU: 12.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2112...\n",
            "Number of non-padding tokens in tar_real: 1806\n",
            "Loss: 2.24518633\n",
            "Average gradient: 0.000745612953\n",
            "Resources: CPU: 18.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2113...\n",
            "Number of non-padding tokens in tar_real: 1734\n",
            "Loss: 2.21958971\n",
            "Average gradient: 0.000849140342\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2114...\n",
            "Number of non-padding tokens in tar_real: 1890\n",
            "Loss: 2.43577671\n",
            "Average gradient: 0.000857615669\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2115...\n",
            "Number of non-padding tokens in tar_real: 1775\n",
            "Loss: 2.18313909\n",
            "Average gradient: 0.00077817135\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2116...\n",
            "Number of non-padding tokens in tar_real: 1960\n",
            "Loss: 2.32867336\n",
            "Average gradient: 0.000791599\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2117...\n",
            "Number of non-padding tokens in tar_real: 1793\n",
            "Loss: 2.13303328\n",
            "Average gradient: 0.000843674236\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2118...\n",
            "Number of non-padding tokens in tar_real: 1809\n",
            "Loss: 2.21677923\n",
            "Average gradient: 0.000834929466\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2119...\n",
            "Number of non-padding tokens in tar_real: 1823\n",
            "Loss: 2.20686889\n",
            "Average gradient: 0.000820048968\n",
            "Resources: CPU: 14.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2120...\n",
            "Number of non-padding tokens in tar_real: 1775\n",
            "Loss: 2.20106363\n",
            "Average gradient: 0.000849795295\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2121...\n",
            "Number of non-padding tokens in tar_real: 1769\n",
            "Loss: 2.33883786\n",
            "Average gradient: 0.00079609704\n",
            "Resources: CPU: 16.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2122...\n",
            "Number of non-padding tokens in tar_real: 1779\n",
            "Loss: 2.27779436\n",
            "Average gradient: 0.000814898929\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2123...\n",
            "Number of non-padding tokens in tar_real: 1824\n",
            "Loss: 2.24341536\n",
            "Average gradient: 0.000856313622\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2124...\n",
            "Number of non-padding tokens in tar_real: 1772\n",
            "Loss: 2.14659381\n",
            "Average gradient: 0.00086881587\n",
            "Resources: CPU: 11.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2125...\n",
            "Number of non-padding tokens in tar_real: 1783\n",
            "Loss: 2.42855859\n",
            "Average gradient: 0.000906241592\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2126...\n",
            "Number of non-padding tokens in tar_real: 1863\n",
            "Loss: 2.34509635\n",
            "Average gradient: 0.000818281551\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2127...\n",
            "Number of non-padding tokens in tar_real: 1824\n",
            "Loss: 2.15764856\n",
            "Average gradient: 0.00082771841\n",
            "Resources: CPU: 10.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2128...\n",
            "Number of non-padding tokens in tar_real: 1802\n",
            "Loss: 2.25752497\n",
            "Average gradient: 0.000875828147\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2129...\n",
            "Number of non-padding tokens in tar_real: 1754\n",
            "Loss: 2.02971077\n",
            "Average gradient: 0.00077362929\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2130...\n",
            "Number of non-padding tokens in tar_real: 1779\n",
            "Loss: 2.09148717\n",
            "Average gradient: 0.000761258241\n",
            "Resources: CPU: 15.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2131...\n",
            "Number of non-padding tokens in tar_real: 1741\n",
            "Loss: 2.2122941\n",
            "Average gradient: 0.000840663095\n",
            "Resources: CPU: 16.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2132...\n",
            "Number of non-padding tokens in tar_real: 1736\n",
            "Loss: 2.22406197\n",
            "Average gradient: 0.00075879076\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2133...\n",
            "Number of non-padding tokens in tar_real: 1861\n",
            "Loss: 2.34989572\n",
            "Average gradient: 0.000805318647\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2134...\n",
            "Number of non-padding tokens in tar_real: 1859\n",
            "Loss: 2.31898022\n",
            "Average gradient: 0.000747262209\n",
            "Resources: CPU: 12.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2135...\n",
            "Number of non-padding tokens in tar_real: 1611\n",
            "Loss: 2.13211393\n",
            "Average gradient: 0.000807209115\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2136...\n",
            "Number of non-padding tokens in tar_real: 1829\n",
            "Loss: 2.17025113\n",
            "Average gradient: 0.000836572552\n",
            "Resources: CPU: 11.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2137...\n",
            "Number of non-padding tokens in tar_real: 1803\n",
            "Loss: 2.28862667\n",
            "Average gradient: 0.000779909955\n",
            "Resources: CPU: 13.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 57.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2138...\n",
            "Number of non-padding tokens in tar_real: 1874\n",
            "Loss: 2.26290655\n",
            "Average gradient: 0.000734396861\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 57.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2139...\n",
            "Number of non-padding tokens in tar_real: 1835\n",
            "Loss: 2.1706202\n",
            "Average gradient: 0.000846994284\n",
            "Resources: CPU: 16.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2140...\n",
            "Number of non-padding tokens in tar_real: 1858\n",
            "Loss: 2.20329976\n",
            "Average gradient: 0.000772119674\n",
            "Resources: CPU: 14.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2141...\n",
            "Number of non-padding tokens in tar_real: 1955\n",
            "Loss: 2.27952266\n",
            "Average gradient: 0.000711605884\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2142...\n",
            "Number of non-padding tokens in tar_real: 1810\n",
            "Loss: 2.38185525\n",
            "Average gradient: 0.000811577\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2143...\n",
            "Number of non-padding tokens in tar_real: 1776\n",
            "Loss: 2.23235774\n",
            "Average gradient: 0.000841038418\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2144...\n",
            "Number of non-padding tokens in tar_real: 1796\n",
            "Loss: 2.21771741\n",
            "Average gradient: 0.000768127094\n",
            "Resources: CPU: 12.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2145...\n",
            "Number of non-padding tokens in tar_real: 1875\n",
            "Loss: 2.24401474\n",
            "Average gradient: 0.000735311245\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2146...\n",
            "Number of non-padding tokens in tar_real: 1932\n",
            "Loss: 2.18815112\n",
            "Average gradient: 0.000801842893\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2147...\n",
            "Number of non-padding tokens in tar_real: 1692\n",
            "Loss: 2.13992\n",
            "Average gradient: 0.000824010582\n",
            "Resources: CPU: 13.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2148...\n",
            "Number of non-padding tokens in tar_real: 1738\n",
            "Loss: 2.05308127\n",
            "Average gradient: 0.000791471335\n",
            "Resources: CPU: 15.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2149...\n",
            "Number of non-padding tokens in tar_real: 1923\n",
            "Loss: 2.31965446\n",
            "Average gradient: 0.000769092876\n",
            "Resources: CPU: 14.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2150...\n",
            "Number of non-padding tokens in tar_real: 1794\n",
            "Loss: 2.33563805\n",
            "Average gradient: 0.000892849755\n",
            "Resources: CPU: 12.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2151...\n",
            "Number of non-padding tokens in tar_real: 1726\n",
            "Loss: 2.28586245\n",
            "Average gradient: 0.000924424035\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2152...\n",
            "Number of non-padding tokens in tar_real: 1762\n",
            "Loss: 2.24110651\n",
            "Average gradient: 0.000837858533\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2153...\n",
            "Number of non-padding tokens in tar_real: 1864\n",
            "Loss: 2.28883529\n",
            "Average gradient: 0.00077223673\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2154...\n",
            "Number of non-padding tokens in tar_real: 1762\n",
            "Loss: 2.26792645\n",
            "Average gradient: 0.000831933285\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2155...\n",
            "Number of non-padding tokens in tar_real: 1959\n",
            "Loss: 2.22930241\n",
            "Average gradient: 0.000747220125\n",
            "Resources: CPU: 14.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 56.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2156...\n",
            "Number of non-padding tokens in tar_real: 1880\n",
            "Loss: 2.29174018\n",
            "Average gradient: 0.000759153336\n",
            "Resources: CPU: 23.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 56.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2157...\n",
            "Number of non-padding tokens in tar_real: 1890\n",
            "Loss: 2.24663067\n",
            "Average gradient: 0.000849134696\n",
            "Resources: CPU: 25.9% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 57.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2158...\n",
            "Number of non-padding tokens in tar_real: 1807\n",
            "Loss: 2.20921183\n",
            "Average gradient: 0.000912913936\n",
            "Resources: CPU: 24.4% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 57.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2159...\n",
            "Number of non-padding tokens in tar_real: 1823\n",
            "Loss: 2.35489845\n",
            "Average gradient: 0.000793358427\n",
            "Resources: CPU: 21.4% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2160...\n",
            "Number of non-padding tokens in tar_real: 1721\n",
            "Loss: 2.13020921\n",
            "Average gradient: 0.000740983291\n",
            "Resources: CPU: 21.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2161...\n",
            "Number of non-padding tokens in tar_real: 1831\n",
            "Loss: 2.19799376\n",
            "Average gradient: 0.00086273544\n",
            "Resources: CPU: 25.4% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2162...\n",
            "Number of non-padding tokens in tar_real: 1913\n",
            "Loss: 2.20440483\n",
            "Average gradient: 0.000795115076\n",
            "Resources: CPU: 28.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2163...\n",
            "Number of non-padding tokens in tar_real: 1814\n",
            "Loss: 2.24928951\n",
            "Average gradient: 0.000867022143\n",
            "Resources: CPU: 23.9% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2164...\n",
            "Number of non-padding tokens in tar_real: 1970\n",
            "Loss: 2.39700937\n",
            "Average gradient: 0.00081527885\n",
            "Resources: CPU: 20.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2165...\n",
            "Number of non-padding tokens in tar_real: 1848\n",
            "Loss: 2.407866\n",
            "Average gradient: 0.000805585121\n",
            "Resources: CPU: 23.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2166...\n",
            "Number of non-padding tokens in tar_real: 1775\n",
            "Loss: 2.09111476\n",
            "Average gradient: 0.00082048669\n",
            "Resources: CPU: 23.9% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2167...\n",
            "Number of non-padding tokens in tar_real: 1836\n",
            "Loss: 2.31402469\n",
            "Average gradient: 0.000822288799\n",
            "Resources: CPU: 22.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2168...\n",
            "Number of non-padding tokens in tar_real: 1894\n",
            "Loss: 2.11500525\n",
            "Average gradient: 0.000910833362\n",
            "Resources: CPU: 22.5% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2169...\n",
            "Number of non-padding tokens in tar_real: 1770\n",
            "Loss: 2.21530461\n",
            "Average gradient: 0.000817165244\n",
            "Resources: CPU: 22.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2170...\n",
            "Number of non-padding tokens in tar_real: 1772\n",
            "Loss: 2.34040451\n",
            "Average gradient: 0.000826704258\n",
            "Resources: CPU: 22.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2171...\n",
            "Number of non-padding tokens in tar_real: 1836\n",
            "Loss: 2.24584365\n",
            "Average gradient: 0.000860196189\n",
            "Resources: CPU: 21.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2172...\n",
            "Number of non-padding tokens in tar_real: 1833\n",
            "Loss: 2.23492432\n",
            "Average gradient: 0.000842749956\n",
            "Resources: CPU: 24.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2173...\n",
            "Number of non-padding tokens in tar_real: 1849\n",
            "Loss: 2.3098433\n",
            "Average gradient: 0.000793918909\n",
            "Resources: CPU: 23.5% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2174...\n",
            "Number of non-padding tokens in tar_real: 1812\n",
            "Loss: 2.25704622\n",
            "Average gradient: 0.000757890055\n",
            "Resources: CPU: 23.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2175...\n",
            "Number of non-padding tokens in tar_real: 1707\n",
            "Loss: 2.16366768\n",
            "Average gradient: 0.000851924124\n",
            "Resources: CPU: 25.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 57.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2176...\n",
            "Number of non-padding tokens in tar_real: 1798\n",
            "Loss: 2.12158728\n",
            "Average gradient: 0.000816918211\n",
            "Resources: CPU: 22.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 57.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2177...\n",
            "Number of non-padding tokens in tar_real: 1812\n",
            "Loss: 2.24238944\n",
            "Average gradient: 0.000810977246\n",
            "Resources: CPU: 23.5% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2178...\n",
            "Number of non-padding tokens in tar_real: 1823\n",
            "Loss: 2.12710547\n",
            "Average gradient: 0.000832948252\n",
            "Resources: CPU: 22.0% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2179...\n",
            "Number of non-padding tokens in tar_real: 1838\n",
            "Loss: 2.12403584\n",
            "Average gradient: 0.000804875512\n",
            "Resources: CPU: 21.4% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2180...\n",
            "Number of non-padding tokens in tar_real: 1824\n",
            "Loss: 2.24404931\n",
            "Average gradient: 0.000799649337\n",
            "Resources: CPU: 20.0% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2181...\n",
            "Number of non-padding tokens in tar_real: 1816\n",
            "Loss: 2.32122946\n",
            "Average gradient: 0.000790644146\n",
            "Resources: CPU: 13.0% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2182...\n",
            "Number of non-padding tokens in tar_real: 1902\n",
            "Loss: 2.37891936\n",
            "Average gradient: 0.000772730156\n",
            "Resources: CPU: 12.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2183...\n",
            "Number of non-padding tokens in tar_real: 1800\n",
            "Loss: 2.24345589\n",
            "Average gradient: 0.000799735542\n",
            "Resources: CPU: 14.9% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2184...\n",
            "Number of non-padding tokens in tar_real: 1843\n",
            "Loss: 2.21760631\n",
            "Average gradient: 0.000768782862\n",
            "Resources: CPU: 16.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2185...\n",
            "Number of non-padding tokens in tar_real: 1840\n",
            "Loss: 2.25310254\n",
            "Average gradient: 0.000819262408\n",
            "Resources: CPU: 11.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2186...\n",
            "Number of non-padding tokens in tar_real: 1830\n",
            "Loss: 2.14659715\n",
            "Average gradient: 0.000744534831\n",
            "Resources: CPU: 14.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2187...\n",
            "Number of non-padding tokens in tar_real: 1807\n",
            "Loss: 2.1621685\n",
            "Average gradient: 0.00080188096\n",
            "Resources: CPU: 12.9% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2188...\n",
            "Number of non-padding tokens in tar_real: 1838\n",
            "Loss: 2.34912348\n",
            "Average gradient: 0.000851082616\n",
            "Resources: CPU: 11.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2189...\n",
            "Number of non-padding tokens in tar_real: 1755\n",
            "Loss: 2.2046628\n",
            "Average gradient: 0.000820635352\n",
            "Resources: CPU: 14.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2190...\n",
            "Number of non-padding tokens in tar_real: 1915\n",
            "Loss: 2.34657311\n",
            "Average gradient: 0.000856794417\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2191...\n",
            "Number of non-padding tokens in tar_real: 1799\n",
            "Loss: 2.14670515\n",
            "Average gradient: 0.000735036912\n",
            "Resources: CPU: 14.4% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2192...\n",
            "Number of non-padding tokens in tar_real: 1748\n",
            "Loss: 2.13449693\n",
            "Average gradient: 0.000780340633\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2193...\n",
            "Number of non-padding tokens in tar_real: 1845\n",
            "Loss: 2.24819088\n",
            "Average gradient: 0.000845468487\n",
            "Resources: CPU: 15.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2194...\n",
            "Number of non-padding tokens in tar_real: 1745\n",
            "Loss: 2.31510973\n",
            "Average gradient: 0.00088642\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2195...\n",
            "Number of non-padding tokens in tar_real: 1849\n",
            "Loss: 2.25990081\n",
            "Average gradient: 0.000805778545\n",
            "Resources: CPU: 14.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2196...\n",
            "Number of non-padding tokens in tar_real: 1791\n",
            "Loss: 2.15588927\n",
            "Average gradient: 0.000763265649\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2197...\n",
            "Number of non-padding tokens in tar_real: 1795\n",
            "Loss: 2.34900546\n",
            "Average gradient: 0.000848380034\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2198...\n",
            "Number of non-padding tokens in tar_real: 1885\n",
            "Loss: 2.24215102\n",
            "Average gradient: 0.000771024672\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2199...\n",
            "Number of non-padding tokens in tar_real: 1768\n",
            "Loss: 2.19762635\n",
            "Average gradient: 0.000804040872\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2200...\n",
            "Number of non-padding tokens in tar_real: 1846\n",
            "Loss: 2.33748484\n",
            "Average gradient: 0.000803866773\n",
            "Resources: CPU: 13.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2201...\n",
            "Number of non-padding tokens in tar_real: 1777\n",
            "Loss: 2.17215753\n",
            "Average gradient: 0.000777501496\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2202...\n",
            "Number of non-padding tokens in tar_real: 1834\n",
            "Loss: 2.25156355\n",
            "Average gradient: 0.000823365292\n",
            "Resources: CPU: 15.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2203...\n",
            "Number of non-padding tokens in tar_real: 1778\n",
            "Loss: 2.24006081\n",
            "Average gradient: 0.000781585812\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2204...\n",
            "Number of non-padding tokens in tar_real: 1681\n",
            "Loss: 2.08629\n",
            "Average gradient: 0.000780765957\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2205...\n",
            "Number of non-padding tokens in tar_real: 1808\n",
            "Loss: 2.17239571\n",
            "Average gradient: 0.000744656485\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2206...\n",
            "Number of non-padding tokens in tar_real: 1812\n",
            "Loss: 2.26480746\n",
            "Average gradient: 0.000823171693\n",
            "Resources: CPU: 14.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2207...\n",
            "Number of non-padding tokens in tar_real: 1781\n",
            "Loss: 2.16112804\n",
            "Average gradient: 0.000889509218\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2208...\n",
            "Number of non-padding tokens in tar_real: 1774\n",
            "Loss: 2.10348296\n",
            "Average gradient: 0.000778653077\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2209...\n",
            "Number of non-padding tokens in tar_real: 1849\n",
            "Loss: 2.27925849\n",
            "Average gradient: 0.000811353966\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2210...\n",
            "Number of non-padding tokens in tar_real: 1870\n",
            "Loss: 2.2413075\n",
            "Average gradient: 0.00071773387\n",
            "Resources: CPU: 13.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2211...\n",
            "Number of non-padding tokens in tar_real: 1740\n",
            "Loss: 2.25500059\n",
            "Average gradient: 0.000847851741\n",
            "Resources: CPU: 15.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2212...\n",
            "Number of non-padding tokens in tar_real: 1898\n",
            "Loss: 2.32770538\n",
            "Average gradient: 0.000754711742\n",
            "Resources: CPU: 14.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2213...\n",
            "Number of non-padding tokens in tar_real: 1863\n",
            "Loss: 2.24940038\n",
            "Average gradient: 0.000826671\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2214...\n",
            "Number of non-padding tokens in tar_real: 1796\n",
            "Loss: 2.07682037\n",
            "Average gradient: 0.000777307432\n",
            "Resources: CPU: 16.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2215...\n",
            "Number of non-padding tokens in tar_real: 1877\n",
            "Loss: 2.31193948\n",
            "Average gradient: 0.000790239952\n",
            "Resources: CPU: 13.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2216...\n",
            "Number of non-padding tokens in tar_real: 1774\n",
            "Loss: 2.14158368\n",
            "Average gradient: 0.000738328032\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2217...\n",
            "Number of non-padding tokens in tar_real: 1760\n",
            "Loss: 2.33657217\n",
            "Average gradient: 0.000809059944\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2218...\n",
            "Number of non-padding tokens in tar_real: 1791\n",
            "Loss: 2.11146069\n",
            "Average gradient: 0.000752478954\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2219...\n",
            "Number of non-padding tokens in tar_real: 1865\n",
            "Loss: 2.17018032\n",
            "Average gradient: 0.000830732693\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2220...\n",
            "Number of non-padding tokens in tar_real: 1868\n",
            "Loss: 2.28189945\n",
            "Average gradient: 0.000803697912\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2221...\n",
            "Number of non-padding tokens in tar_real: 1754\n",
            "Loss: 2.29258776\n",
            "Average gradient: 0.000766404\n",
            "Resources: CPU: 15.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2222...\n",
            "Number of non-padding tokens in tar_real: 1817\n",
            "Loss: 2.27671766\n",
            "Average gradient: 0.000874620571\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2223...\n",
            "Number of non-padding tokens in tar_real: 1859\n",
            "Loss: 2.19195294\n",
            "Average gradient: 0.000754190376\n",
            "Resources: CPU: 18.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2224...\n",
            "Number of non-padding tokens in tar_real: 1880\n",
            "Loss: 2.3359468\n",
            "Average gradient: 0.000775064167\n",
            "Resources: CPU: 10.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2225...\n",
            "Number of non-padding tokens in tar_real: 1847\n",
            "Loss: 2.3245194\n",
            "Average gradient: 0.000907742069\n",
            "Resources: CPU: 13.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2226...\n",
            "Number of non-padding tokens in tar_real: 1789\n",
            "Loss: 2.32273936\n",
            "Average gradient: 0.00082039315\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2227...\n",
            "Number of non-padding tokens in tar_real: 1853\n",
            "Loss: 2.3351655\n",
            "Average gradient: 0.000790593855\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2228...\n",
            "Number of non-padding tokens in tar_real: 1910\n",
            "Loss: 2.32525206\n",
            "Average gradient: 0.000764860772\n",
            "Resources: CPU: 13.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2229...\n",
            "Number of non-padding tokens in tar_real: 1767\n",
            "Loss: 2.20511055\n",
            "Average gradient: 0.000750730105\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2230...\n",
            "Number of non-padding tokens in tar_real: 1747\n",
            "Loss: 2.14744878\n",
            "Average gradient: 0.000755354064\n",
            "Resources: CPU: 15.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2231...\n",
            "Number of non-padding tokens in tar_real: 1860\n",
            "Loss: 2.36855\n",
            "Average gradient: 0.000766054727\n",
            "Resources: CPU: 11.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2232...\n",
            "Number of non-padding tokens in tar_real: 1821\n",
            "Loss: 2.24254203\n",
            "Average gradient: 0.000818408094\n",
            "Resources: CPU: 14.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2233...\n",
            "Number of non-padding tokens in tar_real: 1800\n",
            "Loss: 2.0999558\n",
            "Average gradient: 0.000858924061\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2234...\n",
            "Number of non-padding tokens in tar_real: 1731\n",
            "Loss: 2.12754512\n",
            "Average gradient: 0.000818105647\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2235...\n",
            "Number of non-padding tokens in tar_real: 1784\n",
            "Loss: 2.24428988\n",
            "Average gradient: 0.00088380184\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2236...\n",
            "Number of non-padding tokens in tar_real: 1692\n",
            "Loss: 2.15217781\n",
            "Average gradient: 0.000810952915\n",
            "Resources: CPU: 11.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2237...\n",
            "Number of non-padding tokens in tar_real: 1742\n",
            "Loss: 2.13044071\n",
            "Average gradient: 0.000821623602\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2238...\n",
            "Number of non-padding tokens in tar_real: 1769\n",
            "Loss: 2.1500926\n",
            "Average gradient: 0.000747199112\n",
            "Resources: CPU: 12.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2239...\n",
            "Number of non-padding tokens in tar_real: 1806\n",
            "Loss: 2.39085674\n",
            "Average gradient: 0.000802407216\n",
            "Resources: CPU: 14.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2240...\n",
            "Number of non-padding tokens in tar_real: 1833\n",
            "Loss: 2.32008362\n",
            "Average gradient: 0.000766149373\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2241...\n",
            "Number of non-padding tokens in tar_real: 1892\n",
            "Loss: 2.39280581\n",
            "Average gradient: 0.000798360154\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2242...\n",
            "Number of non-padding tokens in tar_real: 1928\n",
            "Loss: 2.38292646\n",
            "Average gradient: 0.000825576193\n",
            "Resources: CPU: 14.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2243...\n",
            "Number of non-padding tokens in tar_real: 1832\n",
            "Loss: 2.24007654\n",
            "Average gradient: 0.000694804359\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2244...\n",
            "Number of non-padding tokens in tar_real: 1802\n",
            "Loss: 2.12402391\n",
            "Average gradient: 0.000833871658\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2245...\n",
            "Number of non-padding tokens in tar_real: 1812\n",
            "Loss: 2.14304852\n",
            "Average gradient: 0.000744881923\n",
            "Resources: CPU: 12.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2246...\n",
            "Number of non-padding tokens in tar_real: 1856\n",
            "Loss: 2.13653636\n",
            "Average gradient: 0.000708800857\n",
            "Resources: CPU: 13.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2247...\n",
            "Number of non-padding tokens in tar_real: 1812\n",
            "Loss: 2.04463816\n",
            "Average gradient: 0.000756144524\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2248...\n",
            "Number of non-padding tokens in tar_real: 1774\n",
            "Loss: 2.35889912\n",
            "Average gradient: 0.000819665147\n",
            "Resources: CPU: 15.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2249...\n",
            "Number of non-padding tokens in tar_real: 1786\n",
            "Loss: 2.08536148\n",
            "Average gradient: 0.000800909\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2250...\n",
            "Number of non-padding tokens in tar_real: 1926\n",
            "Loss: 2.32468224\n",
            "Average gradient: 0.000836789259\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2251...\n",
            "Number of non-padding tokens in tar_real: 1753\n",
            "Loss: 2.30379415\n",
            "Average gradient: 0.000828653283\n",
            "Resources: CPU: 14.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2252...\n",
            "Number of non-padding tokens in tar_real: 1762\n",
            "Loss: 2.19222331\n",
            "Average gradient: 0.000857533421\n",
            "Resources: CPU: 12.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2253...\n",
            "Number of non-padding tokens in tar_real: 1821\n",
            "Loss: 2.35257816\n",
            "Average gradient: 0.00083484326\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2254...\n",
            "Number of non-padding tokens in tar_real: 1807\n",
            "Loss: 2.31415939\n",
            "Average gradient: 0.000790067133\n",
            "Resources: CPU: 11.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2255...\n",
            "Number of non-padding tokens in tar_real: 1883\n",
            "Loss: 2.26335883\n",
            "Average gradient: 0.000804052688\n",
            "Resources: CPU: 14.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2256...\n",
            "Number of non-padding tokens in tar_real: 1804\n",
            "Loss: 2.13041115\n",
            "Average gradient: 0.000770988525\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2257...\n",
            "Number of non-padding tokens in tar_real: 1770\n",
            "Loss: 2.17027283\n",
            "Average gradient: 0.000797040877\n",
            "Resources: CPU: 17.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2258...\n",
            "Number of non-padding tokens in tar_real: 1832\n",
            "Loss: 2.35903525\n",
            "Average gradient: 0.000791955856\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2259...\n",
            "Number of non-padding tokens in tar_real: 1874\n",
            "Loss: 2.45172572\n",
            "Average gradient: 0.00078594638\n",
            "Resources: CPU: 12.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2260...\n",
            "Number of non-padding tokens in tar_real: 1829\n",
            "Loss: 2.2844286\n",
            "Average gradient: 0.000835512474\n",
            "Resources: CPU: 14.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2261...\n",
            "Number of non-padding tokens in tar_real: 1804\n",
            "Loss: 2.29182172\n",
            "Average gradient: 0.000796598499\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2262...\n",
            "Number of non-padding tokens in tar_real: 1738\n",
            "Loss: 2.32161689\n",
            "Average gradient: 0.000912391464\n",
            "Resources: CPU: 13.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2263...\n",
            "Number of non-padding tokens in tar_real: 1829\n",
            "Loss: 2.32947969\n",
            "Average gradient: 0.000845102826\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2264...\n",
            "Number of non-padding tokens in tar_real: 1825\n",
            "Loss: 2.26192307\n",
            "Average gradient: 0.000738376111\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2265...\n",
            "Number of non-padding tokens in tar_real: 1737\n",
            "Loss: 2.23977637\n",
            "Average gradient: 0.000827130105\n",
            "Resources: CPU: 14.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2266...\n",
            "Number of non-padding tokens in tar_real: 1802\n",
            "Loss: 2.25084877\n",
            "Average gradient: 0.000763649412\n",
            "Resources: CPU: 16.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2267...\n",
            "Number of non-padding tokens in tar_real: 1758\n",
            "Loss: 2.21536016\n",
            "Average gradient: 0.000848729222\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2268...\n",
            "Number of non-padding tokens in tar_real: 1787\n",
            "Loss: 2.31555557\n",
            "Average gradient: 0.00083555514\n",
            "Resources: CPU: 12.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2269...\n",
            "Number of non-padding tokens in tar_real: 1833\n",
            "Loss: 2.12200809\n",
            "Average gradient: 0.000796175096\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2270...\n",
            "Number of non-padding tokens in tar_real: 1734\n",
            "Loss: 2.13929272\n",
            "Average gradient: 0.000815824256\n",
            "Resources: CPU: 14.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2271...\n",
            "Number of non-padding tokens in tar_real: 1809\n",
            "Loss: 2.21597171\n",
            "Average gradient: 0.000727014965\n",
            "Resources: CPU: 14.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2272...\n",
            "Number of non-padding tokens in tar_real: 1683\n",
            "Loss: 2.16221023\n",
            "Average gradient: 0.000818789704\n",
            "Resources: CPU: 24.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2273...\n",
            "Number of non-padding tokens in tar_real: 1854\n",
            "Loss: 2.40506124\n",
            "Average gradient: 0.00081972609\n",
            "Resources: CPU: 20.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2274...\n",
            "Number of non-padding tokens in tar_real: 1841\n",
            "Loss: 2.17850757\n",
            "Average gradient: 0.00083725556\n",
            "Resources: CPU: 24.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2275...\n",
            "Number of non-padding tokens in tar_real: 1834\n",
            "Loss: 2.18829799\n",
            "Average gradient: 0.000809130201\n",
            "Resources: CPU: 23.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2276...\n",
            "Number of non-padding tokens in tar_real: 1824\n",
            "Loss: 2.14878678\n",
            "Average gradient: 0.000785396609\n",
            "Resources: CPU: 20.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2277...\n",
            "Number of non-padding tokens in tar_real: 1863\n",
            "Loss: 2.40823269\n",
            "Average gradient: 0.000844530936\n",
            "Resources: CPU: 23.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2278...\n",
            "Number of non-padding tokens in tar_real: 1838\n",
            "Loss: 2.29986787\n",
            "Average gradient: 0.000722371449\n",
            "Resources: CPU: 23.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2279...\n",
            "Number of non-padding tokens in tar_real: 1808\n",
            "Loss: 2.17152357\n",
            "Average gradient: 0.000781343784\n",
            "Resources: CPU: 25.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 57.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2280...\n",
            "Number of non-padding tokens in tar_real: 1759\n",
            "Loss: 2.09044194\n",
            "Average gradient: 0.00090021675\n",
            "Resources: CPU: 20.0% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 57.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2281...\n",
            "Number of non-padding tokens in tar_real: 1850\n",
            "Loss: 2.21697712\n",
            "Average gradient: 0.000772801228\n",
            "Resources: CPU: 22.4% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2282...\n",
            "Number of non-padding tokens in tar_real: 1798\n",
            "Loss: 2.26354265\n",
            "Average gradient: 0.000875877333\n",
            "Resources: CPU: 23.0% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2283...\n",
            "Number of non-padding tokens in tar_real: 1811\n",
            "Loss: 2.42020178\n",
            "Average gradient: 0.00082311267\n",
            "Resources: CPU: 21.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2284...\n",
            "Number of non-padding tokens in tar_real: 1730\n",
            "Loss: 2.30520844\n",
            "Average gradient: 0.000882023713\n",
            "Resources: CPU: 22.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2285...\n",
            "Number of non-padding tokens in tar_real: 1749\n",
            "Loss: 2.203897\n",
            "Average gradient: 0.000734370667\n",
            "Resources: CPU: 21.2% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2286...\n",
            "Number of non-padding tokens in tar_real: 1819\n",
            "Loss: 2.33823943\n",
            "Average gradient: 0.000804611482\n",
            "Resources: CPU: 22.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2287...\n",
            "Number of non-padding tokens in tar_real: 1770\n",
            "Loss: 2.24806905\n",
            "Average gradient: 0.000766109617\n",
            "Resources: CPU: 22.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2288...\n",
            "Number of non-padding tokens in tar_real: 1762\n",
            "Loss: 2.2401731\n",
            "Average gradient: 0.000801900576\n",
            "Resources: CPU: 25.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2289...\n",
            "Number of non-padding tokens in tar_real: 1865\n",
            "Loss: 2.26135421\n",
            "Average gradient: 0.000748380146\n",
            "Resources: CPU: 22.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2290...\n",
            "Number of non-padding tokens in tar_real: 1685\n",
            "Loss: 2.19607472\n",
            "Average gradient: 0.00093915\n",
            "Resources: CPU: 23.5% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2291...\n",
            "Number of non-padding tokens in tar_real: 1843\n",
            "Loss: 2.15334678\n",
            "Average gradient: 0.000796310604\n",
            "Resources: CPU: 23.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2292...\n",
            "Number of non-padding tokens in tar_real: 1869\n",
            "Loss: 2.23480082\n",
            "Average gradient: 0.000874011312\n",
            "Resources: CPU: 24.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2293...\n",
            "Number of non-padding tokens in tar_real: 1728\n",
            "Loss: 2.41464281\n",
            "Average gradient: 0.000754043\n",
            "Resources: CPU: 23.5% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2294...\n",
            "Number of non-padding tokens in tar_real: 1831\n",
            "Loss: 2.35532045\n",
            "Average gradient: 0.000753974367\n",
            "Resources: CPU: 22.4% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2295...\n",
            "Number of non-padding tokens in tar_real: 1820\n",
            "Loss: 2.3118155\n",
            "Average gradient: 0.000839537708\n",
            "Resources: CPU: 22.2% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2296...\n",
            "Number of non-padding tokens in tar_real: 1730\n",
            "Loss: 2.20853257\n",
            "Average gradient: 0.000853318721\n",
            "Resources: CPU: 19.9% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2297...\n",
            "Number of non-padding tokens in tar_real: 1924\n",
            "Loss: 2.30543065\n",
            "Average gradient: 0.000755365705\n",
            "Resources: CPU: 15.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 57.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2298...\n",
            "Number of non-padding tokens in tar_real: 1853\n",
            "Loss: 2.29449558\n",
            "Average gradient: 0.000737076625\n",
            "Resources: CPU: 13.5% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 57.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2299...\n",
            "Number of non-padding tokens in tar_real: 1802\n",
            "Loss: 2.15316606\n",
            "Average gradient: 0.000724107609\n",
            "Resources: CPU: 11.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2300...\n",
            "Number of non-padding tokens in tar_real: 1736\n",
            "Loss: 2.10956883\n",
            "Average gradient: 0.000800346199\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2301...\n",
            "Number of non-padding tokens in tar_real: 1711\n",
            "Loss: 2.06939316\n",
            "Average gradient: 0.000731720764\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2302...\n",
            "Number of non-padding tokens in tar_real: 1763\n",
            "Loss: 2.2416718\n",
            "Average gradient: 0.000780937728\n",
            "Resources: CPU: 15.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2303...\n",
            "Number of non-padding tokens in tar_real: 1846\n",
            "Loss: 2.43749785\n",
            "Average gradient: 0.000851737859\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2304...\n",
            "Number of non-padding tokens in tar_real: 1819\n",
            "Loss: 2.22331738\n",
            "Average gradient: 0.000821703463\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2305...\n",
            "Number of non-padding tokens in tar_real: 1796\n",
            "Loss: 2.2639792\n",
            "Average gradient: 0.000793335901\n",
            "Resources: CPU: 14.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2306...\n",
            "Number of non-padding tokens in tar_real: 1770\n",
            "Loss: 2.17282653\n",
            "Average gradient: 0.000772836618\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2307...\n",
            "Number of non-padding tokens in tar_real: 1868\n",
            "Loss: 2.13391685\n",
            "Average gradient: 0.000776511733\n",
            "Resources: CPU: 13.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2308...\n",
            "Number of non-padding tokens in tar_real: 1769\n",
            "Loss: 2.18589091\n",
            "Average gradient: 0.000684810744\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2309...\n",
            "Number of non-padding tokens in tar_real: 1888\n",
            "Loss: 2.26563025\n",
            "Average gradient: 0.000803232891\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2310...\n",
            "Number of non-padding tokens in tar_real: 1735\n",
            "Loss: 2.26427627\n",
            "Average gradient: 0.000864811242\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2311...\n",
            "Number of non-padding tokens in tar_real: 1901\n",
            "Loss: 2.19040823\n",
            "Average gradient: 0.000765398203\n",
            "Resources: CPU: 15.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2312...\n",
            "Number of non-padding tokens in tar_real: 1736\n",
            "Loss: 2.23585367\n",
            "Average gradient: 0.000828496588\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2313...\n",
            "Number of non-padding tokens in tar_real: 1832\n",
            "Loss: 2.23373747\n",
            "Average gradient: 0.000767186109\n",
            "Resources: CPU: 10.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2314...\n",
            "Number of non-padding tokens in tar_real: 1798\n",
            "Loss: 2.18552685\n",
            "Average gradient: 0.000823090901\n",
            "Resources: CPU: 13.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2315...\n",
            "Number of non-padding tokens in tar_real: 1864\n",
            "Loss: 2.29147553\n",
            "Average gradient: 0.000917855825\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2316...\n",
            "Number of non-padding tokens in tar_real: 1772\n",
            "Loss: 2.37998247\n",
            "Average gradient: 0.000815807725\n",
            "Resources: CPU: 14.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2317...\n",
            "Number of non-padding tokens in tar_real: 1773\n",
            "Loss: 2.21612859\n",
            "Average gradient: 0.000918710779\n",
            "Resources: CPU: 12.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2318...\n",
            "Number of non-padding tokens in tar_real: 1887\n",
            "Loss: 2.31186438\n",
            "Average gradient: 0.000767961435\n",
            "Resources: CPU: 12.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2319...\n",
            "Number of non-padding tokens in tar_real: 1804\n",
            "Loss: 2.26647806\n",
            "Average gradient: 0.000830022851\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2320...\n",
            "Number of non-padding tokens in tar_real: 1769\n",
            "Loss: 2.20755029\n",
            "Average gradient: 0.00082246121\n",
            "Resources: CPU: 15.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2321...\n",
            "Number of non-padding tokens in tar_real: 1727\n",
            "Loss: 2.2013998\n",
            "Average gradient: 0.000758178532\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2322...\n",
            "Number of non-padding tokens in tar_real: 1751\n",
            "Loss: 2.24077988\n",
            "Average gradient: 0.000743225915\n",
            "Resources: CPU: 12.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2323...\n",
            "Number of non-padding tokens in tar_real: 1836\n",
            "Loss: 2.12321949\n",
            "Average gradient: 0.00180858793\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2324...\n",
            "Number of non-padding tokens in tar_real: 1848\n",
            "Loss: 2.11957812\n",
            "Average gradient: 0.000805776741\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2325...\n",
            "Number of non-padding tokens in tar_real: 1883\n",
            "Loss: 2.28673911\n",
            "Average gradient: 0.000944683095\n",
            "Resources: CPU: 14.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2326...\n",
            "Number of non-padding tokens in tar_real: 1868\n",
            "Loss: 2.2278564\n",
            "Average gradient: 0.000877896033\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2327...\n",
            "Number of non-padding tokens in tar_real: 1706\n",
            "Loss: 2.3281889\n",
            "Average gradient: 0.000777855341\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2328...\n",
            "Number of non-padding tokens in tar_real: 1820\n",
            "Loss: 2.35838747\n",
            "Average gradient: 0.000821018592\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2329...\n",
            "Number of non-padding tokens in tar_real: 1798\n",
            "Loss: 2.35256362\n",
            "Average gradient: 0.000799099274\n",
            "Resources: CPU: 15.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2330...\n",
            "Number of non-padding tokens in tar_real: 1892\n",
            "Loss: 2.20438409\n",
            "Average gradient: 0.000780860311\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2331...\n",
            "Number of non-padding tokens in tar_real: 1807\n",
            "Loss: 2.26766396\n",
            "Average gradient: 0.000828241929\n",
            "Resources: CPU: 12.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2332...\n",
            "Number of non-padding tokens in tar_real: 1751\n",
            "Loss: 2.26864457\n",
            "Average gradient: 0.000776341883\n",
            "Resources: CPU: 13.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2333...\n",
            "Number of non-padding tokens in tar_real: 1857\n",
            "Loss: 2.17777419\n",
            "Average gradient: 0.000728717539\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2334...\n",
            "Number of non-padding tokens in tar_real: 1924\n",
            "Loss: 2.32450318\n",
            "Average gradient: 0.000808391604\n",
            "Resources: CPU: 15.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2335...\n",
            "Number of non-padding tokens in tar_real: 1672\n",
            "Loss: 2.23506761\n",
            "Average gradient: 0.000930814829\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2336...\n",
            "Number of non-padding tokens in tar_real: 1841\n",
            "Loss: 2.29524064\n",
            "Average gradient: 0.000773248088\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2337...\n",
            "Number of non-padding tokens in tar_real: 1792\n",
            "Loss: 2.13139462\n",
            "Average gradient: 0.000722304278\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2338...\n",
            "Number of non-padding tokens in tar_real: 1700\n",
            "Loss: 2.06335735\n",
            "Average gradient: 0.000820057874\n",
            "Resources: CPU: 14.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2339...\n",
            "Number of non-padding tokens in tar_real: 1729\n",
            "Loss: 2.16288447\n",
            "Average gradient: 0.000824795279\n",
            "Resources: CPU: 14.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2340...\n",
            "Number of non-padding tokens in tar_real: 1781\n",
            "Loss: 2.272403\n",
            "Average gradient: 0.000736687332\n",
            "Resources: CPU: 10.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2341...\n",
            "Number of non-padding tokens in tar_real: 1889\n",
            "Loss: 2.26812506\n",
            "Average gradient: 0.000863302848\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2342...\n",
            "Number of non-padding tokens in tar_real: 1693\n",
            "Loss: 2.12558222\n",
            "Average gradient: 0.000864887785\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2343...\n",
            "Number of non-padding tokens in tar_real: 1887\n",
            "Loss: 2.29427862\n",
            "Average gradient: 0.000775983208\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2344...\n",
            "Number of non-padding tokens in tar_real: 1789\n",
            "Loss: 2.19909954\n",
            "Average gradient: 0.000807293225\n",
            "Resources: CPU: 15.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2345...\n",
            "Number of non-padding tokens in tar_real: 1834\n",
            "Loss: 2.36699271\n",
            "Average gradient: 0.000858450774\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2346...\n",
            "Number of non-padding tokens in tar_real: 1873\n",
            "Loss: 2.26418591\n",
            "Average gradient: 0.000832612277\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2347...\n",
            "Number of non-padding tokens in tar_real: 1883\n",
            "Loss: 2.33946419\n",
            "Average gradient: 0.000796247507\n",
            "Resources: CPU: 15.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2348...\n",
            "Number of non-padding tokens in tar_real: 1857\n",
            "Loss: 2.3455174\n",
            "Average gradient: 0.000847724\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2349...\n",
            "Number of non-padding tokens in tar_real: 1826\n",
            "Loss: 2.23909569\n",
            "Average gradient: 0.000961022102\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2350...\n",
            "Number of non-padding tokens in tar_real: 1840\n",
            "Loss: 2.29767275\n",
            "Average gradient: 0.000871755648\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2351...\n",
            "Number of non-padding tokens in tar_real: 1756\n",
            "Loss: 2.21135664\n",
            "Average gradient: 0.000744166493\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2352...\n",
            "Number of non-padding tokens in tar_real: 1892\n",
            "Loss: 2.20010972\n",
            "Average gradient: 0.000830772449\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2353...\n",
            "Number of non-padding tokens in tar_real: 1743\n",
            "Loss: 2.40401649\n",
            "Average gradient: 0.000767896476\n",
            "Resources: CPU: 17.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2354...\n",
            "Number of non-padding tokens in tar_real: 1934\n",
            "Loss: 2.28080106\n",
            "Average gradient: 0.000794434221\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2355...\n",
            "Number of non-padding tokens in tar_real: 1714\n",
            "Loss: 2.30772877\n",
            "Average gradient: 0.000797335175\n",
            "Resources: CPU: 12.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2356...\n",
            "Number of non-padding tokens in tar_real: 1922\n",
            "Loss: 2.24974322\n",
            "Average gradient: 0.000864157\n",
            "Resources: CPU: 14.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2357...\n",
            "Number of non-padding tokens in tar_real: 1810\n",
            "Loss: 2.13922191\n",
            "Average gradient: 0.000859357882\n",
            "Resources: CPU: 16.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2358...\n",
            "Number of non-padding tokens in tar_real: 1701\n",
            "Loss: 2.13937354\n",
            "Average gradient: 0.000839981367\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2359...\n",
            "Number of non-padding tokens in tar_real: 1858\n",
            "Loss: 2.22771692\n",
            "Average gradient: 0.000849867181\n",
            "Resources: CPU: 11.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2360...\n",
            "Number of non-padding tokens in tar_real: 1759\n",
            "Loss: 2.29766798\n",
            "Average gradient: 0.000817545457\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2361...\n",
            "Number of non-padding tokens in tar_real: 1812\n",
            "Loss: 2.22388577\n",
            "Average gradient: 0.00075193157\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2362...\n",
            "Number of non-padding tokens in tar_real: 1895\n",
            "Loss: 2.3565073\n",
            "Average gradient: 0.000725212274\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2363...\n",
            "Number of non-padding tokens in tar_real: 1800\n",
            "Loss: 2.27622271\n",
            "Average gradient: 0.000790698046\n",
            "Resources: CPU: 15.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2364...\n",
            "Number of non-padding tokens in tar_real: 1829\n",
            "Loss: 2.33312964\n",
            "Average gradient: 0.000799555448\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2365...\n",
            "Number of non-padding tokens in tar_real: 1846\n",
            "Loss: 2.14617968\n",
            "Average gradient: 0.000828734308\n",
            "Resources: CPU: 13.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2366...\n",
            "Number of non-padding tokens in tar_real: 1755\n",
            "Loss: 2.15767097\n",
            "Average gradient: 0.00081948482\n",
            "Resources: CPU: 14.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2367...\n",
            "Number of non-padding tokens in tar_real: 1856\n",
            "Loss: 2.1980865\n",
            "Average gradient: 0.000814622617\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2368...\n",
            "Number of non-padding tokens in tar_real: 1889\n",
            "Loss: 2.33047509\n",
            "Average gradient: 0.000857369392\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2369...\n",
            "Number of non-padding tokens in tar_real: 1705\n",
            "Loss: 2.16213036\n",
            "Average gradient: 0.000832659309\n",
            "Resources: CPU: 14.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2370...\n",
            "Number of non-padding tokens in tar_real: 1822\n",
            "Loss: 2.20115304\n",
            "Average gradient: 0.000837875123\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2371...\n",
            "Number of non-padding tokens in tar_real: 1918\n",
            "Loss: 2.30523086\n",
            "Average gradient: 0.000775063876\n",
            "Resources: CPU: 11.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2372...\n",
            "Number of non-padding tokens in tar_real: 1773\n",
            "Loss: 2.22516465\n",
            "Average gradient: 0.000811491744\n",
            "Resources: CPU: 14.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 57.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2373...\n",
            "Number of non-padding tokens in tar_real: 1886\n",
            "Loss: 2.28393078\n",
            "Average gradient: 0.000843912305\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 57.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2374...\n",
            "Number of non-padding tokens in tar_real: 1756\n",
            "Loss: 2.17318583\n",
            "Average gradient: 0.000785259297\n",
            "Resources: CPU: 15.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2375...\n",
            "Number of non-padding tokens in tar_real: 1645\n",
            "Loss: 2.20565701\n",
            "Average gradient: 0.000793387298\n",
            "Resources: CPU: 15.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2376...\n",
            "Number of non-padding tokens in tar_real: 1797\n",
            "Loss: 2.41293383\n",
            "Average gradient: 0.000781171781\n",
            "Resources: CPU: 11.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2377...\n",
            "Number of non-padding tokens in tar_real: 1765\n",
            "Loss: 2.23726988\n",
            "Average gradient: 0.00077166647\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2378...\n",
            "Number of non-padding tokens in tar_real: 1885\n",
            "Loss: 2.25306845\n",
            "Average gradient: 0.000786314718\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2379...\n",
            "Number of non-padding tokens in tar_real: 1799\n",
            "Loss: 2.20477366\n",
            "Average gradient: 0.000875212369\n",
            "Resources: CPU: 14.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2380...\n",
            "Number of non-padding tokens in tar_real: 1828\n",
            "Loss: 2.3987813\n",
            "Average gradient: 0.000792711566\n",
            "Resources: CPU: 14.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2381...\n",
            "Number of non-padding tokens in tar_real: 1907\n",
            "Loss: 2.28755736\n",
            "Average gradient: 0.000730960921\n",
            "Resources: CPU: 14.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2382...\n",
            "Number of non-padding tokens in tar_real: 1742\n",
            "Loss: 2.1916666\n",
            "Average gradient: 0.000866509043\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2383...\n",
            "Number of non-padding tokens in tar_real: 1835\n",
            "Loss: 2.14185333\n",
            "Average gradient: 0.000739879382\n",
            "Resources: CPU: 14.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2384...\n",
            "Number of non-padding tokens in tar_real: 1769\n",
            "Loss: 2.33987927\n",
            "Average gradient: 0.000865352747\n",
            "Resources: CPU: 14.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2385...\n",
            "Number of non-padding tokens in tar_real: 1761\n",
            "Loss: 2.22173476\n",
            "Average gradient: 0.000783650612\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2386...\n",
            "Number of non-padding tokens in tar_real: 1793\n",
            "Loss: 2.15837026\n",
            "Average gradient: 0.000776299043\n",
            "Resources: CPU: 14.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2387...\n",
            "Number of non-padding tokens in tar_real: 1806\n",
            "Loss: 2.17981052\n",
            "Average gradient: 0.000831866288\n",
            "Resources: CPU: 16.0% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2388...\n",
            "Number of non-padding tokens in tar_real: 1768\n",
            "Loss: 2.45789337\n",
            "Average gradient: 0.000914100907\n",
            "Resources: CPU: 24.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2389...\n",
            "Number of non-padding tokens in tar_real: 1763\n",
            "Loss: 2.34442687\n",
            "Average gradient: 0.000803430856\n",
            "Resources: CPU: 20.9% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2390...\n",
            "Number of non-padding tokens in tar_real: 1845\n",
            "Loss: 2.14680457\n",
            "Average gradient: 0.000803801115\n",
            "Resources: CPU: 22.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2391...\n",
            "Number of non-padding tokens in tar_real: 1824\n",
            "Loss: 2.24848104\n",
            "Average gradient: 0.000824044\n",
            "Resources: CPU: 23.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2392...\n",
            "Number of non-padding tokens in tar_real: 1745\n",
            "Loss: 2.25758553\n",
            "Average gradient: 0.000769472565\n",
            "Resources: CPU: 22.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2393...\n",
            "Number of non-padding tokens in tar_real: 1863\n",
            "Loss: 2.35414124\n",
            "Average gradient: 0.000852499797\n",
            "Resources: CPU: 26.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2394...\n",
            "Number of non-padding tokens in tar_real: 1841\n",
            "Loss: 2.18693161\n",
            "Average gradient: 0.000737788912\n",
            "Resources: CPU: 22.4% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2395...\n",
            "Number of non-padding tokens in tar_real: 1815\n",
            "Loss: 2.20197034\n",
            "Average gradient: 0.000787472469\n",
            "Resources: CPU: 23.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2396...\n",
            "Number of non-padding tokens in tar_real: 1865\n",
            "Loss: 2.20978761\n",
            "Average gradient: 0.000804739422\n",
            "Resources: CPU: 21.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2397...\n",
            "Number of non-padding tokens in tar_real: 1874\n",
            "Loss: 2.21068454\n",
            "Average gradient: 0.000781094073\n",
            "Resources: CPU: 22.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2398...\n",
            "Number of non-padding tokens in tar_real: 1814\n",
            "Loss: 2.34145188\n",
            "Average gradient: 0.000869179261\n",
            "Resources: CPU: 20.9% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2399...\n",
            "Number of non-padding tokens in tar_real: 1765\n",
            "Loss: 2.31250834\n",
            "Average gradient: 0.00075799058\n",
            "Resources: CPU: 22.0% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2400...\n",
            "Number of non-padding tokens in tar_real: 1737\n",
            "Loss: 2.27550983\n",
            "Average gradient: 0.000756164547\n",
            "Resources: CPU: 21.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2401...\n",
            "Number of non-padding tokens in tar_real: 1771\n",
            "Loss: 2.15586257\n",
            "Average gradient: 0.000785234501\n",
            "Resources: CPU: 22.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2402...\n",
            "Number of non-padding tokens in tar_real: 1780\n",
            "Loss: 2.21176887\n",
            "Average gradient: 0.000762730604\n",
            "Resources: CPU: 23.9% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2403...\n",
            "Number of non-padding tokens in tar_real: 1803\n",
            "Loss: 2.11672425\n",
            "Average gradient: 0.000787357218\n",
            "Resources: CPU: 23.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2404...\n",
            "Number of non-padding tokens in tar_real: 1772\n",
            "Loss: 2.23073745\n",
            "Average gradient: 0.000805592339\n",
            "Resources: CPU: 23.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2405...\n",
            "Number of non-padding tokens in tar_real: 1841\n",
            "Loss: 2.10213542\n",
            "Average gradient: 0.000815311505\n",
            "Resources: CPU: 23.5% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2406...\n",
            "Number of non-padding tokens in tar_real: 1804\n",
            "Loss: 2.34098983\n",
            "Average gradient: 0.000809853722\n",
            "Resources: CPU: 25.2% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2407...\n",
            "Number of non-padding tokens in tar_real: 1802\n",
            "Loss: 2.36728501\n",
            "Average gradient: 0.000737856259\n",
            "Resources: CPU: 21.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2408...\n",
            "Number of non-padding tokens in tar_real: 1852\n",
            "Loss: 2.18310094\n",
            "Average gradient: 0.000706570689\n",
            "Resources: CPU: 22.4% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 57.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2409...\n",
            "Number of non-padding tokens in tar_real: 1806\n",
            "Loss: 2.16913342\n",
            "Average gradient: 0.000748949766\n",
            "Resources: CPU: 23.9% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 57.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2410...\n",
            "Number of non-padding tokens in tar_real: 1774\n",
            "Loss: 2.30243325\n",
            "Average gradient: 0.000785022625\n",
            "Resources: CPU: 23.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2411...\n",
            "Number of non-padding tokens in tar_real: 1833\n",
            "Loss: 2.13244963\n",
            "Average gradient: 0.000797447574\n",
            "Resources: CPU: 27.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2412...\n",
            "Number of non-padding tokens in tar_real: 1749\n",
            "Loss: 2.27759409\n",
            "Average gradient: 0.000743915152\n",
            "Resources: CPU: 15.9% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2413...\n",
            "Number of non-padding tokens in tar_real: 1930\n",
            "Loss: 2.30881333\n",
            "Average gradient: 0.000748176361\n",
            "Resources: CPU: 11.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2414...\n",
            "Number of non-padding tokens in tar_real: 1742\n",
            "Loss: 2.24039936\n",
            "Average gradient: 0.000744771329\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2415...\n",
            "Number of non-padding tokens in tar_real: 1842\n",
            "Loss: 2.30115056\n",
            "Average gradient: 0.000786550518\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2416...\n",
            "Number of non-padding tokens in tar_real: 1823\n",
            "Loss: 2.30791831\n",
            "Average gradient: 0.000735132\n",
            "Resources: CPU: 10.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2417...\n",
            "Number of non-padding tokens in tar_real: 1811\n",
            "Loss: 2.00898623\n",
            "Average gradient: 0.000725274382\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2418...\n",
            "Number of non-padding tokens in tar_real: 1779\n",
            "Loss: 2.2648654\n",
            "Average gradient: 0.000812122715\n",
            "Resources: CPU: 15.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2419...\n",
            "Number of non-padding tokens in tar_real: 1839\n",
            "Loss: 2.22490692\n",
            "Average gradient: 0.000821891183\n",
            "Resources: CPU: 14.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2420...\n",
            "Number of non-padding tokens in tar_real: 1903\n",
            "Loss: 2.17765331\n",
            "Average gradient: 0.000749819097\n",
            "Resources: CPU: 15.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2421...\n",
            "Number of non-padding tokens in tar_real: 1767\n",
            "Loss: 2.3646574\n",
            "Average gradient: 0.000733748486\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2422...\n",
            "Number of non-padding tokens in tar_real: 1876\n",
            "Loss: 2.40117574\n",
            "Average gradient: 0.000779410708\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2423...\n",
            "Number of non-padding tokens in tar_real: 1819\n",
            "Loss: 2.44555163\n",
            "Average gradient: 0.000797740882\n",
            "Resources: CPU: 10.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2424...\n",
            "Number of non-padding tokens in tar_real: 1808\n",
            "Loss: 2.22171354\n",
            "Average gradient: 0.000735426263\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2425...\n",
            "Number of non-padding tokens in tar_real: 1776\n",
            "Loss: 2.29767275\n",
            "Average gradient: 0.000795260479\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2426...\n",
            "Number of non-padding tokens in tar_real: 1792\n",
            "Loss: 2.30223513\n",
            "Average gradient: 0.000791521277\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2427...\n",
            "Number of non-padding tokens in tar_real: 1859\n",
            "Loss: 2.36653423\n",
            "Average gradient: 0.000800260575\n",
            "Resources: CPU: 14.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2428...\n",
            "Number of non-padding tokens in tar_real: 1828\n",
            "Loss: 2.29127264\n",
            "Average gradient: 0.000861638517\n",
            "Resources: CPU: 14.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2429...\n",
            "Number of non-padding tokens in tar_real: 1847\n",
            "Loss: 2.21488929\n",
            "Average gradient: 0.000757955888\n",
            "Resources: CPU: 14.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2430...\n",
            "Number of non-padding tokens in tar_real: 1925\n",
            "Loss: 2.34832621\n",
            "Average gradient: 0.000770351384\n",
            "Resources: CPU: 12.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2431...\n",
            "Number of non-padding tokens in tar_real: 1856\n",
            "Loss: 2.29282808\n",
            "Average gradient: 0.000764525495\n",
            "Resources: CPU: 13.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2432...\n",
            "Number of non-padding tokens in tar_real: 1847\n",
            "Loss: 2.30024576\n",
            "Average gradient: 0.000784339907\n",
            "Resources: CPU: 14.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2433...\n",
            "Number of non-padding tokens in tar_real: 1933\n",
            "Loss: 2.25069952\n",
            "Average gradient: 0.000799892237\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2434...\n",
            "Number of non-padding tokens in tar_real: 1789\n",
            "Loss: 2.25818086\n",
            "Average gradient: 0.000812409678\n",
            "Resources: CPU: 17.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2435...\n",
            "Number of non-padding tokens in tar_real: 1903\n",
            "Loss: 2.36386752\n",
            "Average gradient: 0.00087252917\n",
            "Resources: CPU: 12.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2436...\n",
            "Number of non-padding tokens in tar_real: 1803\n",
            "Loss: 2.22258162\n",
            "Average gradient: 0.000805534539\n",
            "Resources: CPU: 13.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2437...\n",
            "Number of non-padding tokens in tar_real: 1870\n",
            "Loss: 2.28909254\n",
            "Average gradient: 0.000741066237\n",
            "Resources: CPU: 16.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2438...\n",
            "Number of non-padding tokens in tar_real: 1722\n",
            "Loss: 2.20803666\n",
            "Average gradient: 0.000746854232\n",
            "Resources: CPU: 14.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2439...\n",
            "Number of non-padding tokens in tar_real: 1799\n",
            "Loss: 2.12754798\n",
            "Average gradient: 0.000801872578\n",
            "Resources: CPU: 13.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2440...\n",
            "Number of non-padding tokens in tar_real: 1807\n",
            "Loss: 1.98382008\n",
            "Average gradient: 0.000741225202\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2441...\n",
            "Number of non-padding tokens in tar_real: 1716\n",
            "Loss: 2.15402699\n",
            "Average gradient: 0.000697700481\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2442...\n",
            "Number of non-padding tokens in tar_real: 1897\n",
            "Loss: 2.31027508\n",
            "Average gradient: 0.000887198315\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2443...\n",
            "Number of non-padding tokens in tar_real: 1730\n",
            "Loss: 2.12160349\n",
            "Average gradient: 0.000738913892\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2444...\n",
            "Number of non-padding tokens in tar_real: 1803\n",
            "Loss: 2.29655337\n",
            "Average gradient: 0.000751631\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2445...\n",
            "Number of non-padding tokens in tar_real: 1882\n",
            "Loss: 2.27585697\n",
            "Average gradient: 0.000813982275\n",
            "Resources: CPU: 13.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2446...\n",
            "Number of non-padding tokens in tar_real: 1771\n",
            "Loss: 2.21117783\n",
            "Average gradient: 0.000799723261\n",
            "Resources: CPU: 15.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2447...\n",
            "Number of non-padding tokens in tar_real: 2019\n",
            "Loss: 2.35349488\n",
            "Average gradient: 0.000730024301\n",
            "Resources: CPU: 14.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2448...\n",
            "Number of non-padding tokens in tar_real: 1884\n",
            "Loss: 2.25240588\n",
            "Average gradient: 0.000806932105\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2449...\n",
            "Number of non-padding tokens in tar_real: 1772\n",
            "Loss: 2.26040983\n",
            "Average gradient: 0.000744362304\n",
            "Resources: CPU: 15.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2450...\n",
            "Number of non-padding tokens in tar_real: 1770\n",
            "Loss: 2.16612172\n",
            "Average gradient: 0.000754154345\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2451...\n",
            "Number of non-padding tokens in tar_real: 1778\n",
            "Loss: 2.27117372\n",
            "Average gradient: 0.0007255401\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2452...\n",
            "Number of non-padding tokens in tar_real: 1757\n",
            "Loss: 2.13982487\n",
            "Average gradient: 0.000748713268\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2453...\n",
            "Number of non-padding tokens in tar_real: 1895\n",
            "Loss: 2.27745652\n",
            "Average gradient: 0.000831202895\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2454...\n",
            "Number of non-padding tokens in tar_real: 1815\n",
            "Loss: 2.15541577\n",
            "Average gradient: 0.000741137599\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2455...\n",
            "Number of non-padding tokens in tar_real: 1863\n",
            "Loss: 2.29409266\n",
            "Average gradient: 0.000827658921\n",
            "Resources: CPU: 14.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2456...\n",
            "Number of non-padding tokens in tar_real: 1715\n",
            "Loss: 2.05906582\n",
            "Average gradient: 0.000744665216\n",
            "Resources: CPU: 15.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2457...\n",
            "Number of non-padding tokens in tar_real: 1834\n",
            "Loss: 2.12274289\n",
            "Average gradient: 0.000801309186\n",
            "Resources: CPU: 14.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2458...\n",
            "Number of non-padding tokens in tar_real: 1864\n",
            "Loss: 2.30353022\n",
            "Average gradient: 0.000790680177\n",
            "Resources: CPU: 12.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2459...\n",
            "Number of non-padding tokens in tar_real: 1832\n",
            "Loss: 2.1200943\n",
            "Average gradient: 0.00072848436\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2460...\n",
            "Number of non-padding tokens in tar_real: 1807\n",
            "Loss: 2.08026123\n",
            "Average gradient: 0.000758191862\n",
            "Resources: CPU: 12.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2461...\n",
            "Number of non-padding tokens in tar_real: 1794\n",
            "Loss: 2.00954914\n",
            "Average gradient: 0.00071561645\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2462...\n",
            "Number of non-padding tokens in tar_real: 1842\n",
            "Loss: 2.28240275\n",
            "Average gradient: 0.000748320716\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2463...\n",
            "Number of non-padding tokens in tar_real: 1651\n",
            "Loss: 2.10780358\n",
            "Average gradient: 0.000848674506\n",
            "Resources: CPU: 12.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2464...\n",
            "Number of non-padding tokens in tar_real: 1746\n",
            "Loss: 2.11048412\n",
            "Average gradient: 0.000753456\n",
            "Resources: CPU: 13.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2465...\n",
            "Number of non-padding tokens in tar_real: 1772\n",
            "Loss: 2.11563444\n",
            "Average gradient: 0.000807764707\n",
            "Resources: CPU: 15.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2466...\n",
            "Number of non-padding tokens in tar_real: 1773\n",
            "Loss: 2.18176723\n",
            "Average gradient: 0.00080017338\n",
            "Resources: CPU: 16.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2467...\n",
            "Number of non-padding tokens in tar_real: 1790\n",
            "Loss: 2.36013579\n",
            "Average gradient: 0.000856470491\n",
            "Resources: CPU: 12.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2468...\n",
            "Number of non-padding tokens in tar_real: 1841\n",
            "Loss: 2.08134031\n",
            "Average gradient: 0.000791420636\n",
            "Resources: CPU: 13.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2469...\n",
            "Number of non-padding tokens in tar_real: 1924\n",
            "Loss: 2.26329374\n",
            "Average gradient: 0.000776156958\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2470...\n",
            "Number of non-padding tokens in tar_real: 1832\n",
            "Loss: 2.31028605\n",
            "Average gradient: 0.000773808046\n",
            "Resources: CPU: 12.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2471...\n",
            "Number of non-padding tokens in tar_real: 1913\n",
            "Loss: 2.27240443\n",
            "Average gradient: 0.000860250904\n",
            "Resources: CPU: 10.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2472...\n",
            "Number of non-padding tokens in tar_real: 1831\n",
            "Loss: 2.36275744\n",
            "Average gradient: 0.000731294509\n",
            "Resources: CPU: 12.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2473...\n",
            "Number of non-padding tokens in tar_real: 1714\n",
            "Loss: 2.11343074\n",
            "Average gradient: 0.000762098236\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2474...\n",
            "Number of non-padding tokens in tar_real: 1773\n",
            "Loss: 2.15775\n",
            "Average gradient: 0.000865883136\n",
            "Resources: CPU: 16.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2475...\n",
            "Number of non-padding tokens in tar_real: 1827\n",
            "Loss: 2.15621638\n",
            "Average gradient: 0.000913011259\n",
            "Resources: CPU: 14.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2476...\n",
            "Number of non-padding tokens in tar_real: 1851\n",
            "Loss: 2.25676823\n",
            "Average gradient: 0.000769864244\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2477...\n",
            "Number of non-padding tokens in tar_real: 1838\n",
            "Loss: 2.15934634\n",
            "Average gradient: 0.000858737796\n",
            "Resources: CPU: 14.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2478...\n",
            "Number of non-padding tokens in tar_real: 1893\n",
            "Loss: 2.36944199\n",
            "Average gradient: 0.000833161641\n",
            "Resources: CPU: 14.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2479...\n",
            "Number of non-padding tokens in tar_real: 1826\n",
            "Loss: 2.25385761\n",
            "Average gradient: 0.000783939555\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2480...\n",
            "Number of non-padding tokens in tar_real: 1842\n",
            "Loss: 2.20690703\n",
            "Average gradient: 0.000743276381\n",
            "Resources: CPU: 12.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2481...\n",
            "Number of non-padding tokens in tar_real: 1718\n",
            "Loss: 1.89287639\n",
            "Average gradient: 0.000830700388\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2482...\n",
            "Number of non-padding tokens in tar_real: 1741\n",
            "Loss: 2.16619897\n",
            "Average gradient: 0.000800612848\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2483...\n",
            "Number of non-padding tokens in tar_real: 1820\n",
            "Loss: 2.46342301\n",
            "Average gradient: 0.000819533772\n",
            "Resources: CPU: 18.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2484...\n",
            "Number of non-padding tokens in tar_real: 1762\n",
            "Loss: 2.16131568\n",
            "Average gradient: 0.000909125607\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2485...\n",
            "Number of non-padding tokens in tar_real: 1854\n",
            "Loss: 2.29370379\n",
            "Average gradient: 0.000751711952\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2486...\n",
            "Number of non-padding tokens in tar_real: 1833\n",
            "Loss: 2.2034111\n",
            "Average gradient: 0.000700929202\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2487...\n",
            "Number of non-padding tokens in tar_real: 1702\n",
            "Loss: 2.23930836\n",
            "Average gradient: 0.000802637194\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2488...\n",
            "Number of non-padding tokens in tar_real: 1901\n",
            "Loss: 2.17323947\n",
            "Average gradient: 0.000791625702\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2489...\n",
            "Number of non-padding tokens in tar_real: 1840\n",
            "Loss: 2.39932537\n",
            "Average gradient: 0.000782371615\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2490...\n",
            "Number of non-padding tokens in tar_real: 1800\n",
            "Loss: 2.22249174\n",
            "Average gradient: 0.000809740741\n",
            "Resources: CPU: 10.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2491...\n",
            "Number of non-padding tokens in tar_real: 1780\n",
            "Loss: 2.23283958\n",
            "Average gradient: 0.000859589432\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2492...\n",
            "Number of non-padding tokens in tar_real: 1752\n",
            "Loss: 2.2668395\n",
            "Average gradient: 0.000761329895\n",
            "Resources: CPU: 18.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2493...\n",
            "Number of non-padding tokens in tar_real: 1758\n",
            "Loss: 2.19855428\n",
            "Average gradient: 0.000797051\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2494...\n",
            "Number of non-padding tokens in tar_real: 1775\n",
            "Loss: 2.20769501\n",
            "Average gradient: 0.000812488724\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2495...\n",
            "Number of non-padding tokens in tar_real: 1893\n",
            "Loss: 2.36752248\n",
            "Average gradient: 0.000814864412\n",
            "Resources: CPU: 13.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2496...\n",
            "Number of non-padding tokens in tar_real: 1848\n",
            "Loss: 2.21011567\n",
            "Average gradient: 0.000773026724\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2497...\n",
            "Number of non-padding tokens in tar_real: 1880\n",
            "Loss: 2.36991572\n",
            "Average gradient: 0.000816248474\n",
            "Resources: CPU: 13.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2498...\n",
            "Number of non-padding tokens in tar_real: 1880\n",
            "Loss: 2.31072974\n",
            "Average gradient: 0.000782506424\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2499...\n",
            "Number of non-padding tokens in tar_real: 1640\n",
            "Loss: 2.08988404\n",
            "Average gradient: 0.000776518253\n",
            "Resources: CPU: 12.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2500...\n",
            "Number of non-padding tokens in tar_real: 1837\n",
            "Loss: 2.34752393\n",
            "Average gradient: 0.000820465\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2501...\n",
            "Number of non-padding tokens in tar_real: 1729\n",
            "Loss: 1.89600921\n",
            "Average gradient: 0.000756112917\n",
            "Resources: CPU: 17.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2502...\n",
            "Number of non-padding tokens in tar_real: 1863\n",
            "Loss: 2.31131983\n",
            "Average gradient: 0.000792659528\n",
            "Resources: CPU: 13.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2503...\n",
            "Number of non-padding tokens in tar_real: 1841\n",
            "Loss: 2.13181305\n",
            "Average gradient: 0.000688376836\n",
            "Resources: CPU: 24.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2504...\n",
            "Number of non-padding tokens in tar_real: 1737\n",
            "Loss: 2.27899337\n",
            "Average gradient: 0.000766804558\n",
            "Resources: CPU: 20.5% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2505...\n",
            "Number of non-padding tokens in tar_real: 1929\n",
            "Loss: 2.291641\n",
            "Average gradient: 0.000769009697\n",
            "Resources: CPU: 23.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2506...\n",
            "Number of non-padding tokens in tar_real: 1837\n",
            "Loss: 2.38752699\n",
            "Average gradient: 0.00085986848\n",
            "Resources: CPU: 17.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 50.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2507...\n",
            "Number of non-padding tokens in tar_real: 1902\n",
            "Loss: 2.19519973\n",
            "Average gradient: 0.000796686334\n",
            "Resources: CPU: 24.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 50.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2508...\n",
            "Number of non-padding tokens in tar_real: 1794\n",
            "Loss: 2.2578373\n",
            "Average gradient: 0.000817802269\n",
            "Resources: CPU: 21.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2509...\n",
            "Number of non-padding tokens in tar_real: 1805\n",
            "Loss: 2.26363897\n",
            "Average gradient: 0.000762077572\n",
            "Resources: CPU: 21.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2510...\n",
            "Number of non-padding tokens in tar_real: 1813\n",
            "Loss: 2.24148893\n",
            "Average gradient: 0.000823091948\n",
            "Resources: CPU: 27.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2511...\n",
            "Number of non-padding tokens in tar_real: 1887\n",
            "Loss: 2.29350281\n",
            "Average gradient: 0.000815208768\n",
            "Resources: CPU: 22.0% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2512...\n",
            "Number of non-padding tokens in tar_real: 1829\n",
            "Loss: 2.18921113\n",
            "Average gradient: 0.000738199451\n",
            "Resources: CPU: 22.4% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2513...\n",
            "Number of non-padding tokens in tar_real: 1819\n",
            "Loss: 2.17258406\n",
            "Average gradient: 0.000787761295\n",
            "Resources: CPU: 21.4% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2514...\n",
            "Number of non-padding tokens in tar_real: 1832\n",
            "Loss: 2.25366068\n",
            "Average gradient: 0.000824047136\n",
            "Resources: CPU: 21.4% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2515...\n",
            "Number of non-padding tokens in tar_real: 1780\n",
            "Loss: 2.38636088\n",
            "Average gradient: 0.000822820526\n",
            "Resources: CPU: 23.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2516...\n",
            "Number of non-padding tokens in tar_real: 1904\n",
            "Loss: 2.24673891\n",
            "Average gradient: 0.000722516445\n",
            "Resources: CPU: 21.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2517...\n",
            "Number of non-padding tokens in tar_real: 1726\n",
            "Loss: 2.12304711\n",
            "Average gradient: 0.000805966789\n",
            "Resources: CPU: 23.9% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2518...\n",
            "Number of non-padding tokens in tar_real: 1931\n",
            "Loss: 2.13251615\n",
            "Average gradient: 0.000794770429\n",
            "Resources: CPU: 23.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2519...\n",
            "Number of non-padding tokens in tar_real: 1825\n",
            "Loss: 2.38376212\n",
            "Average gradient: 0.000795521657\n",
            "Resources: CPU: 27.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2520...\n",
            "Number of non-padding tokens in tar_real: 1872\n",
            "Loss: 2.30954909\n",
            "Average gradient: 0.000750346226\n",
            "Resources: CPU: 24.4% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2521...\n",
            "Number of non-padding tokens in tar_real: 1743\n",
            "Loss: 2.15703988\n",
            "Average gradient: 0.000726651051\n",
            "Resources: CPU: 23.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2522...\n",
            "Number of non-padding tokens in tar_real: 1807\n",
            "Loss: 2.24937558\n",
            "Average gradient: 0.000693100854\n",
            "Resources: CPU: 24.4% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2523...\n",
            "Number of non-padding tokens in tar_real: 1720\n",
            "Loss: 2.12461615\n",
            "Average gradient: 0.000748674152\n",
            "Resources: CPU: 22.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2524...\n",
            "Number of non-padding tokens in tar_real: 1841\n",
            "Loss: 2.26839042\n",
            "Average gradient: 0.000871148543\n",
            "Resources: CPU: 21.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2525...\n",
            "Number of non-padding tokens in tar_real: 1791\n",
            "Loss: 2.29256248\n",
            "Average gradient: 0.000891402829\n",
            "Resources: CPU: 20.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2526...\n",
            "Number of non-padding tokens in tar_real: 1639\n",
            "Loss: 2.28424311\n",
            "Average gradient: 0.000899580831\n",
            "Resources: CPU: 21.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 56.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2527...\n",
            "Number of non-padding tokens in tar_real: 1935\n",
            "Loss: 2.22551107\n",
            "Average gradient: 0.000734698493\n",
            "Resources: CPU: 21.2% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 56.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2528...\n",
            "Number of non-padding tokens in tar_real: 1818\n",
            "Loss: 2.26312828\n",
            "Average gradient: 0.000797305\n",
            "Resources: CPU: 16.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2529...\n",
            "Number of non-padding tokens in tar_real: 1766\n",
            "Loss: 2.28358603\n",
            "Average gradient: 0.000776187808\n",
            "Resources: CPU: 14.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2530...\n",
            "Number of non-padding tokens in tar_real: 1812\n",
            "Loss: 2.1391387\n",
            "Average gradient: 0.000784729724\n",
            "Resources: CPU: 11.5% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2531...\n",
            "Number of non-padding tokens in tar_real: 1698\n",
            "Loss: 2.24715161\n",
            "Average gradient: 0.000947521476\n",
            "Resources: CPU: 13.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2532...\n",
            "Number of non-padding tokens in tar_real: 1888\n",
            "Loss: 2.31689954\n",
            "Average gradient: 0.000846311566\n",
            "Resources: CPU: 11.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2533...\n",
            "Number of non-padding tokens in tar_real: 1851\n",
            "Loss: 2.26107121\n",
            "Average gradient: 0.000834345934\n",
            "Resources: CPU: 12.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2534...\n",
            "Number of non-padding tokens in tar_real: 1837\n",
            "Loss: 2.24746895\n",
            "Average gradient: 0.000862650399\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2535...\n",
            "Number of non-padding tokens in tar_real: 1886\n",
            "Loss: 2.22551155\n",
            "Average gradient: 0.000772779225\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2536...\n",
            "Number of non-padding tokens in tar_real: 1822\n",
            "Loss: 2.27586079\n",
            "Average gradient: 0.000812698796\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2537...\n",
            "Number of non-padding tokens in tar_real: 1829\n",
            "Loss: 2.33387756\n",
            "Average gradient: 0.000771119667\n",
            "Resources: CPU: 16.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2538...\n",
            "Number of non-padding tokens in tar_real: 1761\n",
            "Loss: 2.22027421\n",
            "Average gradient: 0.000842972833\n",
            "Resources: CPU: 15.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2539...\n",
            "Number of non-padding tokens in tar_real: 1769\n",
            "Loss: 2.26865292\n",
            "Average gradient: 0.000864525733\n",
            "Resources: CPU: 12.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2540...\n",
            "Number of non-padding tokens in tar_real: 1772\n",
            "Loss: 2.29796433\n",
            "Average gradient: 0.00080680562\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2541...\n",
            "Number of non-padding tokens in tar_real: 1727\n",
            "Loss: 2.11582732\n",
            "Average gradient: 0.000838201959\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2542...\n",
            "Number of non-padding tokens in tar_real: 1820\n",
            "Loss: 2.23697877\n",
            "Average gradient: 0.000866191753\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2543...\n",
            "Number of non-padding tokens in tar_real: 1835\n",
            "Loss: 2.12579846\n",
            "Average gradient: 0.000759023591\n",
            "Resources: CPU: 15.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2544...\n",
            "Number of non-padding tokens in tar_real: 1813\n",
            "Loss: 2.12063146\n",
            "Average gradient: 0.000739576644\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2545...\n",
            "Number of non-padding tokens in tar_real: 1823\n",
            "Loss: 2.0307734\n",
            "Average gradient: 0.000745495083\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2546...\n",
            "Number of non-padding tokens in tar_real: 1814\n",
            "Loss: 2.13173699\n",
            "Average gradient: 0.000791851082\n",
            "Resources: CPU: 16.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2547...\n",
            "Number of non-padding tokens in tar_real: 1793\n",
            "Loss: 2.2188108\n",
            "Average gradient: 0.000837053\n",
            "Resources: CPU: 16.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2548...\n",
            "Number of non-padding tokens in tar_real: 1829\n",
            "Loss: 2.25216556\n",
            "Average gradient: 0.00082342152\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2549...\n",
            "Number of non-padding tokens in tar_real: 1783\n",
            "Loss: 2.2060349\n",
            "Average gradient: 0.00070999132\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2550...\n",
            "Number of non-padding tokens in tar_real: 1929\n",
            "Loss: 2.2746\n",
            "Average gradient: 0.000770563609\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2551...\n",
            "Number of non-padding tokens in tar_real: 1734\n",
            "Loss: 2.33195233\n",
            "Average gradient: 0.000786093646\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2552...\n",
            "Number of non-padding tokens in tar_real: 1816\n",
            "Loss: 2.24726963\n",
            "Average gradient: 0.000821081747\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2553...\n",
            "Number of non-padding tokens in tar_real: 1856\n",
            "Loss: 2.27121735\n",
            "Average gradient: 0.00083490496\n",
            "Resources: CPU: 14.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2554...\n",
            "Number of non-padding tokens in tar_real: 1747\n",
            "Loss: 2.12034225\n",
            "Average gradient: 0.000762578857\n",
            "Resources: CPU: 11.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2555...\n",
            "Number of non-padding tokens in tar_real: 1759\n",
            "Loss: 2.30999637\n",
            "Average gradient: 0.000812147686\n",
            "Resources: CPU: 14.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2556...\n",
            "Number of non-padding tokens in tar_real: 1802\n",
            "Loss: 2.22586727\n",
            "Average gradient: 0.000802298\n",
            "Resources: CPU: 15.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2557...\n",
            "Number of non-padding tokens in tar_real: 1810\n",
            "Loss: 2.26013875\n",
            "Average gradient: 0.000819109729\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2558...\n",
            "Number of non-padding tokens in tar_real: 1820\n",
            "Loss: 2.29002881\n",
            "Average gradient: 0.000754960638\n",
            "Resources: CPU: 11.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2559...\n",
            "Number of non-padding tokens in tar_real: 1859\n",
            "Loss: 2.14051723\n",
            "Average gradient: 0.000838930369\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2560...\n",
            "Number of non-padding tokens in tar_real: 1853\n",
            "Loss: 2.09820557\n",
            "Average gradient: 0.000829417375\n",
            "Resources: CPU: 14.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2561...\n",
            "Number of non-padding tokens in tar_real: 1755\n",
            "Loss: 2.26675487\n",
            "Average gradient: 0.000866270333\n",
            "Resources: CPU: 12.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2562...\n",
            "Number of non-padding tokens in tar_real: 1943\n",
            "Loss: 2.21961856\n",
            "Average gradient: 0.000794942898\n",
            "Resources: CPU: 11.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2563...\n",
            "Number of non-padding tokens in tar_real: 1704\n",
            "Loss: 2.14000487\n",
            "Average gradient: 0.000817906694\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2564...\n",
            "Number of non-padding tokens in tar_real: 1731\n",
            "Loss: 2.19300413\n",
            "Average gradient: 0.000763983699\n",
            "Resources: CPU: 17.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2565...\n",
            "Number of non-padding tokens in tar_real: 1843\n",
            "Loss: 2.3023088\n",
            "Average gradient: 0.000789471145\n",
            "Resources: CPU: 13.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2566...\n",
            "Number of non-padding tokens in tar_real: 1760\n",
            "Loss: 2.22470236\n",
            "Average gradient: 0.000883074244\n",
            "Resources: CPU: 14.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2567...\n",
            "Number of non-padding tokens in tar_real: 1950\n",
            "Loss: 2.22871304\n",
            "Average gradient: 0.000760752184\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2568...\n",
            "Number of non-padding tokens in tar_real: 1928\n",
            "Loss: 2.33085775\n",
            "Average gradient: 0.000760733732\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2569...\n",
            "Number of non-padding tokens in tar_real: 1840\n",
            "Loss: 2.37836814\n",
            "Average gradient: 0.000812384416\n",
            "Resources: CPU: 13.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2570...\n",
            "Number of non-padding tokens in tar_real: 1751\n",
            "Loss: 2.16168594\n",
            "Average gradient: 0.000838647422\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2571...\n",
            "Number of non-padding tokens in tar_real: 1796\n",
            "Loss: 2.07080245\n",
            "Average gradient: 0.000861154287\n",
            "Resources: CPU: 10.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2572...\n",
            "Number of non-padding tokens in tar_real: 1920\n",
            "Loss: 2.25005269\n",
            "Average gradient: 0.000804807816\n",
            "Resources: CPU: 12.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2573...\n",
            "Number of non-padding tokens in tar_real: 1832\n",
            "Loss: 2.12011862\n",
            "Average gradient: 0.000833263446\n",
            "Resources: CPU: 16.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2574...\n",
            "Number of non-padding tokens in tar_real: 1820\n",
            "Loss: 2.38519216\n",
            "Average gradient: 0.000876835198\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2575...\n",
            "Number of non-padding tokens in tar_real: 1805\n",
            "Loss: 2.06467986\n",
            "Average gradient: 0.000775161549\n",
            "Resources: CPU: 14.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2576...\n",
            "Number of non-padding tokens in tar_real: 1886\n",
            "Loss: 2.4371047\n",
            "Average gradient: 0.000844031631\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2577...\n",
            "Number of non-padding tokens in tar_real: 1894\n",
            "Loss: 2.30597162\n",
            "Average gradient: 0.000803714851\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2578...\n",
            "Number of non-padding tokens in tar_real: 1698\n",
            "Loss: 2.21958113\n",
            "Average gradient: 0.000814978383\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2579...\n",
            "Number of non-padding tokens in tar_real: 1741\n",
            "Loss: 2.13947511\n",
            "Average gradient: 0.000801732822\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2580...\n",
            "Number of non-padding tokens in tar_real: 1771\n",
            "Loss: 1.98223078\n",
            "Average gradient: 0.000711363216\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2581...\n",
            "Number of non-padding tokens in tar_real: 1721\n",
            "Loss: 2.2384\n",
            "Average gradient: 0.000895806937\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2582...\n",
            "Number of non-padding tokens in tar_real: 1803\n",
            "Loss: 2.22082663\n",
            "Average gradient: 0.000835940184\n",
            "Resources: CPU: 16.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2583...\n",
            "Number of non-padding tokens in tar_real: 1910\n",
            "Loss: 2.3663373\n",
            "Average gradient: 0.000828458578\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2584...\n",
            "Number of non-padding tokens in tar_real: 1806\n",
            "Loss: 2.25567937\n",
            "Average gradient: 0.000871014665\n",
            "Resources: CPU: 14.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2585...\n",
            "Number of non-padding tokens in tar_real: 1789\n",
            "Loss: 2.28981638\n",
            "Average gradient: 0.00072548067\n",
            "Resources: CPU: 14.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2586...\n",
            "Number of non-padding tokens in tar_real: 1709\n",
            "Loss: 2.2108829\n",
            "Average gradient: 0.000774627726\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2587...\n",
            "Number of non-padding tokens in tar_real: 1891\n",
            "Loss: 2.34786224\n",
            "Average gradient: 0.000829543627\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2588...\n",
            "Number of non-padding tokens in tar_real: 1800\n",
            "Loss: 2.22662973\n",
            "Average gradient: 0.000923117273\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2589...\n",
            "Number of non-padding tokens in tar_real: 1834\n",
            "Loss: 2.24220085\n",
            "Average gradient: 0.000876305858\n",
            "Resources: CPU: 10.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2590...\n",
            "Number of non-padding tokens in tar_real: 1866\n",
            "Loss: 2.30905485\n",
            "Average gradient: 0.000807165517\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2591...\n",
            "Number of non-padding tokens in tar_real: 1836\n",
            "Loss: 2.32508254\n",
            "Average gradient: 0.000827918062\n",
            "Resources: CPU: 15.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2592...\n",
            "Number of non-padding tokens in tar_real: 1736\n",
            "Loss: 2.24626493\n",
            "Average gradient: 0.000846993178\n",
            "Resources: CPU: 14.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2593...\n",
            "Number of non-padding tokens in tar_real: 1806\n",
            "Loss: 2.28481054\n",
            "Average gradient: 0.000791754108\n",
            "Resources: CPU: 13.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2594...\n",
            "Number of non-padding tokens in tar_real: 1819\n",
            "Loss: 2.33180785\n",
            "Average gradient: 0.000823277\n",
            "Resources: CPU: 15.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2595...\n",
            "Number of non-padding tokens in tar_real: 1841\n",
            "Loss: 2.21121645\n",
            "Average gradient: 0.000896944257\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2596...\n",
            "Number of non-padding tokens in tar_real: 1773\n",
            "Loss: 2.10750103\n",
            "Average gradient: 0.000843103859\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2597...\n",
            "Number of non-padding tokens in tar_real: 1714\n",
            "Loss: 2.16580224\n",
            "Average gradient: 0.000862824498\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2598...\n",
            "Number of non-padding tokens in tar_real: 1839\n",
            "Loss: 2.38887\n",
            "Average gradient: 0.000874657882\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2599...\n",
            "Number of non-padding tokens in tar_real: 1732\n",
            "Loss: 2.04548597\n",
            "Average gradient: 0.000767322723\n",
            "Resources: CPU: 11.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2600...\n",
            "Number of non-padding tokens in tar_real: 1890\n",
            "Loss: 2.35614061\n",
            "Average gradient: 0.000759677088\n",
            "Resources: CPU: 13.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2601...\n",
            "Number of non-padding tokens in tar_real: 1836\n",
            "Loss: 2.3146975\n",
            "Average gradient: 0.000835994782\n",
            "Resources: CPU: 14.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2602...\n",
            "Number of non-padding tokens in tar_real: 1821\n",
            "Loss: 2.19911957\n",
            "Average gradient: 0.000736902526\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2603...\n",
            "Number of non-padding tokens in tar_real: 1808\n",
            "Loss: 2.1916\n",
            "Average gradient: 0.000827565731\n",
            "Resources: CPU: 13.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2604...\n",
            "Number of non-padding tokens in tar_real: 1905\n",
            "Loss: 2.39824176\n",
            "Average gradient: 0.000753255794\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2605...\n",
            "Number of non-padding tokens in tar_real: 1793\n",
            "Loss: 2.23839402\n",
            "Average gradient: 0.000811341917\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2606...\n",
            "Number of non-padding tokens in tar_real: 1822\n",
            "Loss: 2.36331344\n",
            "Average gradient: 0.00084103737\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2607...\n",
            "Number of non-padding tokens in tar_real: 1804\n",
            "Loss: 2.17298293\n",
            "Average gradient: 0.000846314593\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2608...\n",
            "Number of non-padding tokens in tar_real: 1886\n",
            "Loss: 2.23960066\n",
            "Average gradient: 0.000835651066\n",
            "Resources: CPU: 13.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2609...\n",
            "Number of non-padding tokens in tar_real: 1756\n",
            "Loss: 2.37485266\n",
            "Average gradient: 0.000859541702\n",
            "Resources: CPU: 14.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2610...\n",
            "Number of non-padding tokens in tar_real: 1850\n",
            "Loss: 2.24956179\n",
            "Average gradient: 0.000782053045\n",
            "Resources: CPU: 15.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2611...\n",
            "Number of non-padding tokens in tar_real: 1784\n",
            "Loss: 2.12493134\n",
            "Average gradient: 0.000771360297\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2612...\n",
            "Number of non-padding tokens in tar_real: 1835\n",
            "Loss: 2.24478269\n",
            "Average gradient: 0.000820836\n",
            "Resources: CPU: 14.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2613...\n",
            "Number of non-padding tokens in tar_real: 1852\n",
            "Loss: 2.38208508\n",
            "Average gradient: 0.000872910838\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2614...\n",
            "Number of non-padding tokens in tar_real: 1817\n",
            "Loss: 2.34758687\n",
            "Average gradient: 0.000843117712\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2615...\n",
            "Number of non-padding tokens in tar_real: 1748\n",
            "Loss: 2.1907053\n",
            "Average gradient: 0.000821105845\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2616...\n",
            "Number of non-padding tokens in tar_real: 1801\n",
            "Loss: 2.17427754\n",
            "Average gradient: 0.000855933933\n",
            "Resources: CPU: 12.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2617...\n",
            "Number of non-padding tokens in tar_real: 1768\n",
            "Loss: 2.23605919\n",
            "Average gradient: 0.000759354094\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2618...\n",
            "Number of non-padding tokens in tar_real: 1786\n",
            "Loss: 2.09270763\n",
            "Average gradient: 0.000763123797\n",
            "Resources: CPU: 14.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2619...\n",
            "Number of non-padding tokens in tar_real: 1772\n",
            "Loss: 2.43811059\n",
            "Average gradient: 0.000893188349\n",
            "Resources: CPU: 27.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 57.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2620...\n",
            "Number of non-padding tokens in tar_real: 1787\n",
            "Loss: 2.23144078\n",
            "Average gradient: 0.000782388437\n",
            "Resources: CPU: 22.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 57.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2621...\n",
            "Number of non-padding tokens in tar_real: 1836\n",
            "Loss: 2.33893919\n",
            "Average gradient: 0.000889486866\n",
            "Resources: CPU: 22.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2622...\n",
            "Number of non-padding tokens in tar_real: 1779\n",
            "Loss: 2.2727387\n",
            "Average gradient: 0.000932330964\n",
            "Resources: CPU: 22.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2623...\n",
            "Number of non-padding tokens in tar_real: 1804\n",
            "Loss: 2.09226489\n",
            "Average gradient: 0.000848788477\n",
            "Resources: CPU: 21.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2624...\n",
            "Number of non-padding tokens in tar_real: 1729\n",
            "Loss: 2.25687575\n",
            "Average gradient: 0.000800290203\n",
            "Resources: CPU: 22.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2625...\n",
            "Number of non-padding tokens in tar_real: 1829\n",
            "Loss: 2.24591303\n",
            "Average gradient: 0.000828538032\n",
            "Resources: CPU: 22.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2626...\n",
            "Number of non-padding tokens in tar_real: 1835\n",
            "Loss: 2.18104815\n",
            "Average gradient: 0.000766766141\n",
            "Resources: CPU: 22.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2627...\n",
            "Number of non-padding tokens in tar_real: 1845\n",
            "Loss: 2.24331617\n",
            "Average gradient: 0.000752508815\n",
            "Resources: CPU: 23.0% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2628...\n",
            "Number of non-padding tokens in tar_real: 1776\n",
            "Loss: 2.16271544\n",
            "Average gradient: 0.000865237089\n",
            "Resources: CPU: 23.0% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 56.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2629...\n",
            "Number of non-padding tokens in tar_real: 1812\n",
            "Loss: 2.20133591\n",
            "Average gradient: 0.000807160046\n",
            "Resources: CPU: 21.4% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 56.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2630...\n",
            "Number of non-padding tokens in tar_real: 1674\n",
            "Loss: 2.11530113\n",
            "Average gradient: 0.000794582\n",
            "Resources: CPU: 20.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2631...\n",
            "Number of non-padding tokens in tar_real: 1827\n",
            "Loss: 2.43215632\n",
            "Average gradient: 0.000864649657\n",
            "Resources: CPU: 24.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2632...\n",
            "Number of non-padding tokens in tar_real: 1803\n",
            "Loss: 2.35722613\n",
            "Average gradient: 0.000767790829\n",
            "Resources: CPU: 20.2% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2633...\n",
            "Number of non-padding tokens in tar_real: 1791\n",
            "Loss: 2.16869211\n",
            "Average gradient: 0.000831791782\n",
            "Resources: CPU: 23.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2634...\n",
            "Number of non-padding tokens in tar_real: 1863\n",
            "Loss: 2.29367113\n",
            "Average gradient: 0.0007673605\n",
            "Resources: CPU: 22.0% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2635...\n",
            "Number of non-padding tokens in tar_real: 1828\n",
            "Loss: 2.20514107\n",
            "Average gradient: 0.000809276069\n",
            "Resources: CPU: 23.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2636...\n",
            "Number of non-padding tokens in tar_real: 1857\n",
            "Loss: 2.27342415\n",
            "Average gradient: 0.000855249411\n",
            "Resources: CPU: 24.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2637...\n",
            "Number of non-padding tokens in tar_real: 1718\n",
            "Loss: 2.176332\n",
            "Average gradient: 0.000831939629\n",
            "Resources: CPU: 26.5% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2638...\n",
            "Number of non-padding tokens in tar_real: 1803\n",
            "Loss: 2.1970737\n",
            "Average gradient: 0.000810243713\n",
            "Resources: CPU: 24.2% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2639...\n",
            "Number of non-padding tokens in tar_real: 1767\n",
            "Loss: 2.13313079\n",
            "Average gradient: 0.000862785964\n",
            "Resources: CPU: 25.2% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2640...\n",
            "Number of non-padding tokens in tar_real: 1759\n",
            "Loss: 2.38857436\n",
            "Average gradient: 0.000797557819\n",
            "Resources: CPU: 22.5% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2641...\n",
            "Number of non-padding tokens in tar_real: 1802\n",
            "Loss: 2.26052117\n",
            "Average gradient: 0.000773810083\n",
            "Resources: CPU: 22.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2642...\n",
            "Number of non-padding tokens in tar_real: 1733\n",
            "Loss: 2.32900214\n",
            "Average gradient: 0.000800848764\n",
            "Resources: CPU: 24.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2643...\n",
            "Number of non-padding tokens in tar_real: 1789\n",
            "Loss: 2.29674721\n",
            "Average gradient: 0.000754485256\n",
            "Resources: CPU: 17.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2644...\n",
            "Number of non-padding tokens in tar_real: 1823\n",
            "Loss: 2.23351288\n",
            "Average gradient: 0.000747004175\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2645...\n",
            "Number of non-padding tokens in tar_real: 1809\n",
            "Loss: 2.27820587\n",
            "Average gradient: 0.000811478356\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2646...\n",
            "Number of non-padding tokens in tar_real: 1821\n",
            "Loss: 2.30047274\n",
            "Average gradient: 0.000762257201\n",
            "Resources: CPU: 14.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2647...\n",
            "Number of non-padding tokens in tar_real: 1841\n",
            "Loss: 2.30770493\n",
            "Average gradient: 0.000751621032\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2648...\n",
            "Number of non-padding tokens in tar_real: 1736\n",
            "Loss: 2.17920923\n",
            "Average gradient: 0.000744398683\n",
            "Resources: CPU: 11.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2649...\n",
            "Number of non-padding tokens in tar_real: 1884\n",
            "Loss: 2.27708292\n",
            "Average gradient: 0.000832761056\n",
            "Resources: CPU: 14.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2650...\n",
            "Number of non-padding tokens in tar_real: 1807\n",
            "Loss: 2.28361368\n",
            "Average gradient: 0.000897084188\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2651...\n",
            "Number of non-padding tokens in tar_real: 1854\n",
            "Loss: 2.22407055\n",
            "Average gradient: 0.000784801319\n",
            "Resources: CPU: 12.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2652...\n",
            "Number of non-padding tokens in tar_real: 1727\n",
            "Loss: 2.18827105\n",
            "Average gradient: 0.000740285672\n",
            "Resources: CPU: 14.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2653...\n",
            "Number of non-padding tokens in tar_real: 1839\n",
            "Loss: 2.34816766\n",
            "Average gradient: 0.000801809831\n",
            "Resources: CPU: 12.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2654...\n",
            "Number of non-padding tokens in tar_real: 1814\n",
            "Loss: 2.30686569\n",
            "Average gradient: 0.000849163916\n",
            "Resources: CPU: 15.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2655...\n",
            "Number of non-padding tokens in tar_real: 1768\n",
            "Loss: 2.02743316\n",
            "Average gradient: 0.000814075465\n",
            "Resources: CPU: 14.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2656...\n",
            "Number of non-padding tokens in tar_real: 1831\n",
            "Loss: 2.27603817\n",
            "Average gradient: 0.000762113312\n",
            "Resources: CPU: 14.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2657...\n",
            "Number of non-padding tokens in tar_real: 1797\n",
            "Loss: 2.32999802\n",
            "Average gradient: 0.00079160009\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2658...\n",
            "Number of non-padding tokens in tar_real: 1780\n",
            "Loss: 2.15374827\n",
            "Average gradient: 0.000762644\n",
            "Resources: CPU: 14.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2659...\n",
            "Number of non-padding tokens in tar_real: 1843\n",
            "Loss: 2.35974479\n",
            "Average gradient: 0.000765943318\n",
            "Resources: CPU: 13.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2660...\n",
            "Number of non-padding tokens in tar_real: 1814\n",
            "Loss: 2.19611\n",
            "Average gradient: 0.000789316837\n",
            "Resources: CPU: 13.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2661...\n",
            "Number of non-padding tokens in tar_real: 1842\n",
            "Loss: 2.33914232\n",
            "Average gradient: 0.000777263369\n",
            "Resources: CPU: 11.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2662...\n",
            "Number of non-padding tokens in tar_real: 1778\n",
            "Loss: 2.17168093\n",
            "Average gradient: 0.00085695606\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2663...\n",
            "Number of non-padding tokens in tar_real: 1859\n",
            "Loss: 2.36789942\n",
            "Average gradient: 0.00083663332\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2664...\n",
            "Number of non-padding tokens in tar_real: 1846\n",
            "Loss: 2.21575904\n",
            "Average gradient: 0.000771993538\n",
            "Resources: CPU: 15.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2665...\n",
            "Number of non-padding tokens in tar_real: 1832\n",
            "Loss: 2.39013481\n",
            "Average gradient: 0.000811550883\n",
            "Resources: CPU: 12.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2666...\n",
            "Number of non-padding tokens in tar_real: 1773\n",
            "Loss: 2.27205849\n",
            "Average gradient: 0.000790966093\n",
            "Resources: CPU: 11.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2667...\n",
            "Number of non-padding tokens in tar_real: 1773\n",
            "Loss: 2.23995972\n",
            "Average gradient: 0.000744545599\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2668...\n",
            "Number of non-padding tokens in tar_real: 1766\n",
            "Loss: 2.15646052\n",
            "Average gradient: 0.000778354239\n",
            "Resources: CPU: 14.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2669...\n",
            "Number of non-padding tokens in tar_real: 1810\n",
            "Loss: 2.29237175\n",
            "Average gradient: 0.000790058\n",
            "Resources: CPU: 11.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2670...\n",
            "Number of non-padding tokens in tar_real: 1776\n",
            "Loss: 2.1697371\n",
            "Average gradient: 0.000784074131\n",
            "Resources: CPU: 13.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2671...\n",
            "Number of non-padding tokens in tar_real: 1833\n",
            "Loss: 2.3708334\n",
            "Average gradient: 0.000765819626\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2672...\n",
            "Number of non-padding tokens in tar_real: 1654\n",
            "Loss: 2.0469811\n",
            "Average gradient: 0.000761276926\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2673...\n",
            "Number of non-padding tokens in tar_real: 1768\n",
            "Loss: 2.2685864\n",
            "Average gradient: 0.000775495835\n",
            "Resources: CPU: 18.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2674...\n",
            "Number of non-padding tokens in tar_real: 1822\n",
            "Loss: 2.20851541\n",
            "Average gradient: 0.000794381776\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2675...\n",
            "Number of non-padding tokens in tar_real: 1794\n",
            "Loss: 2.19203186\n",
            "Average gradient: 0.00080376945\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2676...\n",
            "Number of non-padding tokens in tar_real: 1813\n",
            "Loss: 2.2269938\n",
            "Average gradient: 0.000691772904\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2677...\n",
            "Number of non-padding tokens in tar_real: 1841\n",
            "Loss: 2.02118802\n",
            "Average gradient: 0.00072577945\n",
            "Resources: CPU: 14.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2678...\n",
            "Number of non-padding tokens in tar_real: 1892\n",
            "Loss: 2.22279954\n",
            "Average gradient: 0.000720224576\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2679...\n",
            "Number of non-padding tokens in tar_real: 1785\n",
            "Loss: 2.2088244\n",
            "Average gradient: 0.000808947\n",
            "Resources: CPU: 11.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2680...\n",
            "Number of non-padding tokens in tar_real: 1862\n",
            "Loss: 2.30922055\n",
            "Average gradient: 0.000832969963\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2681...\n",
            "Number of non-padding tokens in tar_real: 1746\n",
            "Loss: 2.197577\n",
            "Average gradient: 0.000953252136\n",
            "Resources: CPU: 14.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2682...\n",
            "Number of non-padding tokens in tar_real: 1805\n",
            "Loss: 2.19135356\n",
            "Average gradient: 0.00078350259\n",
            "Resources: CPU: 14.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2683...\n",
            "Number of non-padding tokens in tar_real: 1807\n",
            "Loss: 2.28029919\n",
            "Average gradient: 0.000743271783\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2684...\n",
            "Number of non-padding tokens in tar_real: 1796\n",
            "Loss: 2.25874066\n",
            "Average gradient: 0.000823014299\n",
            "Resources: CPU: 11.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2685...\n",
            "Number of non-padding tokens in tar_real: 1824\n",
            "Loss: 2.14239812\n",
            "Average gradient: 0.00076890632\n",
            "Resources: CPU: 12.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2686...\n",
            "Number of non-padding tokens in tar_real: 1831\n",
            "Loss: 2.19998384\n",
            "Average gradient: 0.000845915347\n",
            "Resources: CPU: 15.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2687...\n",
            "Number of non-padding tokens in tar_real: 1967\n",
            "Loss: 2.42268896\n",
            "Average gradient: 0.00085272349\n",
            "Resources: CPU: 13.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2688...\n",
            "Number of non-padding tokens in tar_real: 1764\n",
            "Loss: 2.24780297\n",
            "Average gradient: 0.000786614721\n",
            "Resources: CPU: 12.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2689...\n",
            "Number of non-padding tokens in tar_real: 1917\n",
            "Loss: 2.29704428\n",
            "Average gradient: 0.000898264232\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2690...\n",
            "Number of non-padding tokens in tar_real: 1777\n",
            "Loss: 2.15527225\n",
            "Average gradient: 0.000747540791\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2691...\n",
            "Number of non-padding tokens in tar_real: 1754\n",
            "Loss: 2.1989975\n",
            "Average gradient: 0.000799964182\n",
            "Resources: CPU: 15.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2692...\n",
            "Number of non-padding tokens in tar_real: 1831\n",
            "Loss: 2.25440407\n",
            "Average gradient: 0.000852484547\n",
            "Resources: CPU: 15.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2693...\n",
            "Number of non-padding tokens in tar_real: 1869\n",
            "Loss: 2.10748601\n",
            "Average gradient: 0.000784454809\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2694...\n",
            "Number of non-padding tokens in tar_real: 1830\n",
            "Loss: 2.24323106\n",
            "Average gradient: 0.000812691404\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2695...\n",
            "Number of non-padding tokens in tar_real: 1827\n",
            "Loss: 2.50357318\n",
            "Average gradient: 0.000798452\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2696...\n",
            "Number of non-padding tokens in tar_real: 1814\n",
            "Loss: 2.30380678\n",
            "Average gradient: 0.000881185231\n",
            "Resources: CPU: 14.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2697...\n",
            "Number of non-padding tokens in tar_real: 1851\n",
            "Loss: 2.18597412\n",
            "Average gradient: 0.000867722847\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2698...\n",
            "Number of non-padding tokens in tar_real: 1820\n",
            "Loss: 2.15283823\n",
            "Average gradient: 0.000726252038\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2699...\n",
            "Number of non-padding tokens in tar_real: 1824\n",
            "Loss: 2.15856862\n",
            "Average gradient: 0.000696427654\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2700...\n",
            "Number of non-padding tokens in tar_real: 1723\n",
            "Loss: 2.17192864\n",
            "Average gradient: 0.000839462038\n",
            "Resources: CPU: 12.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2701...\n",
            "Number of non-padding tokens in tar_real: 1764\n",
            "Loss: 2.05452061\n",
            "Average gradient: 0.000824358314\n",
            "Resources: CPU: 13.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2702...\n",
            "Number of non-padding tokens in tar_real: 1873\n",
            "Loss: 2.34557509\n",
            "Average gradient: 0.000807609\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2703...\n",
            "Number of non-padding tokens in tar_real: 1794\n",
            "Loss: 2.1974287\n",
            "Average gradient: 0.000846913434\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2704...\n",
            "Number of non-padding tokens in tar_real: 1842\n",
            "Loss: 2.16351\n",
            "Average gradient: 0.000736587273\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2705...\n",
            "Number of non-padding tokens in tar_real: 1687\n",
            "Loss: 2.18348241\n",
            "Average gradient: 0.000874055491\n",
            "Resources: CPU: 14.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2706...\n",
            "Number of non-padding tokens in tar_real: 1838\n",
            "Loss: 2.3874557\n",
            "Average gradient: 0.000865974056\n",
            "Resources: CPU: 16.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2707...\n",
            "Number of non-padding tokens in tar_real: 1864\n",
            "Loss: 2.20787549\n",
            "Average gradient: 0.000773302745\n",
            "Resources: CPU: 15.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2708...\n",
            "Number of non-padding tokens in tar_real: 1789\n",
            "Loss: 2.10435152\n",
            "Average gradient: 0.000799501315\n",
            "Resources: CPU: 13.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2709...\n",
            "Number of non-padding tokens in tar_real: 1939\n",
            "Loss: 2.32737613\n",
            "Average gradient: 0.000740013726\n",
            "Resources: CPU: 13.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2710...\n",
            "Number of non-padding tokens in tar_real: 1807\n",
            "Loss: 2.12498498\n",
            "Average gradient: 0.000710118737\n",
            "Resources: CPU: 15.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2711...\n",
            "Number of non-padding tokens in tar_real: 1763\n",
            "Loss: 2.14539957\n",
            "Average gradient: 0.000712719047\n",
            "Resources: CPU: 12.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2712...\n",
            "Number of non-padding tokens in tar_real: 1801\n",
            "Loss: 2.30964708\n",
            "Average gradient: 0.00074092194\n",
            "Resources: CPU: 12.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2713...\n",
            "Number of non-padding tokens in tar_real: 1805\n",
            "Loss: 2.11425805\n",
            "Average gradient: 0.000786462333\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2714...\n",
            "Number of non-padding tokens in tar_real: 1808\n",
            "Loss: 2.19009161\n",
            "Average gradient: 0.000773160835\n",
            "Resources: CPU: 13.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2715...\n",
            "Number of non-padding tokens in tar_real: 1778\n",
            "Loss: 2.18006563\n",
            "Average gradient: 0.000843353278\n",
            "Resources: CPU: 14.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2716...\n",
            "Number of non-padding tokens in tar_real: 1733\n",
            "Loss: 2.09862089\n",
            "Average gradient: 0.000785794226\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2717...\n",
            "Number of non-padding tokens in tar_real: 1811\n",
            "Loss: 2.2454977\n",
            "Average gradient: 0.000785310694\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2718...\n",
            "Number of non-padding tokens in tar_real: 1773\n",
            "Loss: 2.1672821\n",
            "Average gradient: 0.00072640134\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2719...\n",
            "Number of non-padding tokens in tar_real: 1892\n",
            "Loss: 2.27152801\n",
            "Average gradient: 0.000847736315\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2720...\n",
            "Number of non-padding tokens in tar_real: 1797\n",
            "Loss: 2.2473135\n",
            "Average gradient: 0.000810073689\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2721...\n",
            "Number of non-padding tokens in tar_real: 1755\n",
            "Loss: 2.28304076\n",
            "Average gradient: 0.000743136\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2722...\n",
            "Number of non-padding tokens in tar_real: 1783\n",
            "Loss: 2.29091668\n",
            "Average gradient: 0.00080578326\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2723...\n",
            "Number of non-padding tokens in tar_real: 1877\n",
            "Loss: 2.17961788\n",
            "Average gradient: 0.000763398479\n",
            "Resources: CPU: 14.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2724...\n",
            "Number of non-padding tokens in tar_real: 1778\n",
            "Loss: 2.26920271\n",
            "Average gradient: 0.000811605947\n",
            "Resources: CPU: 13.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2725...\n",
            "Number of non-padding tokens in tar_real: 1881\n",
            "Loss: 2.40251064\n",
            "Average gradient: 0.000900940213\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2726...\n",
            "Number of non-padding tokens in tar_real: 1813\n",
            "Loss: 2.30517507\n",
            "Average gradient: 0.000743580807\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2727...\n",
            "Number of non-padding tokens in tar_real: 1802\n",
            "Loss: 2.1080544\n",
            "Average gradient: 0.00075790257\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2728...\n",
            "Number of non-padding tokens in tar_real: 1832\n",
            "Loss: 2.2729845\n",
            "Average gradient: 0.000796192035\n",
            "Resources: CPU: 15.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2729...\n",
            "Number of non-padding tokens in tar_real: 1877\n",
            "Loss: 2.33993959\n",
            "Average gradient: 0.000798982568\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2730...\n",
            "Number of non-padding tokens in tar_real: 1815\n",
            "Loss: 2.32497096\n",
            "Average gradient: 0.000843058748\n",
            "Resources: CPU: 14.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2731...\n",
            "Number of non-padding tokens in tar_real: 1782\n",
            "Loss: 2.27668548\n",
            "Average gradient: 0.00080489408\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2732...\n",
            "Number of non-padding tokens in tar_real: 1813\n",
            "Loss: 2.18766594\n",
            "Average gradient: 0.000788239762\n",
            "Resources: CPU: 13.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2733...\n",
            "Number of non-padding tokens in tar_real: 1792\n",
            "Loss: 2.25639105\n",
            "Average gradient: 0.000786745572\n",
            "Resources: CPU: 15.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2734...\n",
            "Number of non-padding tokens in tar_real: 1826\n",
            "Loss: 2.36735249\n",
            "Average gradient: 0.000850124517\n",
            "Resources: CPU: 19.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 57.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2735...\n",
            "Number of non-padding tokens in tar_real: 1799\n",
            "Loss: 2.18963957\n",
            "Average gradient: 0.000869531825\n",
            "Resources: CPU: 22.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 57.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2736...\n",
            "Number of non-padding tokens in tar_real: 1829\n",
            "Loss: 2.31559896\n",
            "Average gradient: 0.000943874125\n",
            "Resources: CPU: 25.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2737...\n",
            "Number of non-padding tokens in tar_real: 1688\n",
            "Loss: 2.11409521\n",
            "Average gradient: 0.000731925596\n",
            "Resources: CPU: 25.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2738...\n",
            "Number of non-padding tokens in tar_real: 1929\n",
            "Loss: 2.14770651\n",
            "Average gradient: 0.000838718668\n",
            "Resources: CPU: 20.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2739...\n",
            "Number of non-padding tokens in tar_real: 1776\n",
            "Loss: 2.22326827\n",
            "Average gradient: 0.000783915399\n",
            "Resources: CPU: 21.5% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2740...\n",
            "Number of non-padding tokens in tar_real: 1835\n",
            "Loss: 2.30836701\n",
            "Average gradient: 0.000824242714\n",
            "Resources: CPU: 25.2% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2741...\n",
            "Number of non-padding tokens in tar_real: 1798\n",
            "Loss: 2.14657784\n",
            "Average gradient: 0.000796249195\n",
            "Resources: CPU: 22.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2742...\n",
            "Number of non-padding tokens in tar_real: 1824\n",
            "Loss: 2.38061476\n",
            "Average gradient: 0.000916477176\n",
            "Resources: CPU: 25.0% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2743...\n",
            "Number of non-padding tokens in tar_real: 1789\n",
            "Loss: 2.2513814\n",
            "Average gradient: 0.000855451042\n",
            "Resources: CPU: 21.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2744...\n",
            "Number of non-padding tokens in tar_real: 1765\n",
            "Loss: 2.18540478\n",
            "Average gradient: 0.000891681644\n",
            "Resources: CPU: 22.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2745...\n",
            "Number of non-padding tokens in tar_real: 1827\n",
            "Loss: 2.23097086\n",
            "Average gradient: 0.000862098823\n",
            "Resources: CPU: 22.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2746...\n",
            "Number of non-padding tokens in tar_real: 1831\n",
            "Loss: 2.34770155\n",
            "Average gradient: 0.00084291969\n",
            "Resources: CPU: 22.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2747...\n",
            "Number of non-padding tokens in tar_real: 1819\n",
            "Loss: 2.27652359\n",
            "Average gradient: 0.000727158564\n",
            "Resources: CPU: 20.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2748...\n",
            "Number of non-padding tokens in tar_real: 1763\n",
            "Loss: 2.07585955\n",
            "Average gradient: 0.000807967037\n",
            "Resources: CPU: 23.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2749...\n",
            "Number of non-padding tokens in tar_real: 1776\n",
            "Loss: 2.13522053\n",
            "Average gradient: 0.000779334921\n",
            "Resources: CPU: 22.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2750...\n",
            "Number of non-padding tokens in tar_real: 1756\n",
            "Loss: 2.24918628\n",
            "Average gradient: 0.00087236485\n",
            "Resources: CPU: 22.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2751...\n",
            "Number of non-padding tokens in tar_real: 1853\n",
            "Loss: 2.31739\n",
            "Average gradient: 0.000759246817\n",
            "Resources: CPU: 23.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2752...\n",
            "Number of non-padding tokens in tar_real: 1786\n",
            "Loss: 2.08705616\n",
            "Average gradient: 0.000868130184\n",
            "Resources: CPU: 24.4% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2753...\n",
            "Number of non-padding tokens in tar_real: 1867\n",
            "Loss: 2.4266727\n",
            "Average gradient: 0.000823899405\n",
            "Resources: CPU: 22.2% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2754...\n",
            "Number of non-padding tokens in tar_real: 1883\n",
            "Loss: 2.3341763\n",
            "Average gradient: 0.000794794818\n",
            "Resources: CPU: 26.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2755...\n",
            "Number of non-padding tokens in tar_real: 1804\n",
            "Loss: 2.21884751\n",
            "Average gradient: 0.000799499103\n",
            "Resources: CPU: 25.2% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2756...\n",
            "Number of non-padding tokens in tar_real: 1848\n",
            "Loss: 2.22954297\n",
            "Average gradient: 0.000725000922\n",
            "Resources: CPU: 21.4% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2757...\n",
            "Number of non-padding tokens in tar_real: 1807\n",
            "Loss: 2.2668848\n",
            "Average gradient: 0.000726813276\n",
            "Resources: CPU: 22.4% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2758...\n",
            "Number of non-padding tokens in tar_real: 1875\n",
            "Loss: 2.3109169\n",
            "Average gradient: 0.000759743736\n",
            "Resources: CPU: 22.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2759...\n",
            "Number of non-padding tokens in tar_real: 1678\n",
            "Loss: 2.25825834\n",
            "Average gradient: 0.000826783595\n",
            "Resources: CPU: 16.4% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2760...\n",
            "Number of non-padding tokens in tar_real: 1897\n",
            "Loss: 2.17304111\n",
            "Average gradient: 0.0008156689\n",
            "Resources: CPU: 14.0% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2761...\n",
            "Number of non-padding tokens in tar_real: 1787\n",
            "Loss: 2.21639585\n",
            "Average gradient: 0.000793440558\n",
            "Resources: CPU: 13.0% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2762...\n",
            "Number of non-padding tokens in tar_real: 1823\n",
            "Loss: 2.25948405\n",
            "Average gradient: 0.000806468131\n",
            "Resources: CPU: 13.7% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2763...\n",
            "Number of non-padding tokens in tar_real: 1841\n",
            "Loss: 2.2968812\n",
            "Average gradient: 0.00083951687\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2764...\n",
            "Number of non-padding tokens in tar_real: 1786\n",
            "Loss: 2.1589632\n",
            "Average gradient: 0.000825136434\n",
            "Resources: CPU: 15.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2765...\n",
            "Number of non-padding tokens in tar_real: 1806\n",
            "Loss: 2.27405691\n",
            "Average gradient: 0.000732659944\n",
            "Resources: CPU: 12.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2766...\n",
            "Number of non-padding tokens in tar_real: 1874\n",
            "Loss: 2.30941033\n",
            "Average gradient: 0.000763575605\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2767...\n",
            "Number of non-padding tokens in tar_real: 1779\n",
            "Loss: 2.09957838\n",
            "Average gradient: 0.000849255302\n",
            "Resources: CPU: 13.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2768...\n",
            "Number of non-padding tokens in tar_real: 1890\n",
            "Loss: 2.38804245\n",
            "Average gradient: 0.000739499694\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2769...\n",
            "Number of non-padding tokens in tar_real: 1775\n",
            "Loss: 2.28904414\n",
            "Average gradient: 0.000840454362\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2770...\n",
            "Number of non-padding tokens in tar_real: 1749\n",
            "Loss: 2.24139667\n",
            "Average gradient: 0.000880926382\n",
            "Resources: CPU: 13.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2771...\n",
            "Number of non-padding tokens in tar_real: 1761\n",
            "Loss: 2.21107674\n",
            "Average gradient: 0.000761049\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2772...\n",
            "Number of non-padding tokens in tar_real: 1817\n",
            "Loss: 2.20486045\n",
            "Average gradient: 0.00081259408\n",
            "Resources: CPU: 14.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2773...\n",
            "Number of non-padding tokens in tar_real: 1842\n",
            "Loss: 2.11331224\n",
            "Average gradient: 0.000744567136\n",
            "Resources: CPU: 16.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2774...\n",
            "Number of non-padding tokens in tar_real: 1781\n",
            "Loss: 2.19317889\n",
            "Average gradient: 0.000823405571\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2775...\n",
            "Number of non-padding tokens in tar_real: 1820\n",
            "Loss: 2.39491\n",
            "Average gradient: 0.000890388445\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2776...\n",
            "Number of non-padding tokens in tar_real: 1825\n",
            "Loss: 2.14872265\n",
            "Average gradient: 0.000818853383\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2777...\n",
            "Number of non-padding tokens in tar_real: 1801\n",
            "Loss: 2.23730946\n",
            "Average gradient: 0.000784727919\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2778...\n",
            "Number of non-padding tokens in tar_real: 1859\n",
            "Loss: 2.19373393\n",
            "Average gradient: 0.000812192797\n",
            "Resources: CPU: 12.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2779...\n",
            "Number of non-padding tokens in tar_real: 1834\n",
            "Loss: 2.1378963\n",
            "Average gradient: 0.000882731518\n",
            "Resources: CPU: 15.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2780...\n",
            "Number of non-padding tokens in tar_real: 1774\n",
            "Loss: 2.28127241\n",
            "Average gradient: 0.000859921332\n",
            "Resources: CPU: 11.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2781...\n",
            "Number of non-padding tokens in tar_real: 1858\n",
            "Loss: 2.27537847\n",
            "Average gradient: 0.000814251485\n",
            "Resources: CPU: 11.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2782...\n",
            "Number of non-padding tokens in tar_real: 1822\n",
            "Loss: 2.27835059\n",
            "Average gradient: 0.000839193061\n",
            "Resources: CPU: 14.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2783...\n",
            "Number of non-padding tokens in tar_real: 1831\n",
            "Loss: 2.19496465\n",
            "Average gradient: 0.000790706428\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2784...\n",
            "Number of non-padding tokens in tar_real: 1901\n",
            "Loss: 2.24318862\n",
            "Average gradient: 0.000791213126\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2785...\n",
            "Number of non-padding tokens in tar_real: 1872\n",
            "Loss: 2.30170321\n",
            "Average gradient: 0.000794198946\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2786...\n",
            "Number of non-padding tokens in tar_real: 1862\n",
            "Loss: 2.34714508\n",
            "Average gradient: 0.000885382527\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2787...\n",
            "Number of non-padding tokens in tar_real: 1770\n",
            "Loss: 2.2059195\n",
            "Average gradient: 0.000875080761\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2788...\n",
            "Number of non-padding tokens in tar_real: 1853\n",
            "Loss: 2.24409223\n",
            "Average gradient: 0.000924081076\n",
            "Resources: CPU: 14.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2789...\n",
            "Number of non-padding tokens in tar_real: 1771\n",
            "Loss: 2.18833494\n",
            "Average gradient: 0.000815916748\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2790...\n",
            "Number of non-padding tokens in tar_real: 1769\n",
            "Loss: 2.20917\n",
            "Average gradient: 0.000848509138\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2791...\n",
            "Number of non-padding tokens in tar_real: 1845\n",
            "Loss: 2.24280548\n",
            "Average gradient: 0.000833283411\n",
            "Resources: CPU: 16.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2792...\n",
            "Number of non-padding tokens in tar_real: 1831\n",
            "Loss: 2.33600187\n",
            "Average gradient: 0.000864484173\n",
            "Resources: CPU: 12.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2793...\n",
            "Number of non-padding tokens in tar_real: 1938\n",
            "Loss: 2.32666087\n",
            "Average gradient: 0.000841766538\n",
            "Resources: CPU: 13.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2794...\n",
            "Number of non-padding tokens in tar_real: 1809\n",
            "Loss: 2.17738104\n",
            "Average gradient: 0.000827917887\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2795...\n",
            "Number of non-padding tokens in tar_real: 1891\n",
            "Loss: 2.31405807\n",
            "Average gradient: 0.000853216043\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2796...\n",
            "Number of non-padding tokens in tar_real: 1789\n",
            "Loss: 2.14033079\n",
            "Average gradient: 0.000788430101\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2797...\n",
            "Number of non-padding tokens in tar_real: 1749\n",
            "Loss: 2.23610806\n",
            "Average gradient: 0.000733951747\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2798...\n",
            "Number of non-padding tokens in tar_real: 1883\n",
            "Loss: 2.3221817\n",
            "Average gradient: 0.0007945947\n",
            "Resources: CPU: 14.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2799...\n",
            "Number of non-padding tokens in tar_real: 1787\n",
            "Loss: 2.17923474\n",
            "Average gradient: 0.000777264766\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2800...\n",
            "Number of non-padding tokens in tar_real: 1883\n",
            "Loss: 2.17211151\n",
            "Average gradient: 0.0007655964\n",
            "Resources: CPU: 15.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2801...\n",
            "Number of non-padding tokens in tar_real: 1835\n",
            "Loss: 2.15611911\n",
            "Average gradient: 0.000898869941\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2802...\n",
            "Number of non-padding tokens in tar_real: 1842\n",
            "Loss: 2.2197094\n",
            "Average gradient: 0.000873954967\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2803...\n",
            "Number of non-padding tokens in tar_real: 1814\n",
            "Loss: 2.39855599\n",
            "Average gradient: 0.000828831049\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2804...\n",
            "Number of non-padding tokens in tar_real: 1875\n",
            "Loss: 2.32944202\n",
            "Average gradient: 0.000842963404\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 66.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2805...\n",
            "Number of non-padding tokens in tar_real: 1778\n",
            "Loss: 2.1470561\n",
            "Average gradient: 0.000803010131\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2806...\n",
            "Number of non-padding tokens in tar_real: 1638\n",
            "Loss: 2.00894904\n",
            "Average gradient: 0.000769888517\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2807...\n",
            "Number of non-padding tokens in tar_real: 1767\n",
            "Loss: 2.34117532\n",
            "Average gradient: 0.000780289469\n",
            "Resources: CPU: 14.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2808...\n",
            "Number of non-padding tokens in tar_real: 1798\n",
            "Loss: 2.32018\n",
            "Average gradient: 0.000938874728\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2809...\n",
            "Number of non-padding tokens in tar_real: 1814\n",
            "Loss: 2.26857328\n",
            "Average gradient: 0.000835947401\n",
            "Resources: CPU: 15.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2810...\n",
            "Number of non-padding tokens in tar_real: 1817\n",
            "Loss: 2.29174495\n",
            "Average gradient: 0.000829728728\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2811...\n",
            "Number of non-padding tokens in tar_real: 1938\n",
            "Loss: 2.43181419\n",
            "Average gradient: 0.000799158937\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2812...\n",
            "Number of non-padding tokens in tar_real: 1866\n",
            "Loss: 2.08626\n",
            "Average gradient: 0.000761811447\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2813...\n",
            "Number of non-padding tokens in tar_real: 1844\n",
            "Loss: 2.07642817\n",
            "Average gradient: 0.000756303\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2814...\n",
            "Number of non-padding tokens in tar_real: 1702\n",
            "Loss: 2.40231013\n",
            "Average gradient: 0.000897894963\n",
            "Resources: CPU: 11.5% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2815...\n",
            "Number of non-padding tokens in tar_real: 1932\n",
            "Loss: 2.40689397\n",
            "Average gradient: 0.000789282669\n",
            "Resources: CPU: 14.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2816...\n",
            "Number of non-padding tokens in tar_real: 1789\n",
            "Loss: 2.12772942\n",
            "Average gradient: 0.000748655468\n",
            "Resources: CPU: 15.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2817...\n",
            "Number of non-padding tokens in tar_real: 1816\n",
            "Loss: 2.36945605\n",
            "Average gradient: 0.000786335557\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 59.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2818...\n",
            "Number of non-padding tokens in tar_real: 1798\n",
            "Loss: 2.28675699\n",
            "Average gradient: 0.000751130516\n",
            "Resources: CPU: 14.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2819...\n",
            "Number of non-padding tokens in tar_real: 1699\n",
            "Loss: 2.07190466\n",
            "Average gradient: 0.000776199\n",
            "Resources: CPU: 14.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2820...\n",
            "Number of non-padding tokens in tar_real: 1794\n",
            "Loss: 2.02568364\n",
            "Average gradient: 0.000715661852\n",
            "Resources: CPU: 14.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2821...\n",
            "Number of non-padding tokens in tar_real: 1803\n",
            "Loss: 2.20212173\n",
            "Average gradient: 0.00076788693\n",
            "Resources: CPU: 12.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2822...\n",
            "Number of non-padding tokens in tar_real: 1854\n",
            "Loss: 2.23084641\n",
            "Average gradient: 0.000800672104\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2823...\n",
            "Number of non-padding tokens in tar_real: 1931\n",
            "Loss: 2.40224957\n",
            "Average gradient: 0.000741500524\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2824...\n",
            "Number of non-padding tokens in tar_real: 1868\n",
            "Loss: 2.28633118\n",
            "Average gradient: 0.000893301447\n",
            "Resources: CPU: 12.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2825...\n",
            "Number of non-padding tokens in tar_real: 1756\n",
            "Loss: 2.17632413\n",
            "Average gradient: 0.000803692383\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2826...\n",
            "Number of non-padding tokens in tar_real: 1869\n",
            "Loss: 2.25196171\n",
            "Average gradient: 0.000745162135\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2827...\n",
            "Number of non-padding tokens in tar_real: 1785\n",
            "Loss: 2.39255214\n",
            "Average gradient: 0.000831115874\n",
            "Resources: CPU: 15.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2828...\n",
            "Number of non-padding tokens in tar_real: 1789\n",
            "Loss: 2.14625239\n",
            "Average gradient: 0.000833850645\n",
            "Resources: CPU: 15.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2829...\n",
            "Number of non-padding tokens in tar_real: 1734\n",
            "Loss: 2.20480871\n",
            "Average gradient: 0.000861196255\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2830...\n",
            "Number of non-padding tokens in tar_real: 1866\n",
            "Loss: 2.08363938\n",
            "Average gradient: 0.000835915445\n",
            "Resources: CPU: 11.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2831...\n",
            "Number of non-padding tokens in tar_real: 1712\n",
            "Loss: 1.99085474\n",
            "Average gradient: 0.000800762326\n",
            "Resources: CPU: 11.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2832...\n",
            "Number of non-padding tokens in tar_real: 1856\n",
            "Loss: 2.34818506\n",
            "Average gradient: 0.000882394088\n",
            "Resources: CPU: 15.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2833...\n",
            "Number of non-padding tokens in tar_real: 1702\n",
            "Loss: 2.06938648\n",
            "Average gradient: 0.000777114299\n",
            "Resources: CPU: 12.9% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 65.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2834...\n",
            "Number of non-padding tokens in tar_real: 1749\n",
            "Loss: 2.03249431\n",
            "Average gradient: 0.000824784103\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2835...\n",
            "Number of non-padding tokens in tar_real: 1739\n",
            "Loss: 2.24946356\n",
            "Average gradient: 0.000831993762\n",
            "Resources: CPU: 14.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2836...\n",
            "Number of non-padding tokens in tar_real: 1813\n",
            "Loss: 2.11647391\n",
            "Average gradient: 0.000856775674\n",
            "Resources: CPU: 13.7% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2837...\n",
            "Number of non-padding tokens in tar_real: 1749\n",
            "Loss: 2.38635\n",
            "Average gradient: 0.000785042357\n",
            "Resources: CPU: 16.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2838...\n",
            "Number of non-padding tokens in tar_real: 1784\n",
            "Loss: 2.21352124\n",
            "Average gradient: 0.000843450543\n",
            "Resources: CPU: 13.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2839...\n",
            "Number of non-padding tokens in tar_real: 1804\n",
            "Loss: 2.2811377\n",
            "Average gradient: 0.00082956173\n",
            "Resources: CPU: 14.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2840...\n",
            "Number of non-padding tokens in tar_real: 1841\n",
            "Loss: 2.20343494\n",
            "Average gradient: 0.00080900488\n",
            "Resources: CPU: 10.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2841...\n",
            "Number of non-padding tokens in tar_real: 1764\n",
            "Loss: 2.08148503\n",
            "Average gradient: 0.000721870922\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2842...\n",
            "Number of non-padding tokens in tar_real: 1745\n",
            "Loss: 2.27003264\n",
            "Average gradient: 0.000790570688\n",
            "Resources: CPU: 11.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2843...\n",
            "Number of non-padding tokens in tar_real: 1817\n",
            "Loss: 2.12941527\n",
            "Average gradient: 0.000770685903\n",
            "Resources: CPU: 13.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 62.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2844...\n",
            "Number of non-padding tokens in tar_real: 1773\n",
            "Loss: 2.24036503\n",
            "Average gradient: 0.000815173786\n",
            "Resources: CPU: 14.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2845...\n",
            "Number of non-padding tokens in tar_real: 1748\n",
            "Loss: 2.14422488\n",
            "Average gradient: 0.000869577751\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 64.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2846...\n",
            "Number of non-padding tokens in tar_real: 1739\n",
            "Loss: 2.24212694\n",
            "Average gradient: 0.000739225594\n",
            "Resources: CPU: 16.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2847...\n",
            "Number of non-padding tokens in tar_real: 1810\n",
            "Loss: 2.24857\n",
            "Average gradient: 0.000767323596\n",
            "Resources: CPU: 14.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2848...\n",
            "Number of non-padding tokens in tar_real: 1864\n",
            "Loss: 2.22653842\n",
            "Average gradient: 0.000742074859\n",
            "Resources: CPU: 12.2% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 69.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2849...\n",
            "Number of non-padding tokens in tar_real: 1753\n",
            "Loss: 2.1926465\n",
            "Average gradient: 0.00079539069\n",
            "Resources: CPU: 12.4% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2850...\n",
            "Number of non-padding tokens in tar_real: 1819\n",
            "Loss: 2.10453081\n",
            "Average gradient: 0.000802256691\n",
            "Resources: CPU: 17.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2851...\n",
            "Number of non-padding tokens in tar_real: 1790\n",
            "Loss: 2.10396314\n",
            "Average gradient: 0.000791583676\n",
            "Resources: CPU: 23.3% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2852...\n",
            "Number of non-padding tokens in tar_real: 1746\n",
            "Loss: 2.24989128\n",
            "Average gradient: 0.000863703375\n",
            "Resources: CPU: 20.8% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2853...\n",
            "Number of non-padding tokens in tar_real: 1897\n",
            "Loss: 2.28572559\n",
            "Average gradient: 0.000778346555\n",
            "Resources: CPU: 21.5% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2854...\n",
            "Number of non-padding tokens in tar_real: 1802\n",
            "Loss: 2.17569757\n",
            "Average gradient: 0.000754228909\n",
            "Resources: CPU: 23.9% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2855...\n",
            "Number of non-padding tokens in tar_real: 1786\n",
            "Loss: 2.10059881\n",
            "Average gradient: 0.000772800471\n",
            "Resources: CPU: 23.5% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 63.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2856...\n",
            "Number of non-padding tokens in tar_real: 1848\n",
            "Loss: 2.30628252\n",
            "Average gradient: 0.000762249518\n",
            "Resources: CPU: 24.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2857...\n",
            "Number of non-padding tokens in tar_real: 1919\n",
            "Loss: 2.31842017\n",
            "Average gradient: 0.000718820374\n",
            "Resources: CPU: 21.5% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 68.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2858...\n",
            "Number of non-padding tokens in tar_real: 1870\n",
            "Loss: 2.30009365\n",
            "Average gradient: 0.00076786906\n",
            "Resources: CPU: 22.3% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2859...\n",
            "Number of non-padding tokens in tar_real: 1774\n",
            "Loss: 2.19229865\n",
            "Average gradient: 0.000845475355\n",
            "Resources: CPU: 22.0% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 67.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2860...\n",
            "Number of non-padding tokens in tar_real: 1748\n",
            "Loss: 2.38676167\n",
            "Average gradient: 0.000798293157\n",
            "Resources: CPU: 21.8% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2861...\n",
            "Number of non-padding tokens in tar_real: 1800\n",
            "Loss: 2.4368484\n",
            "Average gradient: 0.000823768904\n",
            "Resources: CPU: 22.1% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 60.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2862...\n",
            "Number of non-padding tokens in tar_real: 1842\n",
            "Loss: 2.29184699\n",
            "Average gradient: 0.000837289554\n",
            "Resources: CPU: 23.1% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2863...\n",
            "Number of non-padding tokens in tar_real: 1883\n",
            "Loss: 2.3461864\n",
            "Average gradient: 0.000784798875\n",
            "Resources: CPU: 22.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 61.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2864...\n",
            "Number of non-padding tokens in tar_real: 1852\n",
            "Loss: 2.2505939\n",
            "Average gradient: 0.000830250501\n",
            "Resources: CPU: 24.6% | RAM: 7.9% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2865...\n",
            "Number of non-padding tokens in tar_real: 1264\n",
            "Loss: 2.13260245\n",
            "Average gradient: 0.00101581193\n",
            "Resources: CPU: 22.6% | RAM: 7.8% | GPU (NVIDIA A100-SXM4-40GB): 58.0% (MEM: 16.1%)\n",
            "Training Epoch 20, Batch 2866...\n",
            "Epoch 20/20, Train Loss: 2.2454, Val Loss: 2.8792\n",
            "Model weights saved.\n",
            "Model training completed and weights saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ],
      "metadata": {
        "id": "XKK3ZFFDFt19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu\n",
        "\n",
        "# Parameters\n",
        "beam_size = 1\n",
        "max_length = 20\n",
        "start_token_id = 1\n",
        "\n",
        "weights = download_file_from_drive('18dtss4j9kAxVzhS1vJp-jG4Xr1Ct94Zf')\n",
        "\n",
        "transformer.load_weights(weights)\n",
        "print(\"Weights loaded successfully!\")\n",
        "\n",
        "def beam_search_decode(model, input_seq, beam_size=5, max_length=50, debug=False):\n",
        "    enc_padding_mask = create_padding_mask(input_seq)\n",
        "    enc_output = model.encoder(x=input_seq, mask=enc_padding_mask, training=False)\n",
        "\n",
        "    sequences = [(tf.constant([[start_token_id]], dtype=tf.int32), 0.0)]\n",
        "\n",
        "    # Debug: Print shape and first few tokens of input_seq\n",
        "    if debug:\n",
        "        print(\"DEBUG: input_seq shape:\", input_seq.shape)\n",
        "        print(\"DEBUG: input_seq (first row):\", input_seq[0, :10])\n",
        "\n",
        "    for step in range(max_length):\n",
        "        all_candidates = []\n",
        "        for seq, score in sequences:\n",
        "            look_ahead_mask = create_look_ahead_mask(tf.shape(seq)[1])\n",
        "            dec_padding_mask = create_padding_mask(input_seq)\n",
        "            combined_mask = tf.maximum(create_padding_mask(seq), look_ahead_mask)\n",
        "\n",
        "            predictions = model.decoder(\n",
        "                x=seq, enc_output=enc_output,\n",
        "                look_ahead_mask=combined_mask,\n",
        "                padding_mask=dec_padding_mask,\n",
        "                training=False\n",
        "            )\n",
        "            predictions = model.final_layer(predictions)[:, -1, :]  # [1, vocab_size]\n",
        "\n",
        "            log_probs = tf.nn.log_softmax(predictions, axis=-1)[0]  # [vocab_size]\n",
        "\n",
        "            # Debug: Print details at the first time step for the first sequence\n",
        "            if debug and step == 0:\n",
        "                print(\"DEBUG: log_probs shape:\", log_probs.shape)\n",
        "                print(\"DEBUG: top 10 log_probs:\", tf.math.top_k(log_probs, k=10))\n",
        "\n",
        "            top_k_log_probs, top_k_ids = tf.math.top_k(log_probs, k=beam_size)\n",
        "\n",
        "            # Debug: At first step, print chosen top tokens\n",
        "            if debug and step == 0:\n",
        "                print(\"DEBUG: top_k_ids:\", top_k_ids.numpy())\n",
        "                print(\"DEBUG: top_k_log_probs:\", top_k_log_probs.numpy())\n",
        "\n",
        "            for i in range(beam_size):\n",
        "                new_seq = tf.concat([seq, tf.expand_dims([top_k_ids[i]], 0)], axis=-1)\n",
        "                new_score = score + float(top_k_log_probs[i])\n",
        "                all_candidates.append((new_seq, new_score))\n",
        "\n",
        "        all_candidates = sorted(all_candidates, key=lambda x: x[1], reverse=True)\n",
        "        sequences = all_candidates[:beam_size]\n",
        "\n",
        "    best_seq, best_score = sequences[0]\n",
        "    return best_seq[0, 1:].numpy()\n",
        "\n",
        "# Choose 100 random samples from test_df\n",
        "test_samples = test_df.sample(100, random_state=42)\n",
        "\n",
        "references = []\n",
        "predictions_text = []\n",
        "\n",
        "# Debug on only the first sample to avoid too much clutter\n",
        "debug_first_sample = True\n",
        "\n",
        "for i, (eng, gr_ref) in enumerate(zip(test_samples[\"English\"].values, test_samples[\"Greek\"].values)):\n",
        "    ragged = tokenizer.tokenize([eng])\n",
        "    input_seq = ragged.to_tensor(shape=[1, MAX_SEQ_LENGTH])\n",
        "\n",
        "    pred_tokens = beam_search_decode(transformer, input_seq, beam_size=beam_size, max_length=max_length, debug=debug_first_sample)\n",
        "    debug_first_sample = False  # Only debug the first sample\n",
        "\n",
        "    pred_text = \" \".join([sp.id_to_piece(int(t)) for t in pred_tokens])\n",
        "    references.append(gr_ref.strip())\n",
        "    predictions_text.append(pred_text.strip())\n",
        "\n",
        "# Debug: Print first 5 predictions and references\n",
        "print(\"DEBUG: First 5 predictions vs references:\")\n",
        "for i in range(5):\n",
        "    print(\"EN:\", test_samples[\"English\"].values[i])\n",
        "    print(\"REF:\", references[i])\n",
        "    print(\"PRED:\", predictions_text[i])\n",
        "    print(\"---\")\n",
        "\n",
        "df_results = pd.DataFrame({\n",
        "    \"English\": test_samples[\"English\"].values,\n",
        "    \"Greek_Reference\": test_samples[\"Greek\"].values,\n",
        "    \"Predicted_Translation\": predictions_text\n",
        "})\n",
        "\n",
        "df_results.head()\n",
        "\n",
        "references_for_sacrebleu = [references]\n",
        "\n",
        "bleu = sacrebleu.corpus_bleu(predictions_text, references_for_sacrebleu)\n",
        "chrf = sacrebleu.corpus_chrf(predictions_text, references_for_sacrebleu)\n",
        "ter = sacrebleu.corpus_ter(predictions_text, references_for_sacrebleu)\n",
        "\n",
        "# Simple token-level accuracy\n",
        "token_accuracies = []\n",
        "for pred, ref in zip(predictions_text, references):\n",
        "    pred_tokens = pred.split()\n",
        "    ref_tokens = ref.split()\n",
        "    matches = sum(p == r for p, r in zip(pred_tokens, ref_tokens))\n",
        "    total = min(len(pred_tokens), len(ref_tokens))\n",
        "    token_accuracies.append(matches / total if total > 0 else 0)\n",
        "token_accuracy = np.mean(token_accuracies)\n",
        "\n",
        "print(\"--------- Dataset Info ---------\")\n",
        "print(\"Training set size:\", len(train_df))\n",
        "print(\"Validation set size:\", len(val_df))\n",
        "print(\"Test set size:\", len(test_df))\n",
        "print(f\"Tokenized Vocabulary Size: {sp.get_piece_size()}\")\n",
        "print(\"--------- Preprocessing Hyperparameters ---------\")\n",
        "print(f\"MAX_VOCAB_SIZE:{MAX_VOCAB_SIZE}\")\n",
        "print(f\"MAX_SEQ_LENGTH:{MAX_SEQ_LENGTH}\")\n",
        "print(f\"BATCH_SIZE:{BATCH_SIZE}\")\n",
        "print(f\"MIN_TOKENS (per sentence):{MIN_TOKENS}\")\n",
        "print(f\"MAX_TOKENS (per sentence):{MAX_TOKENS}\")\n",
        "print(\"--------- Model Hyperparameters ---------\")\n",
        "print(f\"EPOCHS: {EPOCHS}\")\n",
        "print(f\"LEARNING_RATE: {LEARNING_RATE}\")\n",
        "print(f\"NUM_LAYERS: {NUM_LAYERS}\")\n",
        "print(f\"D_MODEL: {D_MODEL}\")\n",
        "print(f\"NUM_HEADS: {NUM_HEADS}\")\n",
        "print(f\"DFF: {DFF}\")\n",
        "print(f\"DROPOUT_RATE: {DROPOUT_RATE}\")\n",
        "print(\"--------- Evaluation Metrics ---------\")\n",
        "print(f\"BLEU: {bleu.score:.2f}\")\n",
        "print(f\"CHRF: {chrf.score:.2f}\")\n",
        "print(f\"TER: {ter.score:.2f}\")"
      ],
      "metadata": {
        "id": "RYO100aUFu0t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c0c59bb-9193-4115-c19a-7e504a5178b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights loaded successfully!\n",
            "DEBUG: input_seq shape: (1, 22)\n",
            "DEBUG: input_seq (first row): tf.Tensor([9257   71  700   14 1726  263   14 1484 3818   58], shape=(10,), dtype=int32)\n",
            "DEBUG: log_probs shape: (32000,)\n",
            "DEBUG: top 10 log_probs: TopKV2(values=<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([-1.2894046, -1.6825116, -1.8038304, -2.9072692, -3.140919 ,\n",
            "       -3.394728 , -3.5649388, -3.9261518, -4.640788 , -4.732126 ],\n",
            "      dtype=float32)>, indices=<tf.Tensor: shape=(10,), dtype=int32, numpy=\n",
            "array([10901,   102,    18,  1554,   943,   926,    61,  5221,  8471,\n",
            "          66], dtype=int32)>)\n",
            "DEBUG: top_k_ids: [10901]\n",
            "DEBUG: top_k_log_probs: [-1.2894046]\n",
            "DEBUG: First 5 predictions vs references:\n",
            "EN: india is now the country with the most cases of aids.\n",
            "REF: η ινδία είναι τώρα η χώρα με τα περισσότερα περιστατικά aids.\n",
            "PRED: ▁ινδία ▁η ▁χώρα ▁είναι ▁πλέον ▁η ▁χώρα ▁που ▁έχει ▁τη ▁χώρα ▁αυτή ▁να ▁υποφέρει ▁από ▁το ▁aids . ▁\" ▁αναλογία\n",
            "---\n",
            "EN: in most cases, costly collective wage agreements and schemes for better conditions at work fall by the wayside.\n",
            "REF: οι δαπανηρές συλλογικές διαπραγματεύσεις και η βελτίωση των συνθηκών εργασίας είναι συχνά άγνωστες έννοιες στις περιπτώσεις αυτές.\n",
            "PRED: ▁σε ▁πολύ ▁δύσκολες ▁συνθήκες , ▁οι ▁διαδικασίες ▁και ▁οι ▁αποδο τικές ▁συνθήκες ▁είναι ▁χαμηλότερες ▁με ▁περιβαλλοντικά ▁πρότυπα ▁με ▁πολύ ▁υψηλότερο\n",
            "---\n",
            "EN: and if it stops moving, subsidise it.'\n",
            "REF: και αν σταματήσει να κινείται, επιχορηγήστε το\".\n",
            "PRED: ▁αν ▁όχι , ▁να ▁την ▁σταματήσουμε , ▁να ▁την ▁διατρέ χουμε ▁τον ▁καταργ ούμε ▁και ▁να ▁την ▁σταματήσουμε ▁να ▁την\n",
            "---\n",
            "EN: in writing. - i support the principle of trying to make fruit more accessible to young people in schools.\n",
            "REF: γραπτώς. - υποστηρίζω την αρχή να γίνουν τα φρούτα πιο προσιτά στους νέους στα σχολεία.\n",
            "PRED: ▁ζητώ ▁να ▁διευκολυνθεί ▁η ▁στήριξη ▁της ▁χρήσης ▁του ▁στην ▁καλύτερη ▁κατάρτιση ▁των ▁νέων ▁ταιν ιών ▁για ▁τους ▁καλύτερους ▁νέους ▁στόχο\n",
            "---\n",
            "EN: our measures must be harmonised, because this way, efficiency is also increased many fold.\n",
            "REF: τα μέτρα μας πρέπει να είναι εναρμονισμένα, διότι έτσι η αποδοτικότητα θα αυξηθεί πολλαπλάσια.\n",
            "PRED: ▁τα ▁μέτρα ▁πρέπει ▁να ▁μας ▁βοηθήσουν , ▁όπως ▁έχει ▁επιτευχθεί , ▁να ▁διατηρήσουμε ▁την ▁αποτελεσμα τικότητα , ▁αλλά ▁πρέπει ▁να\n",
            "---\n",
            "--------- Dataset Info ---------\n",
            "Training set size: 366815\n",
            "Validation set size: 45852\n",
            "Test set size: 45852\n",
            "Tokenized Vocabulary Size: 32000\n",
            "--------- Preprocessing Hyperparameters ---------\n",
            "MAX_VOCAB_SIZE:32000\n",
            "MAX_SEQ_LENGTH:22\n",
            "BATCH_SIZE:128\n",
            "MIN_TOKENS (per sentence):3\n",
            "MAX_TOKENS (per sentence):20\n",
            "--------- Model Hyperparameters ---------\n",
            "EPOCHS: 20\n",
            "LEARNING_RATE: 0.001\n",
            "NUM_LAYERS: 6\n",
            "D_MODEL: 256\n",
            "NUM_HEADS: 8\n",
            "DFF: 1024\n",
            "DROPOUT_RATE: 0.1\n",
            "--------- Evaluation Metrics ---------\n",
            "BLEU: 0.23\n",
            "CHRF: 26.64\n",
            "TER: 168.98\n",
            "Token-level accuracy: 0.00\n"
          ]
        }
      ]
    }
  ]
}